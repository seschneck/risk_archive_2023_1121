---
title: "chk_ema"
author: "Sarah Sant'Ana"
date: "9/10/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, error = TRUE)
```

Hi Megan! Here is some code to help you get started checking the ema variables. You can also look at the chk_ema script that Hannah and I started on ahilw ago in the scripts_chk folder. You won't be able to copy it exactly because we are starting with raw ema files with the corrections added in from our checks.

Running these code chunks will open the raw ema files, add all corrections from the log, and combine into a single ema file for you to start your checks:

### Setup

```{r Packages and paths, message=FALSE}
# Packages
library(tidyverse)
library(knitr)
library(janitor)
library(lutz)
library(furrr)
library(lubridate)
library(kableExtra)
library(psych)


# Paths
path_shared_data <- "P:/StudyData/RISK/analysis/shared/data" 
path_out <- "P:/StudyData/RISK/analysis/shared/scripts_chk/chk_lapses" 
path_raw <- "P:/StudyData/RISK/raw_data"
path_qualtrics <- "P:/StudyData/RISK/raw_data/qualtrics"

# Function
#This is the function that will update the ema files from the log
update_from_log = function(df, reason){
  #Filter log based on reason and data frame being updated
  log_c <- log_ema %>%
    filter(ema_type == case_when("EMAM_1" %in% names(df) ~ "morning",
                                "EMAL_1" %in% names(df) ~ "later")) %>% 
        filter(log_action=="change")
  
  #Loop through each change, update the specified variable at the correct ema response
  for(i in 1:nrow(log_c)){
    id <- log_c$response_id[i]
    var <- log_c$var_name[i]
    
    #if response_id is all, update the value for every observation at that subid
    if(id=="all"){
      index <- which(df$SubID == log_c$subid[i])
      val <- rep(log_c$new_value[i], length(index))
      
    }else{
      val <- log_c$new_value[i]
      index <- which(df$ResponseID == id)
    class <- df %>% pull({{var}}) %>% class()
    if(class=="numeric"){
      val = as.numeric(val)
    }
    
    df[index, {{var}}] = val
    }
  }
  return(df)
}


```

### Open raw data files

This opens the raw data files -- you can use glimpse() or View() open the full data tibbles in the window if you want to look at it
```{r Load data}

# Log_ema 
log_ema <- 
  read_csv(file.path(path_out,"log_ema.csv"),
           col_types = cols(.default=col_character()))

# Open EMA morning
ema_morning<- read_csv(file.path(path_qualtrics, "ema_morning.csv"))


# Open EMA later
ema_later <- read_csv(file.path(path_qualtrics, "ema_later.csv"))
```

### Clean EMA and combine into one file

At the bottom of this chunk I provide an example of one way to provide some summary info about the data. when you type `r [insert some r code here]` in the non R parts of an rmarkdown, it will print the data for you in the markdown output. So below, I make data frames and then print the means. You can also just do a table or call it in the r code chunk too


```{r make one EMA file}

## Update raw ema file using the data log

#create timezone variable for lapses

ema_morning <- ema_morning %>% 
  mutate(EMAM_1.6 = "America/Chicago")

ema_later <- ema_later %>% 
  mutate(EMAL_1.6 = "America/Chicago")

# Update ema morning
ema_morning <- update_from_log(ema_morning, "All")

# Update ema later
ema_later <- update_from_log(ema_later, "All")


#Clean up morning ema

ema_morning <- ema_morning %>% 
  rename(ema_1_drank = EMAM_1,
         ema_1_drank_s_date = EMAM_1.1,
         ema_1_drank_s_time = EMAM_1.2,
         ema_1_drank_e_date = EMAM_1.3,
         ema_1_drank_e_time = EMAM_1.4,
         ema_1_abstain = EMAM_1.5,
         ema_2_urge = EMAM_2_1,
         ema_3_risk = EMAM_3_1,
         ema_4_stress = EMAM_4_1,
         ema_5_pleasant = EMAM_5_1,
         ema_6_current_feeling_1 = EMAM_6_1,
         ema_7_current_feeling_2 = EMAM_7_1,
         ema_8_future_risk = EMAM_8_1,
         ema_9_future_stress = EMAM_9_1,
         ema_10_future_drink = EMAM_10_1) %>% 
  clean_names(case="snake") %>% 
  mutate(ema_type = "morning")

#Clean up later ema

ema_later<- ema_later %>% 
  rename(ema_drank = EMAL_1,
         ema_1_drank_s_date = EMAL_1.1,
         ema_1_drank_s_time = EMAL_1.2,
         ema_1_drank_e_date = EMAL_1.3,
         ema_1_drank_e_time = EMAL_1.4,
         ema_1_abstain = EMAL_1.5,
         ema_2_urge = EMAL_2_1,
         ema_3_risk = EMAL_3_1,
         ema_4_stress = EMAL_4_1,
         ema_5_pleasant = EMAL_5_1,
         ema_6_current_feeling_1 = EMAL_6_1,
         ema_7_current_feeling_2 = EMAL_7_1,) %>% 
  clean_names(case="snake") %>% 
  mutate(ema_type = "later") 

#Create one ema tibble
ema <- full_join(ema_morning, ema_later, copy = TRUE) %>%
  select(-(c(ema_1_drank, ema_1_drank_s_date, ema_1_drank_s_time, ema_1_drank_e_date, ema_1_drank_e_time)))

completed_subs <- list.files(path = path_raw) %>%
  str_extract("\\d+") %>%
  keep(!is.na(.))
ema <-  ema %>%
  filter(sub_id %in% completed_subs) %>%
  arrange(sub_id)

ema %>%
  pull(sub_id) %>%
  unique(.)


#Note: The survey start and end dates are in UTC
#Since GPS does everything in CST, we will too
ema <- ema %>% 
  mutate(start_date = as_datetime(
    start_date, tz = "America/Chicago"),
    end_date = as_datetime(
    end_date, tz = "America/Chicago"))

#check it out
glimpse(ema)

#Some descriptives
#calculating survey time
ema_sub <- ema %>% 
  mutate(sur_time = as.numeric(end_date - start_date),
         start_date_d = as_date(start_date)) %>% 
  group_by(sub_id) %>% 
  summarise(n = n(), days = length(unique(start_date_d)),sur_time = mean(sur_time))


#Number of morning surveys per subject
nmorn <- ema %>% 
  filter(ema_type=="morning") %>% 
  group_by(sub_id) %>% 
  summarise(n = n())
  

#Number of later surveys per subject
nlat <- ema %>% 
  filter(ema_type=="later") %>% 
  group_by(sub_id) %>% 
  summarise(n = n())
```
A total of **`r nrow(ema)`** EMAs (**`r nrow(ema_morning)`** morning and **`r nrow(ema_later)`** later EMA reports) were submitted by **`r length(unique(ema$sub_id))`** participants. **`r (nrow(ema) - sum(ema$finished))`** of these surveys are unfinished.

On average, each subject completed **`r round(mean(ema_sub$n))`** EMA surveys (**`r round(mean(nmorn$n))`** morning and **`r round(mean(nlat$n))`** later surveys) across **`r mean(ema_sub$days)`** days. The highest number of surveys completed by a participant was **`r round(max(ema_sub$n))`** and the lowest was **`r round(min(ema_sub$n))`**. Surveys took an average of  **`r round(mean(ema_sub$sur_time))`** seconds to complete. *(We will do more in depth descriptives of ema data once lapses are cleaned)*




## Ideas
Make a histogram of how long people take to complete surveys on average
State where the cut-off visually looks and how many people are beyond that cut off
State where the cut off was for stressor use and how many people we would lose

Check for missingness on all variables -- does it make sense to be missing that data? Is it causing a problem?

Get different metrics of how many surveys subs are completing...try to decide how many surveys we need to be credible/include them
Compare to whatever cuts you used for stressor use
For example, do we care about mean surveys per week? One survey per day? On average, how many people completed at least one ema a day? Are there any subs whos ema are too spread out to be useful?


### ema descriptives
```{r}
#create variable for ema completion time in minutes
ema <- ema %>%
  mutate(compl_time = as.numeric((end_date - start_date)/60))

#histogram of completion time distribution
ema %>% 
  ggplot(aes(x = compl_time)) +
  geom_histogram() +
  xlab("survey completion time in minutes") +
  ggtitle("distribution of survey completion times") +
  theme_classic()

#number of surveys completed outside of various windows (60, 15, 10, 7, and 5 minutes)
sum(ema$compl_time > 60)
ema %>% 
  filter(compl_time < 60) %>%
  ggplot(aes(x = compl_time)) +
  geom_histogram() +
  xlab("survey completion time in minutes") +
  ggtitle("distribution of survey completion times") +
  theme_classic()

sum(ema$compl_time > 15)
ema %>% 
  filter(compl_time < 15) %>%
  ggplot(aes(x = compl_time)) +
  geom_histogram() +
  xlab("survey completion time in minutes") +
  ggtitle("distribution of survey completion times") +
  theme_classic()

sum(ema$compl_time > 10)
ema %>% 
  filter(compl_time < 10) %>%
  ggplot(aes(x = compl_time)) +
  geom_histogram() +
  xlab("survey completion time in minutes") +
  ggtitle("distribution of survey completion times") +
  theme_classic()

sum(ema$compl_time > 7)
ema %>% 
  filter(compl_time < 7) %>%
  ggplot(aes(x = compl_time)) +
  geom_histogram() +
  xlab("survey completion time in minutes") +
  ggtitle("distribution of survey completion times") +
  theme_classic()

sum(ema$compl_time > 5) #this was the cut off used in stressor use, however I do feel using a slightly larger 
                        #window is appropriate here given the increase in # of questions and their complexity
ema %>% 
  filter(compl_time < 5) %>%
  ggplot(aes(x = compl_time)) +
  geom_histogram() +
  xlab("survey completion time in minutes") +
  ggtitle("distribution of survey completion times") +
  theme_classic()

##average time btwn stressor use and this sample
##average time to complete by subjects--not necessary

#Checking for missing variables
if(any(is.na(ema))){
   ema %>%
    summarise(across(everything(), ~sum(is.na(.)))) %>%
    gather(key = "var", value = "num_NA" ) %>%
    filter(num_NA > 0) %>%
    kable() %>%
    kable_styling(full_width = FALSE, position = "left")
}else {
  paste("No missing values")
}

###add exploring the missing variables and confirming that all NAs are okay

#looking at stressful events
sum(ema$ema_4_stress > 0, na.rm = TRUE)
ema %>%
  ggplot(aes(x = ema_4_stress)) +
  geom_histogram(bins = 10) +
  xlab("stressful event intensity") +
  ggtitle("distribution of stressful event intensity") +
  theme_classic()

#number of stressful reports per person
ema %>%
  group_by(sub_id) %>%
  summarise(total_stress = as.numeric(sum(ema_4_stress > 0, na.rm = TRUE))) %>%
  ggplot(aes(x = total_stress)) +
  geom_histogram(bins = 10) +
  xlab("number of stressful event reports by subject") +
  ggtitle("distribution of stressful event ireports by subject") +
  theme_classic()

ema %>%
  group_by(sub_id) %>%
  filter(total_stress < 2)

##
#number of completed emas per person
ema %>%
  group_by(sub_id) %>%
  summarise(length(sub_id))



is.numeric(ema$total_stress)
filter(ema$total_stress > 2)


  
  group_by(ema$sub_id(sum(ema$ema_4_stress > 0, na.rm = TRUE)))
  


 
  
```
