---
title: "Clean and process location data from interviews"
author: "Hannah Moshontz & John Curtin"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: 
  html_document:
  toc: true 
  toc_depth: 4
editor_options: 
  chunk_output_type: console
knit: (function(input, ...) {
    rmarkdown::render(
      input,
      output_dir = dplyr::if_else(Sys.info()[["sysname"]] == "Windows",
      "P:/studydata/risk/knits/shared", 
      "/Volumes/private/studydata/risk/knits/shared")
    )
  })
---

### Code status

Under construction


### Notes

Purpose: This file does cleaning and basic processing of interview data.

Inputs:  Opens data files in path_raw

* subid_Locations.xlsx

Also opens log files in path_log

* log_locations.csv

Outputs: 

* locations.csv

### Setup

Functions
```{r}
import_w_subid <- function(xlsxfile){
  read_excel(xlsxfile) %>% 
    mutate(subid = str_extract(xlsxfile, "\\d\\d\\d"))
}

merge_raw_files <- function(file_suffix) {
  list.files(file.path(path_raw), 
           recursive = TRUE,
           pattern = paste0("\\d\\d\\d_", file_suffix, ".xlsx"),
           full.names = TRUE) %>% 
  as.list() %>% 
  set_names(str_extract(., "\\d\\d\\d")) %>% 
  map_df(~import_w_subid(.x) %>% 
           clean_names() %>% 
           mutate(across(everything(), as.character)))
}
```


Paths 
```{r}
path_raw <- "P:/studydata/risk/data_raw" 
path_log <- "./shared/notes"
path_processed <- "P:/studydata/risk/data_processed" 
```

Packages and Source
```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(lubridate)
library(janitor)
library(purrr)
library(readxl)
```

### Import locations files

```{r}
known_locations <- merge_raw_files("Locations") %>% 
  glimpse()
```


### EDA

```{r}
known_locations <- known_locations %>%
  mutate(across(where(is_character), str_to_lower),
         across(
           c("type", 
             "drank",
             "alcohol",
             "emotion",
             "risk",
             "avoid",
             "vacation"),
           as_factor)) %>% 
  glimpse() 
```


Ensuring unique labels for different levels of the type factor

```{r}
known_locations %>% 
  tabyl(type)
```

Reviewing issues with different variable names for six subjects
```{r}
known_locations %>% 
  filter(!is.na(alcohol_here)) %>% 
  pull(subid) %>% 
  unique() %>% 
  length()
```


### Apply log and other fixes


```{r}
library(tidylog) #will document data wrangling
```


Making variable names uniform
```{r}
known_locations <- known_locations %>% 
  mutate(drank = coalesce(drank, drank_here),
         alcohol = coalesce(alcohol, alcohol_here),
         emotion = coalesce(emotion, location_emotion),
         risk = coalesce(risk, location_risk),
         avoid = coalesce(avoid, risk_avoid),
         vacation = coalesce(vacation, vacation_location)) %>% 
  select(-c(drank_here, alcohol_here, location_emotion, location_risk, risk_avoid, vacation_location))
```


```{r}
log_locations <- read_csv(file.path(path_log, "log_locations.csv"))

if (nrow(filter(log_locations, log_action != "recode_all")) > 0) {
  stop("Not all log actions are recode_all; code needs to be rewritten")
}

for (i in seq_along(log_locations$var_name)) {
  
  log_var_name <- pluck(log_locations, "var_name", i)
  log_new_value <- pluck(log_locations, "new_value", i)
  log_old_value <- pluck(log_locations, "old_value", i)
  
  # pull out row ids that need to be recoded
  row_ids <- known_locations %>%
    mutate(row_number = as.numeric(rownames(d))) %>%
    filter(get(log_var_name) == log_old_value) %>%
    select(row_number) %>%
    unlist(use.names = FALSE)
  
  for (i in seq_along(row_ids)) {
    
    known_locations[[row_ids[i], log_var_name]] <- as.character(log_new_value)
  }
}

```


### Save final shared file

```{r}
 known_locations %>% 
   select(subid, utc, lat, long, full_address, type, drank, alcohol, emotion, risk, avoid, vacation) %>%   
   write_csv(file.path(path_processed, "locations.csv"))
```
