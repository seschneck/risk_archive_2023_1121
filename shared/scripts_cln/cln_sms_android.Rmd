---
title: "Andriod/SMS Logs"
author: "Kendra Wyant"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: 
  html_document:
    toc: true 
    toc_depth: 2
editor_options: 
  chunk_output_type: console
knit: (function(input, ...) {
    rmarkdown::render(
      input,
      output_dir = dplyr::if_else(Sys.info()[["sysname"]] == "Windows",
      "P:/studydata/risk/knits/shared", 
      "/Volumes/private/studydata/risk/knits/shared")
    )
  })
---

### Notes
Purpose: This script contains code to open and merge all SMS log files in xml format from participants raw data folders. This is a study-level clean script so cleaning is minimal. Errors that don't have an obvious solution are highlighted in this clean script but are not corrected for. These will need to be corrected during pre-processing at the study-level.     

**Note: File not ready for analysis on text content. Emojis are accidently stripped in the aggregated csv file (may result in blank messages), still working on how to extract them from the xml files and will update.**    


Inputs:   
[subid]_SMS_1.xml  
[subid]_SMS_2.xml   
[subid]_SMS_3.xml  
etc. for as many sms xml logs in the subid's folder  


### Setup
```{css, echo = FALSE}
pre, code {
  max-height: 500px;
  overflow-y: auto;
  white-space: pre !important; 
  overflow-x: auto
}
```

Absolute Paths 
```{r}
switch (Sys.info()[['sysname']],
        # PC paths
        Windows = {
          path_raw <- "P:/studydata/risk/data_raw"
          path_shared <- "P:/studydata/risk/data_processed/shared"},
        # IOS paths
        Darwin = {
          path_raw <- "/Volumes/private/studydata/risk/data_raw"
          path_shared <- "/Volumes/private/studydata/risk/data_processed/shared"})
```


Packages and Source
```{r, message = FALSE}
library(tidyverse)
library(kableExtra)
library(lubridate)
library(XML)
library(xml2)
```

Relative Paths
```{r}
library(here)

path_log <- "shared/notes"
```

### Android SMS Logs (XML) 

#### Create function to read in subid logs

```{r}
read_xml <- function(subid) {
    logs <- tibble(subid = character(),
                   message = character())
    filepaths <- list.files(file.path(path_raw, subid), pattern = "SMS", include.dirs = FALSE, full.names = TRUE)
    # subids 1-15 have a RawSMSVoice folder in addition to XML logs - not including this folder 
    filepaths <- discard(filepaths, filepaths == file.path(path_raw, subid, "RawSMSVoice"))
    if(length(filepaths) > 0) {
      for(file in filepaths) {
        if(str_detect(file,'.xml')) {
          
          # xml code adapted from Susan's fun_database script
          # use read_html instead of read_xml to avoid problem with emojis in contacts
          xml <- xml_children(read_html(file.path(file)))
 
          # fix for problem with nested list after switching to read_html()
          while (length(xml) == 1) {
            xml <- xml_children(xml) #loop to find lower level of xml children 
          }    

          log <- data.frame(
           protocol = xml_attr(xml,'protocol'),
           address = xml_attr(xml,'address'),
           date = xml_attr(xml,'date'),
           type = xml_attr(xml,'type'),
           subject = xml_attr(xml,'subject'),
           body = xml_attr(xml,'body'),
           toa = xml_attr(xml,'toa'),
           sc_toa = xml_attr(xml,'sc_toa'),
           service_center = xml_attr(xml,'service_center'),
           read = xml_attr(xml,'read'),
           status = xml_attr(xml,'status'),
           locked = xml_attr(xml,'locked'),
           date_sent = xml_attr(xml,'date_sent'),
           readable_date = xml_attr(xml,'readable_date'),
           contact_name = xml_attr(xml,'contact_name'),
           stringsAsFactors = FALSE)
          
          # Add subid and log information to dataframe
          log <- log %>% 
            mutate(subid = subid,
                   log_file = file,
                   created = file.info(file)$ctime,
                   modified = file.info(file)$mtime)
          
          # Join log files
          logs <- logs %>% 
            full_join(log)
        }
      }
      return(logs)
    } 
}
```

```{r}
get_xml_ids <- function(subid) {
    log <- tibble(subid = character())
    log_files <- list.files(file.path(path_raw, subid), pattern = "SMS", include.dirs = FALSE)
    log_files <- discard(log_files, log_files == "RawSMSVoice")
    if(length(log_files) > 0) {
      for(file in log_files) {
        if(str_detect(file,'xml')) {
         log <- log %>% 
            add_row(subid = subid)
          return(log) }
      }   
      
    }
}
```

#### get subids
```{r}
subids <- list.dirs(path_raw, recursive = FALSE, full.names = FALSE) %>% 
  keep(~ str_detect(.x, "([0-2][0-9][0-9])")) %>% 
  enframe(name = NULL, value = "subid")

# subids with xml files
xml_subids <- tibble(subid = character())
xml_subids <- map_df(subids$subid, ~get_xml_ids(.)) %>% 
  glimpse()
```


#### read in all XML logs
```{r message = FALSE}
all_logs <- tibble(subid = character())
all_logs <- map_df(xml_subids$subid, ~read_xml(.)) %>% 
  glimpse()
```

#### Remove duplicates

```{r}
all_logs <- all_logs %>%
  distinct(across(-c(log_file, created, modified)), .keep_all = TRUE) %>% 
  glimpse()
```


#### Clean with cleaning log
cleaning function
```{r}
clean_logs <- function(d, log){
  # recode_one log entries
  log_recode_one <- dplyr::filter(log, log_action == "recode_one")

  for (i in seq_along(log_recode_one$index)){

    log_subid <- pluck(log_recode_one, "subid", i)
    log_date <- pluck(log_recode_one, "date", i)
    log_address <- pluck(log_recode_one, "address", i)
    log_var_name <- pluck(log_recode_one, "var_name", i)
    log_new_value <- pluck(log_recode_one, "new_value", i)
    log_old_value <- pluck(log_recode_one, "old_value", i)

    # pull out row id
    row_id <- d %>%
      mutate(row_number = as.numeric(rownames(d))) %>%
      # match on subid, date, phone number, and old value
      dplyr::filter(subid == log_subid) %>%
      dplyr::filter(get(log_var_name) == log_old_value) %>%
      dplyr::filter(date == log_date) %>%
      dplyr::filter(address == log_address) %>%
      select(row_number) %>%
      unlist(use.names = FALSE)
    }
    
    # check that only one matching data row
    if (length(row_id) != 1) {
      stop("Rows matching subid: ", log_subid, " does not equal 1")
    }

    # make change to rowid
    if (is.numeric(d[[row_id, log_var_name]])) d[[row_id, log_var_name]] <- as.numeric(log_new_value)
    if (is_character(d[[row_id, log_var_name]])) d[[row_id, log_var_name]] <- as.character(log_new_value)
    if (is.POSIXt(d[[row_id, log_var_name]])) d[[row_id, log_var_name]] <- as_datetime(log_new_value)

  
  return(d)
}
```

read in log and summarize
```{r}
log <- read_csv(here(path_log, "log_sms_android.csv"), col_types = "ccccccccc") %>%
  rowid_to_column("index") %>%
  glimpse()

# view log actions
table(log$log_action)
```

clean data
```{r}
all_logs <- all_logs %>%
  clean_logs(., log) %>%
  glimpse()
```



#### Convert utc to date time 
Check all dates encoded as 13 digit utc in milliseconds    
```{r}
all_logs %>% 
  filter(!nchar(date) == 13)
```

Convert dates to date time object
```{r}
all_logs <- all_logs %>% 
  mutate(date = round(as.numeric(date)/1000, 0), 
         date = as_datetime(date, tz = "utc"))
```

#### Date sent
Check encoded as 13 digit utc   
FIX: Date sent not all 13 digit utcs - need to look into this before converting to date time
```{r}
all_logs %>% 
  filter(!nchar(date_sent) == 13) %>% 
  count(date_sent) %>% 
  arrange(desc(n)) 
```


#### Other data updates for eda

Replace empty and null character strings with NA
```{r}
all_logs <- all_logs %>% 
  mutate(across(where(is.character), ~na_if(., c(""))),
         across(where(is.character), ~na_if(., c("null")))) %>% 
  glimpse()
```


Remove survey signal messages from study staff
```{r}
(test_messages <- str_subset(all_logs$body, "SurveySignal"))
all_logs <- all_logs %>% 
  filter(!body %in% test_messages) %>% 
  glimpse()
```

<br>

### EDA

`r length(unique(all_logs$subid))` subids had xml sms data logs read in.    


#### Missing data
```{r}
all_logs %>% 
  naniar::miss_var_summary()
```

100% of texts missing message (note text message content is in body variable)       

toa and sc_toa are 0 or NA for all log entries   
```{r}
all_logs %>% 
  janitor::tabyl(toa)

all_logs %>% 
  janitor::tabyl(sc_toa)
```

Remove variables with > 98% missing values
```{r}
all_logs <- all_logs %>%
  select(-c(message, subject, toa, sc_toa)) %>% 
  glimpse()
```


NOTE: Not sure if service center is useful, but keeping for now    

service_center = "The service center (SC) through which to send the message, if present."    
https://developer.android.com/reference/android/provider/Telephony.TextBasedSmsColumns#SERVICE_CENTER
```{r}
all_logs %>% 
  janitor::tabyl(service_center)
```


<br>

#### Dates
Dates range from `r min(all_logs$date, na.rm = TRUE)` to `r max(all_logs$date, na.rm = TRUE)`   

Check dates against readable_date variable   
```{r}
all_logs %>% 
  # convert readable date to date time object
  mutate(date_str = as_datetime(readable_date, tz = "America/Chicago", 
                                                   format = "%b %e, %Y %I:%M:%S %p")) %>% 
  # convert utc date to central time
  mutate(date = with_tz(date, tzone = "America/Chicago")) %>% 
  select(date, date_str)
```

Compare two date entries for discrepancies    
Readable date for 3 entries are 1 hour off. May be due to traveling?   
FIX: Doesn't look like 60 minute difference?
```{r}
all_logs %>% 
  mutate(date_str = as_datetime(readable_date, tz = "America/Chicago", 
                                                   format = "%b %e, %Y %I:%M:%S %p"),
         date = with_tz(date, tzone = "America/Chicago"),
         diff = round(difftime(date, date_str, units = "mins"), 0)) %>%
  filter(diff != 0)  %>% 
  select(subid, address, date, date_str, diff)
```

Removing readable date - will be using unix time stamp from here on out
```{r}
all_logs <- all_logs %>% 
  select(-readable_date)
```

<br>

#### phone numbers
Missing numbers mostly belong to subid 240
```{r}
all_logs %>% 
  filter(is.na(address)) 
```

Raw number format   
Note: email address is possible phone number
```{r}
all_logs %>% 
  filter(!is.na(address)) %>% 
  select(address) %>% 
  head(n = 1000) %>% 
  print(n = Inf)
```



#### text content

Random sample of truncated text content    
FIX: Not seeing many emojis - may have accidently been stripped, working on solution.
```{r}
all_logs %>% 
  select(body) %>% 
  mutate(body = str_trunc(body, 20)) %>% 
  sample_n(., 200) %>% 
  print(n = Inf)
```

#### type
```{r}
all_logs %>% 
  count(type)
```

#### read
```{r}
all_logs %>% 
  count(read)
```

#### status
```{r}
all_logs %>% 
  count(status)
```

#### protocol
```{r}
all_logs %>% 
  count(protocol)
```

#### locked
```{r}
all_logs %>% 
  count(locked)
```

#### date sent

About half have a date of 0. Not sure what 0 is yet, doesn't seem to be related to type of call.
```{r}
all_logs %>% 
  count(date_sent == 0)

all_logs %>% 
  filter(date_sent == 0) %>% 
  janitor::tabyl(type)
```

#### contact name
```{r}
all_logs %>% 
  group_by(contact_name) %>% 
  slice(1) %>% 
  select(contact_name) %>% 
  kbl() %>% 
  kable_styling() %>% 
  scroll_box(width = "50%", height = "500px")
```

#### log files
more than 3 logs
```{r}
all_logs %>% 
  group_by(subid) %>% 
  summarise(n_logs = length(unique(log_file))) %>% 
  filter(n_logs > 3)

all_logs %>% 
  filter(subid == "032") %>% 
  janitor::tabyl(log_file)

all_logs %>% 
  filter(subid == "052") %>% 
  janitor::tabyl(log_file)

all_logs %>% 
  filter(subid == "223") %>% 
  janitor::tabyl(log_file)
```

32 and 52 also have 4 voice call logs:  
subid 32 bought a new phone in the first month of the study and so we collected call/sms logs from both phones at Follow Up 1.  
subid 52 got a new phone while on study - likely explains extra log.   
subid 223 got a new phone and phone number so they came in on 5/20/2019 to get apps put on their phone and to register for surveys. Participant brought their deactivated phone with to delete apps and to transfer calls and SMS files (labeled SMS_1 and Calls_1); Participant did not have a Voice_4 file at their Final Visit they had no phone calls in their phone call log

<br>

log creation dates range from `r min(all_logs$created)` to `r max(all_logs$created)`.      
log modification dates range from `r min(all_logs$modified)` to `r max(all_logs$modified)`.   


### Add categorical labels




### Write csv
```{r}
write_csv(all_logs, file.path(path_shared, "sms_android.csv")) %>% glimpse()
```

**Note: date saved as UTC**

<br>