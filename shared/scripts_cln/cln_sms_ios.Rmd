---
title: "IOS/SMS Logs"
author: "Kendra Wyant"
date: "`r lubridate::today()`"
output: 
  html_document:
    toc: true 
    toc_depth: 4
editor_options: 
  chunk_output_type: console
knit: (function(input, ...) {
    rmarkdown::render(
      input,
      output_dir = dplyr::if_else(Sys.info()[["sysname"]] == "Windows",
      "P:/studydata/risk/knits/shared", 
      "/Volumes/private/studydata/risk/knits/shared")
    )
  })
---

### Code Status

These data are not fully cleaned. In this script I have documented all the information I have found so far about what the different variables are and what potential issues might exist.    

**KW is still actively working on this script.**   

Note:   

* This file not ready for analysis on text content. Emojis may not be properly encoded in aggregated csv file, still working on how to extract them from the SQL files and will update.   
* I have not completed full EDA on every variable. I am still trying to figure out what most of these mean. Focus is on variables relevant for meta study.    


### Notes
Purpose: This script contains code to open and merge all SMS log files in SQL format from participants raw data folders. This is a study-level clean script so cleaning is minimal. Errors that don't have an obvious solution are highlighted in this clean script but are not corrected for. These will need to be corrected during pre-processing at the study-level.     

  

Inputs:   
[subid]_SMS_1.sql  
[subid]_SMS_2.sql  
[subid]_SMS_3.sql  
etc. for as many sms sql logs in the subid's folder  


### Setup

Chunk Defaults
```{r defaults, include=FALSE}
knitr::opts_chunk$set(attr.output='style="max-height: 500px;"')
```

Absolute Paths 
```{r}
switch (Sys.info()[['sysname']],
        # PC paths
        Windows = {
          path_raw <- "P:/studydata/risk/data_raw"
          path_shared <- "P:/studydata/risk/data_processed/shared"},
        # IOS paths
        Darwin = {
          path_raw <- "/Volumes/private/studydata/risk/data_raw"
          path_shared <- "/Volumes/private/studydata/risk/data_processed/shared"})
```


Relative Paths
```{r}
path_log <- "shared/notes"
```


Packages for lab workflow 
```{r, packages_workflow, message=FALSE, warning=FALSE}

library(conflicted) # detect and warn about function conflicts
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")

library(here)  # establish project directory consistently as working directory
```

Packages and Source
```{r, message = FALSE}
library(tidyverse)
library(kableExtra)
library(RSQLite)
library(lubridate)
library(janitor)
```


### IOS SMS Logs (SQL) 

#### Create function to read in subid logs

```{r}
read_sql <- function(subid) {
    logs <- tibble(subid = character(),
                   message = character())
    log_files <- list.files(here(path_raw, subid), pattern = "SMS", include.dirs = FALSE)
    # subids 1-15 have a RawSMSVoice folder in addition to SQL logs - not including this folder 
    log_files <- discard(log_files, log_files == "RawSMSVoice")
    
    if(length(log_files) > 0) {
      
      for(file in log_files) {
        if(str_detect(file,'.sql')) {
          path <- here(path_raw, subid, file)
          log_db <- dbConnect(RSQLite::SQLite(), path)
          # uncomment below to see all available tables
          # dbListTables(log_db)
          message <- dbGetQuery(log_db,'select * from message')
          handle <- dbGetQuery(log_db,'select ROWID, id from handle')
          chat_message_join <- dbGetQuery(log_db,'select chat_id, message_id from chat_message_join')
          # below is table that can be used to link all numbers associated with group chat
          # chat_handle_join <- dbGetQuery(log_db,'select * from chat_handle_join')
          
          # rename keys for joining tables to be more clear and reduce duplicate names
          message <- message %>% 
            rename(message_id = ROWID)
          handle <- handle %>% 
            rename(handle_id = ROWID,
                   phone_number = id)
          
          # join messages with number
          log <- message %>% 
            left_join(handle, by = "handle_id")
          
          # join with chat id
          log <- log %>% 
            left_join(chat_message_join, by = "message_id")
          
          # Add subid and log information to dataframe
          log <- log %>% 
            mutate(subid = subid,
                   log_file = file,
                   created = file.info(path)$ctime,
                   modified = file.info(path)$mtime)
          
         # Remove binary variables not relevant and class everything as character for merging
          log <- log %>%
            select(-c(attributedBody, payload_data, message_summary_info)) %>% 
            mutate(across(where(is.numeric), as.character))
          
          #close the db connection
          dbDisconnect(log_db)
    
                  
           # Join log files
          logs <- logs %>% 
            full_join(log)
          
        }
         
      }
      return(logs)
    } 
}
```

```{r}
get_sql_ids <- function(subid) {
    log <- tibble(subid = character())
    log_files <- list.files(here(path_raw, subid), pattern = "SMS", include.dirs = FALSE)
    log_files <- discard(log_files, log_files == "RawSMSVoice")
    if(length(log_files) > 0) {
      for(file in log_files) {
        if(str_detect(file,'sql')) {
         log <- log %>% 
            add_row(subid = subid)
          return(log) }
      }   
      
    }
}
```


#### get subids
```{r}
subids <- list.dirs(path_raw, recursive = FALSE, full.names = FALSE) %>% 
  keep(~ str_detect(.x, "([0-2][0-9][0-9])")) %>% 
  enframe(name = NULL, value = "subid")

# subids with sql files
sql_subids <- tibble(subid = character())
sql_subids <- map_df(subids$subid, ~get_sql_ids(.)) %>% 
  glimpse()
```


#### read in all SQL logs
```{r message = FALSE}
all_logs <- tibble(subid = character())
all_logs <- map_df(sql_subids$subid, ~read_sql(.)) %>% 
  glimpse()
```



#### Format date (UTC)

Dates are in either a 9-digit time stamp - seconds since 2001-01-01 or 
an 18-digit time stamp - nanoseconds since 2001-01-01 (seen on newer IOS models)
```{r}
all_logs %>% 
  filter(!(nchar(date) == 18 | nchar(date) == 9))
```

Convert 18 digit date format on newer subids to UTC
```{r}
all_logs <- all_logs %>% 
  mutate(date = case_when(nchar(date) == 18 ~ as.numeric(date)/1000000000 + 978307200, # convert from nanoseconds first
                          TRUE ~ as.numeric(date) + 978307200),
         date = as_datetime(date, tz = "utc")) %>% 
  glimpse()
```


#### Other data updates for eda

Replace empty character strings with NA
```{r}
all_logs <- all_logs %>% 
  mutate(across(where(is.character), ~na_if(., c("")))) %>% 
  glimpse()
```

Remove survey signal messages
```{r}
(test_messages <- str_subset(all_logs$text, "SurveySignal"))
all_logs <- all_logs %>% 
  filter(!text %in% test_messages)
```


<br>

#### Remove duplicates
```{r}
all_logs <- all_logs %>% 
  # don't match on log varaibles or variables that were new during study and not on all log versions
  distinct(across(-c(log_file, created, modified, ck_sync_state, ck_record_id,
                     ck_record_change_tag, destination_caller_id, sr_ck_sync_state,
                     is_corrupt, sort_id)), .keep_all = TRUE) %>% 
  glimpse()
```




### EDA

`r length(unique(all_logs$subid))` subids had SQL sms data logs read in.   

sql file detected for subid 9 but not read in     
NOTE: 3 logs exist but no observations in logs
```{r}
sql_subids %>% 
  filter(!subid %in% all_logs$subid)

subid_9 <- read_sql("009") %>% 
  glimpse()
```



Dates range from `r min(all_logs$date)` to `r max(all_logs$date)`  

Max date looks good - min date must be due to someone having old messages.   


#### missing data
```{r}
naniar::miss_var_summary(all_logs) %>% 
  print(n = Inf)
```


**Remove variables with 98 - 100% missing data**
```{r}
all_logs <- all_logs %>% 
  select(-c(message, service_center, sr_ck_record_id, sr_ck_record_change_tag, 
            group_title, expressive_send_style_id, subject, balloon_bundle_id,
            reply_to_guid, associated_message_guid, country))
```


**Remove variables with no variance**

```{r}
all_logs %>% 
  select(where(is.character)) %>% 
  select(-c(subid, message_id, guid, text, handle_id, account, account_guid, chat_id,
            date_read, cache_roomnames, phone_number, ck_record_id, log_file, destination_caller_id,
            ck_record_change_tag, time_expressive_send_played, associated_message_range_location,
            associated_message_range_length, other_handle, date_played, date_delivered)) %>% 
  map(., tabyl)

# no variance variables
all_logs <- all_logs %>% 
  select(-c(is_corrupt, sr_ck_sync_state, message_source, is_archive, is_forward,
            is_service_message, is_system_message, is_delayed, is_empty, is_emote,
            is_finished, replace, is_spam))
```


Other possibly uninformative variables:
```{r}
naniar::miss_var_summary(all_logs) %>% 
  print(n = 5)
```

sort_id   
Unclear what sort_id 17 means - even if valuable we only have one value so not helpful
```{r}
all_logs %>% 
  tabyl(sort_id)

all_logs %>% 
  filter(sort_id == 17) %>% 
  kbl() %>% 
  kable_styling() %>% 
  scroll_box(width = "100%")

# remove variable
all_logs <- all_logs %>% 
  select(-sort_id)
```

cache_roomnames
Doesn't completely Overlap with chat_id
```{r}
# number distinct roomnames
all_logs %>% 
  filter(!is.na(cache_roomnames)) %>% 
  group_by(cache_roomnames) %>% 
  slice(1) %>% 
  nrow()

# number distinct roomname/chat_id pairings
all_logs %>% 
  filter(!is.na(cache_roomnames)) %>% 
  group_by(cache_roomnames, chat_id) %>% 
  slice(1) %>% 
  nrow()
```

ck_record_id - seems to be some type of record identifier - too many missing values to be useful
```{r}
all_logs %>% 
  filter(!is.na(ck_record_id)) %>% 
  select(ck_record_id)

all_logs <- all_logs %>% 
  select(-ck_record_id)
```

ck_record_change_tag
FIX: not sure yet what this is
```{r}
all_logs %>% 
  filter(!is.na(ck_record_change_tag)) %>% 
  count(ck_record_change_tag) %>% 
  head(n = 10)

all_logs %>% 
  filter(ck_record_change_tag == 100) %>% 
  kbl() %>% 
  kable_styling() %>% 
  scroll_box(width = "100%")
```

destination_caller_id
This is just the subid's phone number or apple id account that they make calls through - dont need
```{r}
# Not just outgoing calls have value
all_logs %>% 
  filter(!is.na(destination_caller_id)) %>% 
  tabyl(is_from_me)

all_logs %>% 
  filter(!is.na(destination_caller_id)) %>% 
  group_by(destination_caller_id, subid) %>% 
  slice(1) %>% 
  arrange(subid) %>% 
  select(subid, destination_caller_id) %>% 
  print(n = Inf)
```

account and account_guid is also subid specific. Repetitive and less complete info compared to subid variable
```{r}
all_logs %>% 
  group_by(account, destination_caller_id) %>% 
  slice(1) %>% 
  select(subid, account, destination_caller_id, account_guid) %>% 
  arrange(subid) %>% 
  print(n = Inf)
```

Remove repetitive/unneccessary variables
```{r}
all_logs <- all_logs %>% 
  select(-c(destination_caller_id, account, account_guid))
```


```{r}
all_logs %>% 
  glimpse()
```




<br>

#### guid

Duplicate messages still exist   
Same message, but variables such as row_id, handle_id, version, account, etc. differ   
FIX: Duplicates from group messages?
```{r}
duplicate_guids <- all_logs %>% 
  count(guid) %>% 
  filter(n > 1)

all_logs %>% 
  filter(guid %in% duplicate_guids$guid) %>% 
  arrange(guid) %>% 
  head(20) %>% 
  kbl() %>% 
  kable_styling(bootstrap_options = c("condensed", "striped")) %>% 
  scroll_box(width = "100%", height = "500px")
```


**Note: ROWID and handle_id are SQL keys for joining tables - handle_id joins message to phone number** 

#### Sent (is_from_me)

```{r}
all_logs %>% 
  tabyl(is_from_me)
```


1 = outgoing   
0 = incoming   


#### ID (phone number)

`r nrow(subset(all_logs, is.na(phone_number)))` missing phone numbers

Fix: most missing numbers are sent messages to a group chat.   
Chat Id is a way to see thread of group messages.  

```{r}
all_logs %>% 
  filter(is.na(phone_number)) %>% 
  tabyl(is_from_me)
```


#### Is delivered
```{r}
all_logs %>% 
  tabyl(is_delivered)
```




#### Version

4 subids have version 1 log entries
```{r}
all_logs %>% 
  tabyl(subid, version)
```


#### Type

```{r}
tabyl(all_logs$type) 
```

0 = 
1 = 


#### Group action type

```{r}
tabyl(all_logs$group_action_type)
```

0 = 
1 = 



#### Text message content

Some messages look blank but have a unicode object replacement character   
FIX: Does this mean an image or object was sent via text?
```{r}
all_logs %>% 
  filter(text == "￼")
```




### Write CSV

FIX: Use vroom instead of write_csv? write_csv is slow
```{r}
all_logs %>% 
  # keep only unique rows across retained variables
  distinct(across(-c(log_file, created, modified)), .keep_all = TRUE) %>% 
  write_csv(here(path_shared, "sms_ios.csv")) %>% 
  glimpse()
```

Note: all dates exported as UTC

