---
title: "Characterize best `r params$data_type` model for `r params$window` and lead = `r params$lead` and `r params$version`"
author: "John Curtin & Kendra Wyant"
date: "`r lubridate::today()`"
output: 
  html_document:
    toc: true 
    toc_depth: 4
params:
  study: "ema"
  data_type: "all"
  cv: "kfold"
  window: "1week"
  lead: 0
  version: "v4"
---

### Code Status

in development

### Notes
This is a generic script that reproduces the CV metrics for the best model configuration,
calculates various performance metrics from that resampling, makes plots,
and then fits the best config to the final sample to do feature importance.

This script is called by various studies, passing in the data_type, window, lead, and version.


### Set Up Environment

```{r}
study <- params$study
data_type <- params$data_type
cv <- params$cv
window <- params$window
lead <- params$lead 
version <- params$version
```

Packages for lab workflow 
```{r, packages_workflow, message=FALSE, warning=FALSE}
library(conflicted) # detect and warn about function conflicts
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
conflict_prefer("slice", "dplyr")
conflict_prefer("spec", "yardstick")
conflict_prefer("col_factor", "vroom")
conflict_prefer("vi", "vip")

library(here)
```


Packages for script
```{r, packages_script, message=FALSE, warning=FALSE}
library(tidyverse)
library(tidymodels)
library(themis)
library(vroom)
library(janitor)
library(ggplot2)
# library(kableExtra)
library(future)
# library(SHAPforxgboost)
library(forcats)

theme_set(theme_classic()) 

#Detect n cores
(n_core <- parallel::detectCores(logical = FALSE))
```

Absolute paths
```{r, absolute paths}
switch (Sys.info()[['sysname']],
        # PC paths
        Windows = {
          path_input <- str_c("P:/studydata/risk/chtc/", study)
          path_processed <- str_c("P:/studydata/risk/data_processed/", study)
          path_models <- str_c("P:/studydata/risk/models/", study)},

        # IOS paths
        Darwin = {
          path_input <- str_c("/Volumes/private/studydata/risk/chtc/", study)
          path_processed <- str_c("/Volumes/private/studydata/risk/data_processed/", study)
          path_models <- str_c("/Volumes/private/studydata/risk/models/", study)}
        )
```


Chunk Defaults
```{r defaults, include=FALSE}
knitr::opts_chunk$set(attr.output='style="max-height: 500px;"')

options(tibble.width = Inf)
options(tibble.print_max = Inf)
```


Source training controls 
```{r}
# EDA
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true")

# CHTC support functions
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/chtc/static_files/fun_chtc.R?raw=true")
```


### Read in preds and metrics for best model

```{r}
preds_best <- readRDS(here(path_models, str_c("resample_preds_best_", data_type, "_", window, "_", lead, "_", version, 
                                              "_", cv, ".rds")))
metrics_best <- readRDS(here(path_models, str_c("resample_metrics_best_", data_type, "_", window, "_", lead, "_", version,
                                                "_", cv, ".rds")))
```


### Model Performance

Look at performance within folds
```{r}
  metrics_best %>% 
    print_kbl()
```

```{r model_metrics}
if (cv == "kfold" | cv == "boot") {
  config_best <- metrics_best %>% 
    group_by(algorithm, feature_set, hp1, hp2, hp3, resample) %>% 
    summarise(across(accuracy:roc_auc, ~mean(.x)), .groups = "drop")
}


if (cv == "nested") {
  metrics_best %>% 
    summarise(across(ends_with("_outer"), mean)) 
}

config_best %>% glimpse
```

Confusion matrix using .5 threshold
```{r default_cm}
(cm <- preds_best %>% 
  conf_mat(truth, estimate))

rownames(cm$table) <- c("No lapse", "Lapse")
colnames(cm$table) <- c("No lapse", "Lapse")

cm %>% 
  autoplot() +
  theme(axis.text = element_text(size = rel(1.50)), 
        axis.title = element_text(size = rel(1.75)))

cm %>% summary()

# save plot for presentations
# ggsave(file.choose(), width = 7.5, height = 6.5, units = "in", device = "png",  dpi = 100)
```

Histograms with free Y
```{r prob_plot}
preds_best %>% 
  mutate(truth = if_else(truth == "no_lapse", "No lapse", "Lapse"),
         estimate = if_else(estimate == "no_lapse", "No lapse", "Lapse")) %>% 
  ggplot(data = ., aes(x = prob)) + 
   geom_histogram(bins = 15, fill = "white", col = "black") +
   facet_wrap(~truth, nrow = 2, scales = "free_y") +
   xlab("Pr(Lapse)") +
  theme(axis.text = element_text(size = rel(1.00)), 
        axis.title.x = element_text(size = rel(1.25)),
        strip.text = element_text(size = rel(1.75)))

# save plot for presentations
# ggsave(file.choose(), width = 6.5, height = 6.5, units = "in", device = "png",  dpi = 100)
```

Histograms with fixed Y
```{r prob_plot}
preds_best %>% 
  mutate(truth = if_else(truth == "no_lapse", "No lapse", "Lapse"),
         estimate = if_else(estimate == "no_lapse", "No lapse", "Lapse")) %>% 
  ggplot(data = ., aes(x = prob)) + 
   geom_histogram(bins = 15, fill = "white", col = "black") +
   facet_wrap(~truth, nrow = 2) +
   xlab("Pr(Lapse)") +
  theme(axis.text = element_text(size = rel(1.00)), 
        axis.title.x = element_text(size = rel(1.25)),
        strip.text = element_text(size = rel(1.75)))

# save plot for presentations
# ggsave(file.choose(), width = 6.5, height = 6.5, units = "in", device = "png",  dpi = 100)
```


Here is single ROC by concatenating all folds.
Could consider reporting this AUC though likely average of resample AUCs is more appropriate?
Could also plot ROC by fold but maybe too confusing?
```{r roc_info}
preds_best %>%
  roc_auc(prob, truth = truth, event_level = "second")

roc_data <- preds_best %>% 
  roc_curve(prob, truth = truth, event_level = "second")
  
roc_data %>% 
  ggplot(aes(x = 1 - specificity, y = sensitivity)) +
  geom_path() +
  geom_abline(lty = 3) +
  coord_fixed(xlim = c(0, 1), ylim = c(0, 1)) +
  labs(x = "Specificity",
       y = "Sensitivity") +
  scale_x_continuous(breaks = seq(0,1,.25),
    labels = sprintf("%.2f", seq(1,0,-.25))) +
  theme(axis.text = element_text(size = rel(1.50)), 
        axis.title = element_text(size = rel(1.75)))

# save plot for presentations
# ggsave(file.choose(), width = 6.5, height = 6.5, units = "in", device = "png",  dpi = 100)
```

Here is precision/recall by concatenating all folds
Same approach as above for ROC
```{r pr_info}
preds_best %>%
  pr_auc(prob, truth = truth, event_level = "second")

pr_data <- preds_best %>% 
  pr_curve(prob, truth = truth, event_level = "second")

pr_data %>% 
  ggplot(aes(x = recall, y = precision)) +
  geom_path() +
  geom_hline(lty = 3, yintercept = mean(preds_best$truth == "lapse")) +
  coord_fixed(xlim = c(0, 1), ylim = c(0, 1)) +
  labs(x = "Recall (Sensitivity)",
       y = "Precision (PPV)")
```


Confusion matrix and metrics based on optimal threshold
```{r opt_cm}
(thresh_opt <- roc_data %>% 
  mutate(j = sensitivity + specificity - 1) %>% 
  arrange(desc(j)) %>% 
  slice(1) %>% 
  pull(.threshold))

preds_best <- preds_best %>% 
  mutate(estimate_opt = if_else(prob < thresh_opt, "no_lapse", "lapse"),
         estimate_opt = factor(estimate_opt, levels = c("no_lapse", "lapse")))

(cm_opt <- preds_best %>% 
  conf_mat(truth, estimate_opt))

cm_opt %>% 
  autoplot()

cm_opt %>% summary(event_level = "second")
```

Confusion matrix and metrics based on high (.90) threshold
```{r opt_cm_hi}

thresh_hi <- .90

preds_best <- preds_best %>% 
  mutate(estimate_hi = if_else(prob < thresh_hi, "no_lapse", "lapse"),
         estimate_hi = factor(estimate_hi, levels = c("no_lapse", "lapse")))

(cm_hi <- preds_best %>% 
  conf_mat(truth, estimate_hi))

cm_hi %>% 
  autoplot()

cm_hi %>% summary(event_level = "second")
```

### Feature Importance

Read in best model fit (chosen with kfold)
```{r}
# Add check that file exists
if (file.exists(here(path_models, str_c("best_model_fit_", data_type, "_", 
                                        window, "_", lead, "_", version, ".rds")))) {
  model_fit_best <- readRDS(here(path_models, str_c("best_model_fit_", 
                                                    data_type, "_", window, "_", 
                                                    lead, "_", version, ".rds")))
  } else {
  stop("Feature importance skipped for nested: Need to first select best model with kfold and save out model fit.")
}
```


get data
```{r}

path_best <- here(path_input, 
                  str_c("train_", data_type, "_", window, "_", lead, "_", version, "_xgboost_", cv), 
                  "input/")
source(here(path_best, "training_controls.R"))

chunks <- str_split_fixed(data_trn, "\\.", n = Inf) # parse name from extensions
if (length(chunks) == 2) {
  fn <- str_c("data_trn.", chunks[[2]])
} else {
  fn <- str_c("data_trn.", chunks[[2]], ".", chunks[[3]])
}

# open based on file type
if (str_detect(fn, "csv")) {
  d <- vroom(here(path_best, fn), show_col_types = FALSE) 
} else {
  d <- readRDS(here(path_best, fn))
}

d <- d %>% 
  rename(y = {{y_col_name}})
    
# build recipe
# need to get the config for the final model selected by kfold.  We really only need
#this for nested because we already have it if we started with kfold but opening 
# again just for clearer setting cv = kfold
config_best <- readRDS(here(path_models, 
                            str_c("resample_metrics_best_", data_type, "_", 
                                  window, "_", lead, "_", version,
                                  "_kfold", ".rds"))) %>% 
  group_by(algorithm, feature_set, hp1, hp2, hp3, resample) %>% 
  summarise(across(accuracy:roc_auc, ~mean(.x)), .groups = "drop")
rec_xgb <- build_recipe(d = d, job = config_best)

features <- rec_xgb %>% 
  prep(training = d, strings_as_factors = FALSE) %>%
  bake(new_data = NULL)

x <- features %>% select(-y)  # x features
y <- features %>% select(y) %>% 
  mutate(y = if_else(y == "yes", "lapse", "no_lapse"))
```

iml predictor function
```{r}
predict_wrapper <- function(model, newdata) {
  predict(model, newdata, type = "prob") %>%  # set type = "prob" for probabilities
    dplyr::select(lapse = .pred_lapse, no_lapse = .pred_no_lapse)
}

# make iml predictor function
predictor <- iml::Predictor$new(model = model_fit_best, 
                           data = x, 
                           y = y,
                           predict.fun = predict_wrapper)  
```

```{r}

plan(multisession, workers = n_core)
imp_permute <- iml::FeatureImp$new(predictor, loss = "ce")
plan(sequential) 
```


```{r}

  shap_long <- shap.prep(xgb_model = extract_fit_engine(model_fit_best), 
                         X_train = features %>% as.matrix(),
                         top_n = 30) # top 30 features
   
  # just mean SHAP                      
  plot_mean_shap <- shap_long %>% 
    group_by(variable) %>% 
    slice(1) %>% 
    arrange(desc(mean_value)) %>% 
    select(variable, mean_shap = mean_value) %>% 
    mutate(variable = fct_rev(variable)) %>% 
    ggplot(aes(x=variable, y=mean_shap)) + 
      geom_col() +
      coord_flip() 
  
  print(plot_mean_shap)
  
  # full SHAP plot
  shap_long %>% 
    shap.plot.summary(dilute = 3)  # 1/3 of observations for shap values
  
# # plot feature values by SHAP for single feature  
# shap_long %>% 
#   mutate(variable = as.character(variable)) %>% 
#   filter(variable == "ema_10.p72.l0.rmax_response") %>% 
#   ggplot(aes(x = jitter(rfvalue), y = jitter(value))) +
#   geom_point()
}
```
