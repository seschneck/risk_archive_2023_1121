---
title: "Calculate SHAP probabilities for best `r params$data_type` model for `r params$window` and lead = `r params$lead` and `r params$version`"
author: "Kendra Wyant & John Curtin"
date: "`r lubridate::today()`"
output: 
  html_document:
    toc: true 
    toc_depth: 4
params:
  study: "ema"
  data_type: "all"
  cv: "kfold"
  window: "1week"
  lead: 0
  version: "v4"
---

### Code Status

In use with iterative improvement

### Notes
This script maps across all observations to calculate SHAP values as probabilities.

This script is called by various studies, passing in the data_type, window, lead, and version.


### Set Up Environment

```{r}
study <- params$study
data_type <- params$data_type
cv <- params$cv
window <- params$window
lead <- params$lead 
version <- params$version
```

Packages 
```{r, packages_script, message=FALSE, warning=FALSE}
library(conflicted) # detect and warn about function conflicts
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
conflict_prefer("slice", "dplyr")
conflict_prefer("spec", "yardstick")

library(tidyverse)
library(tidymodels)
library(DALEXtra)
library(furrr)

theme_set(theme_classic()) 
```

Absolute paths
```{r, absolute paths}
switch (Sys.info()[['sysname']],
        # PC paths
        Windows = {
          path_input <- str_c("P:/studydata/risk/chtc/", study)
          path_processed <- str_c("P:/studydata/risk/data_processed/", study)
          path_models <- str_c("P:/studydata/risk/models/", study)},

        # IOS paths
        Darwin = {
          path_input <- str_c("/Volumes/private/studydata/risk/chtc/", study)
          path_processed <- str_c("/Volumes/private/studydata/risk/data_processed/", study)
          path_models <- str_c("/Volumes/private/studydata/risk/models/", study)}
        )
```


Chunk Defaults
```{r defaults, include=FALSE}
knitr::opts_chunk$set(attr.output='style="max-height: 500px;"')

options(tibble.width = Inf)
options(tibble.print_max = Inf)
```


### Read in best model and feature set

Read in best model fit 
```{r load_best_model}
model_fit_best <- readRDS(file.path(path_models, str_c("best_model_fit_", 
                                                    data_type, "_", window, "_", 
                                                    lead, "_", version, ".rds")))

```


get data
```{r get_data}
path_best <- file.path(path_input, 
                  str_c("train_", data_type, "_", window, "_", lead, "_", 
                        version, "_xgboost_", cv), "input")
source(file.path(path_best, "training_controls.R"))

chunks <- str_split_fixed(data_trn, "\\.", n = Inf) # parse name from extensions
if (length(chunks) == 2) {
  fn <- str_c("data_trn.", chunks[[2]])
} else {
  fn <- str_c("data_trn.", chunks[[2]], ".", chunks[[3]])
}

# open based on file type
if (str_detect(fn, "csv")) {
  d <- read_delim(file.path(path_best, fn), delim = "\t",
                  show_col_types = FALSE) 
} else {
  d <- readRDS(file.path(path_best, fn))
}

d <- d %>% 
  rename(y = {{y_col_name}})
    
# build recipe
config_best <- readRDS(file.path(path_models, 
                            str_c("resample_metrics_best_", data_type, "_", 
                                  window, "_", lead, "_", version,
                                  "_kfold", ".rds"))) %>% 
  group_by(algorithm, feature_set, hp1, hp2, hp3, resample) %>% 
  summarise(across(accuracy:roc_auc, ~mean(.x)), .groups = "drop")

rec <- build_recipe(d = d, job = config_best)

features <- rec %>% 
  prep(training = d, strings_as_factors = FALSE) %>%
  bake(new_data = d) #  get test data (no resampling) by setting new_data = d
```

### Feature Importance (SHAP probabilities)

Make explainer function
```{r}
explain_dalex <- explain_tidymodels(model_fit_best, data = features, y = features$y)
```

Estimate how long to run   
One observation
```{r}
features_single_obs <- features %>% 
  slice(1)

tictoc::tic()
predict_parts_shap(explainer = explain_dalex, 
                   new_observation = features_single_obs, 
                   B = 25)
tictoc::toc()
```

ten observations
```{r}
# set up parallel processing
(n_cores <- parallel::detectCores(logical = FALSE))
plan(multisession, workers = n_cores)

# slice features to test 10 observations
set.seed(102030)
features_10_obs <- features %>% 
  slice_sample(n = 10)

# use future map
tictoc::tic()

tictoc::toc()
```



Downsample data to 10%
```{r}
# setseed(102030)
# features_10 <- features %>% 
#   slice_sample(prop = .1)
```

Map explainer function across all downsampled observations
```{r}
# FIX: Add check for if file exists
```

Save out SHAP values
```{r}

```


Create and save out plot
```{r}

```

















