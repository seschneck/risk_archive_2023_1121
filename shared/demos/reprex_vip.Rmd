---
title: "VIP reprex"
author: "JJC"
date: "11/4/2021"
output: html_document
---

## Notes
See the vip [tutorial](https://koalaverse.github.io/vip/articles/vip.html)

See [tutorial](https://cran.r-project.org/web/packages/datarobot/vignettes/VariableImportance.html) on using permutation method for model agnostic vip


## Setup

packages
```{r}
library(tidyverse)
library(tidymodels)
library(vip)
```

data
```{r}
data_trn <- tibble(x_1 = rnorm(100, 0, 1),
            x_2 = rnorm(100, 0, 1),
            x_3 = rnorm(100, 0, 1),
            y = 1 * x_1 + -2 * x_2 + rnorm(100, 0, .1))
```

recipe and splits
```{r}
rec <- recipe(y ~ ., data = data_trn) %>% 
  step_normalize(all_predictors())

summary(rec)

set.seed(20140102)
splits_boot <- data_trn %>% 
   bootstraps(times = 10, strata = "y")  # toy example with 10 splits

splits_boot
```

## Select and Train Best Model

Select best model configuration
```{r}
grid_hp <- expand_grid(penalty = exp(seq(-4, 4, length.out = 50)),
                            mixture = seq(0, 1, .2))

fits <-
  linear_reg(penalty = tune(), 
             mixture = tune()) %>% 
  set_engine("glmnet") %>% 
  tune_grid(preprocessor = rec, 
            resamples = splits_boot, grid = grid_hp, 
            metrics = metric_set(rmse))

fits %>% show_best()
```


Train Final Model
```{r}
feat_trn <- rec %>%
  prep(training = data_trn, strings_as_factors = FALSE) %>%
  bake(new_data = data_trn) %>% 
  glimpse()

fit <-
  linear_reg(penalty = select_best(fits)$penalty, 
             mixture = select_best(fits)$mixture) %>%
  set_engine("glmnet") %>% 
  fit(y ~ ., data = feat_trn)

fit %>% 
  tidy() %>% 
  print()
```

## Model Specific VI

Use `vi()` in `vip` package

This is an example for glmnet.   Will add for random forest later.  

* If `lambda` is omitted, `vi` seems to default to specified penalty in fit but this doesnt work in a classification model
Should always specify lambda with glmnet to be safe?
* Can get other `lambda` values b/c fit fit a series of lambdas
* `vi` seems to already remove sign when calculating `Importance`.  No need for `abs()`
* `vi` sorts in decreasing importance by default
```{r}
fit %>%
  vi(lambda = select_best(fits)$penalty) %>%   
  mutate(
    Variable = fct_reorder(Variable, Importance)  # this is for plotting order
  ) %>%
  ggplot(aes(x = Importance, y = Variable, fill = Sign)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)
```


## Model Agnostic VI

This will calculate the difference (or ratio if set explicitly) in the performance metric that occurs when the 
specific feature is permuted so that it is no longer related to the outcome.

Get x and y for use with vi_permute in vi()
```{r}
x <- feat_trn %>% 
  select(contains("x_")) %>% 
  as.matrix()

y <- feat_trn %>% 
  pull(y)
```


Functions for use with `vi_permute`

* metric function needs to have parameters named actual and predicted
* prediction function needs parameters named object, and newdata.  Needs to return a vector for regression.
Will need to adjust for other statistical algorithms and for classification.  
* Should also note that the model (object) is extracted
from the $fit field of the model fit object from tidy models internally by vi_permute()
```{r}

rmse_perm <- function(actual, predicted) {
  rmse_vec(actual, predicted)
}

pred_perm <- function(object, newdata) {
  predict(object, newdata, s = select_best(fits)$penalty)[, 1]  # HACK: using global variable for lambda in function.
}

```


```{r}
set.seed(1234)  # for reproducibility in vi_permute ()
fit %>%
  vi(method = "permute", 
     train = x, 
     target = y,
     metric = rmse_perm,
     pred_wrapper = pred_perm,   
     smaller_is_better = TRUE, 
     nsim = 100) %>%   # consider best value for nsim for stability
  mutate(
    Variable = fct_reorder(Variable, Importance)  # this is for plotting order
  ) %>%
  ggplot(aes(x = Importance, y = Variable)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)
```