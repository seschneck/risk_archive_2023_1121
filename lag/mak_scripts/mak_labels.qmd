---
title: "Make lapse labels for for 1 week window"
author: "John Curtin"
date: "`r lubridate::today()`"
editor_options: 
  chunk_output_type: console
format:
  html:
    embed-resources: true
---

### Code Status

This script is based on the EMA study script for making the three windows with updates to apply to only 1week window.  Lags arent relevant until we calculate features.   There are other minor updates for qmd and current lab conventions.

This script makes labels based on the cleaned lapses. See conclusions for important decisions and notes related to the pre-processing of lapses done in shared/scripts_cln/mak_lapses.Rmd   

### Conclusions   

- More complete EDA on all EMA data and lapses is in cln_ema.Rmd and mak_lapses.Rmd.  

- We decided to retain lapses with no end time if their onset was valid. We will use a
24 hour rule when sampling non-lapses. That is we will not sample non-lapses in the 
24 hours following the onset of the lapse.  

- with all lapses we will not sample no_lapses +- 24 hours from lapse   

- invalid lapses were also not sampled from for no_lapses within 24 hours of lapse  

- Our exclusion criteria can be summarized as:

  - lapses that were reported in an interview   
  - lapses that have no start time and date     
  - lapses that have a negative duration   
  - lapses that have a duration longer than 24 hours     
  - future lapses (lapse start > ema end time)   
  

- John and Kendra have decided to drop subid 104's data for the following reasons:   
  - They had lapses every day on study except one day.    
  - Only had 75 surveys where a lapse was not reported.   
  - Viewing their lapse times it appears they were drinking constantly (morning and 
  night).   
  - They consistently report being uncertain that their goal is to be abstinent 
  (uncertain on 125 of 137 lapses. They also report they are uncertain in this goal 
  at followup 1 and 2.    
  - They are ultimately discontinued since they were struggling to gain sobriety.   
  - Unfortunately this drops 109 valid lapses.    


- John and Kendra have decided to drop subid 269's data for the following reasons:       
  - They completed 10-15 surveys on many days on study (avg number of surveys per 
  day is 6.76).  
  - Their responses indicate careless responding - they were filling 2-4 surveys out 
  within an hour of each other and the responses to the questions were completely different.     
  - They have questionable no lapse labels - they reported no lapses while on study but 
  according to notes left two messages for study staff where they admitted to drinking 
  over the weekend.   
  

- John and Kendra have decided to drop subid 204's data for the following reasons:    
  - Subid 204 had extremely poor compliance. 33 out of 89 study days had an EMA completed. 
  They only did a total of 5 surveys between followup 2 and 3.    
  - We don't trust their lapse labels - They report several lapses during their interviews 
  but times appear questionable (same time every night). They only report 1 lapse with EMA.
  - From notes - "Participant did not do many surveys during their second month of participation. 
  At their Follow-up 2 visit they reported several lapses that were not documented in their 
  EMAs - estimated lapse days/times in subid's raw data log."  
  - JC note: "There are issues with 204. They are missing lapses reported by interview. But they  
  also stopped doing any ema by 5/17 even though their study end date was 6/13. Probably need to 
  drop them for lapse analyses for anything after 5/17.  Probably also need to add in their 
  reported lapses at follow-up 2. OR we drop them at the end of follow-up 1 or wherever their 
  ema gets sketchy"    


- John and Kendra have decided to decided to retain 128's data even though they have over 100 lapses for 
the following reasons:   
  - Compliance is good (averaged over 3 surveys per day, no days without an EMA).       
  - completed the study for the full 90 days.    
  - appeared to still want abstinence as they reported they were uncertain to ema_1_5 
  on only 3 surveys. They reported they were uncertain that their goal was to remain 
  abstinent at followup 1 and confirmed their goal was to remain abstinent at followup 2.    
  - Has more non-lapse surveys than lapse surveys.   
  

- Subid 118 has an invalid end time (None12pm) left in cleaned EMA as study-level decision. 
After Kendra and John reviewed this situation, it was concluded that it was likely they were 
still drinking at time of EMA (i.e., no end time). Changing end time to NA in this script.    
  
  
- Subid 238 has 419 total EMAs for 89 days on study. Some days they have as many as 10 
surveys a day. Not clear why. They report no lapses while on study. They also have no other notes or 
evidence to suggest their data is unreliable.    

- Interview lapses are used to exclude days from non-lapse sampling but should not be 
used as valid lapses. Times are approximations made retrospectively.     

- There were no EMA surveys sent to any participants on 3/2/19.   

- 23 EMAs with lapses took more than 10 minutes to complete (ranges from 11 - 582 minutes 
for finished surveys).     

- All unfinished surveys (finished = 0) have at least ema_1 answered which reports if 
there have been any lapses since the last survey.  
  - Note that there are several "self-correcting surveys" where a participant answers 
  "Yes" for ema_1 then restarts another survey within minutes of the incomplete survey 
  and puts "no" for ema_1.  
  

- All final timezones are in America/Chicago timezone.    


### Set Up Environment

Chunk Defaults
```{r defaults}
#| include: false

knitr::opts_chunk$set(attr.output='style="max-height: 500px;"')

options(tibble.width = Inf)
options(tibble.print_max = Inf)
```

Absolute paths
```{r, absolute paths}
switch (Sys.info()[['sysname']],
        # PC paths
        Windows = {
          path_raw <- "P:/studydata/risk/data_raw"
          path_processed <- "P:/studydata/risk/data_processed/shared"
          path_lag <- "P:/studydata/risk/data_processed/lag"},

        # IOS paths
        Darwin = {
          path_raw <- "/Volumes/private/studydata/risk/data_raw"
          path_processed <- "/Volumes/private/studydata/risk/data_processed/shared"
          path_lag <- "/Volumes/private/studydata/risk/data_processed/lag"},
        
        # Linux paths
        Linux = {
          path_raw <- "~/mnt/private/studydata/risk/data_raw"
          path_processed <- "~/mnt/private/studydata/risk/data_processed/shared"
          path_lag <- "~/mnt/private/studydata/risk/data_processed/lag"},
        
        )
```

Packages for script
```{r, packages_script}
options(conflicts.policy = "depends.ok")
library(tidyverse)
library(furrr)
```


Source for script
```{r, source_script}
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/print_kbl.R?raw=true")
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true")
source(here::here("shared/fun_local.R"))
```

### Read in lapses
```{r}
lapses <- read_csv(here::here(path_processed, "lapses.csv"), col_types = cols()) |> 
  mutate(across(c(lapse_start, lapse_end, ema_end), ~ with_tz(.x, "America/Chicago"))) |> 
  glimpse()
```


### Study Dates/Times

We will not predict lapses outside of study participation dates. Need info on:

* Start and end dates for participation
* Who completed followup_1 so that they have context
* Time of the last EMA so we can know the definite window for no_lapse sampling.
We can assume no_lapse sampling starts with study_start but it end with the earlier
of study_end or ema_end (time of the last ema that we trust has valid data)     

Read in dates from study level folder
```{r}
dates <- read_csv(here::here(path_lag, "study_dates.csv"), col_types = cols()) |>
  mutate(across(study_start:ema_end, ~ with_tz(.x, tz = "America/Chicago"))) |> 
  glimpse()
```


`r length(unique(subset(lapses, !exclude)$subid))` out of `r length(unique(dates$subid))` subids (`r round(length(unique(subset(lapses, !exclude)$subid))/length(unique(dates$subid)), 2)`) have lapses. 
```{r}
lapses |> 
  filter(!exclude)  |> 
  tab(subid) |> 
  arrange(desc(n))
```

### Get valid observations of lapse and no_lapse

Get valid lapse and no_lapse observations by specified window duration (in seconds)   

Set up parallel processing.  use furrr to future map over subids (the_subid) when making labels
```{r}
n_cores <- parallel::detectCores(logical = FALSE)
cl <- parallel::makePSOCKcluster(n_cores)
doParallel::registerDoParallel(cl)
plan(multisession, workers = n_cores)

subids <- unique(dates$subid)
```

Make labels with 1 week window duration.  Start at midnight on second day
```{r map_labels}   
labels <- subids |> 
  future_map_dfr(\(subid) get_lapse_labels(subid, lapses, dates, 
                                    buffer_start = 60 * 60 * 24, window_dur = 604800)) |>  # 60 * 60 * 24 * 7 
  glimpse()
```

Return to sequential processing
```{r}
plan(sequential)
```

### Check counts of lapse and no lapse labels

lapses
```{r}
(n_lapse <- labels |> filter(lapse == TRUE) |> nrow())
```

no lapses
```{r}
labels |> filter(no_lapse == TRUE) |> nrow()
```

labeled as both lapse and no lapse (should be 0
)
```{r}
labels |> filter(lapse == TRUE,
                 no_lapse == TRUE) |> nrow()
```

not labeled
```{r}
labels |> filter(lapse == FALSE,
                 no_lapse == FALSE) |> nrow()
```



### Check labels end one epoch before study_end date

recalculate study end time
```{r}
study_end_times <- dates |> 
  rowwise() |> 
  mutate(study_end = study_end + (hours(23)),
         ema_end = floor_date(ema_end, unit = "hours"),
         end_time = min(study_end, ema_end)) |> 
  ungroup() |> 
  select(subid, end_time)
```

calculate difference between study end date and last label dttm
```{r}
labels |> 
  left_join(study_end_times, by = "subid") |> 
  group_by(subid) |> 
  slice_tail(n = 1) |> 
  ungroup() |> 
  mutate(end_label_diff = end_time - dttm_label) |> 
  tab(end_label_diff)
```


### Get Final Labels 

Removes no_lapse labels that we do not want to use (e.g., they are 24 hours before or after a lapse)
```{r}
labels <- bind_labels(labels) |> 
  rename(lapse = label) |> 
  mutate(lapse = if_else(lapse == "lapse", "yes", "no")) |> 
  arrange(subid, dttm_label) |> 
  glimpse()
```

### EDA on Final Labels 

Proportion of lapses    

```{r}
labels |> 
  tab(lapse)
```

Labels per subid. Sorted by number lapses
```{r}
labels |> 
  tab2(subid, lapse) |> 
  arrange(yes)
```


### Save
Save valid_observations and labels
```{r}
labels |> 
  write_csv(here::here(path_lag, "labels_1week.csv")) 
```
