---
title             : "Personal Sensing of Smartphone Communications to Support Recovery from Alcohol Use Disorder"
shorttitle        : "Personal Sensing for AUD"

author: 
  - name          : "Kendra Wyant"
    affiliation   : "1"
    corresponding : yes    
    address       : "1202 West Johnson St., Madison, WI 53706"
    email         : "kpaquette2@wisc.edu"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization 
      - Writing - Original Draft Preparation
      - Writing - Review & Editing


affiliation:
  - id            : "1"
    institution   : "Department of Psychology, University of Wisconsin-Madison"

authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  
  Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
  
  One sentence clearly stating the **general problem** being addressed by  this particular study.
  
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  
  One or two sentences to put the results into a more **general context**.
  
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "keywords"
wordcount         : "X"

bibliography: meta.bib
csl: journal-of-medical-internet-research.csl

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf

header-includes:
  - \raggedbottom
  - \usepackage{booktabs}
  - \definecolor{lightred}{rgb}{1.0, 0.6, 0.6}
  
knit: (function(input, ...) {
    rmarkdown::render(
      input,
      output_dir = dplyr::if_else(Sys.info()[["sysname"]] == "Windows",
      "P:/studydata/risk/manuscripts/meta/fyp", 
      "/Volumes/private/studydata/risk/manuscripts/meta/fyp")
    )
  })
---

Packages for lab workflow 
```{r, packages_workflow, message=FALSE, warning=FALSE}

library(conflicted) # detect and warn about function conflicts
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")

library(here)  # establish project directory consistently as working directory
```

Absolute paths
```{r, paths}

switch (Sys.info()[['sysname']],
        # PC paths
        Windows = {
          path_study_start <- "P:/studydata/risk/data_processed/meta"
          path_results <- "P:/studydata/risk/chtc/meta/jobs/training/model_selection/output/results"},

        # IOS paths
        Darwin = {
          path_study_start <- "/Volumes/private/studydata/risk/data_processed/meta"
          path_results <- "/Volumes/private/studydata/risk/chtc/meta/jobs/training/model_selection/output/results"}
        )
```


Relative paths
```{r}
path_models <- "meta/ana_scripts/model_output"
path_meta <- "P:/studydata/risk/data_processed/meta"
path_shared <- "P:/studydata/risk/data_processed/shared"
```

Packages & Source
```{r setup, include = FALSE}
library("papaja")
library(tidyverse)
library(tidymodels)
library(vroom)
library(kableExtra)
library(lubridate)
library(ggplot2)
library(ggforce)
theme_set(theme_classic())
options(knitr.kable.NA = '')

source(here("meta/fun_meta.R"))
source(here("../lab_support/chtc/fun_chtc.R"))
source(here("../lab_support/print_kbl.R"))
```


<!--Vocabulary.  Lets keep adding to this!
grouped 10-fold cross validation(grouped 10-fold cv for short);  grouped 10-fold cross validation with 10 repeats (grouped 10x10-fold cv for short)

training sets, validation sets (this is what you use for performance), test set (you don't have one but you mention it so use this term).
At some point you talk about "fits" but you really are talking about balanced accuracy across 100 "validation sets"

model configuration  (you talk about best models but it really should be best model configuration).
You fit (or train; choose one term) model configurations in training sets to get models that can be used for prediction

model selection (which is technically selecting the "best" model configuration); model evaluation (which is technically evaluating the expected performance of the 
best model configuration)
-->

## Alcohol Use Disorder
Paragraph on harms/costs/frequency of AUD

Alcohol Use Disorder is a chronic relapsing disease [@rounsavilleLapseRelapseChasing2010; @scottPathwaysRelapsetreatmentrecoveryCycle2005]. People can relapse days, weeks, months, or even years after achieving abstinence [@witkiewitzLapsesFollowingAlcohol2008; @jinPredictorsRelapseLongterm1998; @anderssonRelapseInpatientSubstance2018; @millerHowEffectiveAlcoholism2001]. Lapses, an initial setback or slip, are often an early warning sign of relapse, a full return to previous drinking behavior [@witkiewitzRelapsePreventionAlcohol2004]. Studies show that lapses predict future lapses, with more frequent lapses resulting in increased chances of relapse [@rounsavilleLapseRelapseChasing2010]. Likewise, longer durations of abstinence is associated with decreased chances of lapse, suggesting the stability of a patient’s recovery itself as an important predictor of abstinence [@rounsavilleLapseRelapseChasing2010]. In fact, the most important predictor of relapse is whether the individual has already had a lapse during treatment [@hogstrombrandtPredictionSingleEpisodes1999]. This high correlation between an initial lapse and relapse is the abstinence violation effect, which states that people who internalize feelings of loss of control, guilt, and hopelessness after violating a self-imposed rule (i.e., abstinence) have a greater risk of relapse compared to those who view the lapse as external and controllable [@marlattRelapsePreventionAlcohol; @hogstrombrandtPredictionSingleEpisodes1999]. Thus, identifying when an initial lapse will occur is an important goal in preventing lapses, repeated lapses, and relapse. 

Like most mental health disorders, Alcohol Use Disorder can be characterized by fluctuations in affective and behavioral states that covary with the severity of the underlying disorder and impact its treatment. The ability to detect these changes offers the opportunity to selectively deliver different interventions to patients that match their needs in that moment.  For example, during periods of stability, patients in recovery from Alcohol Use Disorder might benefit from interventions that help them modify their social network and daily activities to include more time with family and friends who support their recovery. In contrast, during times of peak stress and associated alcohol craving, they might need focused interventions that prevent an imminent lapse back to alcohol use. 

## Lapse Risk Factors
Lapses may seem to come out of nowhere, but they are often preceded by changes in cognitive (e.g., negative affect, craving), situational (e.g., lack of social support, risky situations), and behavioral (e.g., decreased social interactions, coping strategies) factors [@rounsavilleLapseRelapseChasing2010; @jinPredictorsRelapseLongterm1998; @anderssonRelapseInpatientSubstance2018]. 

These risk factors are known as proximal risk factors that are fluid and change over time (much like how mental health disorder symptoms can ebb and flow through periods of stability and periods of lapse) [@rounsavilleLapseRelapseChasing2010; @witkiewitzLapsesFollowingAlcohol2008]. Proximal risk factors contrast distal risk factors - stable states or traits that contribute to a mental health disorder, but do not change much over time. For example, one’s genetic makeup, the presence of co-occurring psychopathology, or Alcohol Use Disorder severity may contribute to whether one is predisposed to Alcohol Use Disorder, but they are less involved in the cyclical nature of lapses [@huffordRelapseNonlinearDynamic2003]. On the other hand, fluctuations in proximal factors often precipitate a lapse [@witkiewitzRelapsePreventionAlcohol2004; @chihPredictiveModelingAddiction2014; @larimerRelapsePrevention1999]. But due to the dynamic nature of these factors, traditional treatments (e.g., monthly therapy or counseling sessions) may not be best suited for monitoring for changes in lapse risk. 

Not all proximal risk factors are detectable within the same time window. Situational factors, such as passing a bar or being around people who are drinking may immediately precede a lapse. Other stressors, such as getting upsetting news from a family member or increased financial strain, may slowly increase lapse risk over hours, days or weeks. Thus, a system for continuously monitoring a person's lapse risk is critical in detecting when someone will lapse. 

## Personal Sensing
With new advances in technology, we can now accomplish this through personal sensing, a longitudinal in situ measurement approach for collecting data via smartphone sensors, logs, and social media apps [@mohrPersonalSensingUnderstanding2017]. That is we can harness personal sensing data to capture fluctuations in lapse risk in real time.

Active-passive continuum (to support logs as being low burden).

GPS and EMA studies (GPS may detect immediate risk factors and EMA is active).

## Cellular Communication Logs
One understudied personal sensing method in the lapse risk literature is cellular communication logs. 

Cellular communication logs are both passive and they have the potential to capture risk factors on varying timetables. We may be able to capture immediate risk based on who someone is calling or what time of day it is. Additionally, slower acting risk indicators may also be detected. Decreased interactions may signify isolation common with depressive symptoms, reaching out to people in one’s social network could signify a positive coping strategy, or changes in patterns between a single person in one’s social network could indicate conflict [@millerHowEffectiveAlcoholism2001; @huffordRelapseNonlinearDynamic2003; @chihPredictiveModelingAddiction2014].

Not only does it have potential predictive power, but it also appears to be a feasible source of personal sensing data. In a smartphone-based sensing platform the primary expense on the individual is the smartphone. Smartphone usage is already widespread. Eighty-five percent of US adults have a smartphone and this number is consistent across all sociodemographic groups, including those in recovery programs for substance use [@pewresearchcenterMobileFactSheet2021; @massonHealthrelatedInternetUse2019]. 

Additionally, people generally find personal sensing of cellular communication logs to be acceptable (cite Burden). 

## Social Context
Many proximal lapse predictors are inherently social [@hunter-reelEmphasizingInterpersonalFactors2009]. For example, decreased interactions may signify isolation common with depressive symptoms, reaching out to people in one’s social network could signify a positive coping strategy, or changes in patterns between a single person in one’s social network could indicate conflict. Accordingly, these factors are intrinsically linked to social interactions [@hunter-reelEmphasizingInterpersonalFactors2009; @witkiewitzEmphasisInterpersonalFactors2005; @stantonRelapsePreventionNeeds2005].

On its own, the nature of people’s social interactions with others appears to be a salient factor relevant to lapse risk. Positive social interaction has been associated with positive alcohol treatment outcomes [@grohFriendsFamilyAlcohol2010; @kellyRoleAlcoholicsAnonymous2012; @zywiakDecomposingRelationshipsPretreatment2002; @longabaughNetworkSupportPrognostic2010]. It is thought that the social component of self-help groups like Alcoholics Anonymous (i.e., increasing pro-abstinence relationship ties) play a major contributing role in their efficacy [@kellyRoleAlcoholicsAnonymous2012; @grohSocialNetworkVariables2008; @woffServiceProvidersPerceptions1996; @humphreysEnhancedFriendshipNetworks1999]. The buffering hypothesis of social support suggests that social relationships may buffer individuals against the negative effects of stress by providing a source of resources to promote adaptive responses to stress [@cohenStressSocialSupport; @holt-lunstadSocialRelationshipsMortality2010]. With stress being an often-cited precipitant of alcohol lapse, it is likely these buffering effects extrapolate to lapse risk [@fronkStressAllostasisSubstance2020]. 

There is also much literature on the importance of social network influences on drinking behavior [@hunter-reelEmphasizingInterpersonalFactors2009; @alvarezSocialNetworkHeavy2021]. A social network made up of heavy drinkers or abstainers can ultimately influence one’s recovery towards maintaining abstinence or lapsing [@alvarezSocialNetworkHeavy2021; @gordonSocialNetworksRecovery1991; @mohrGettingGettingHigh2001]. Individuals in recovery who maintain interactions with people who do not support their recovery is associated with decreased likelihood of maintaining abstinence. Social interactions with negative peer influences (e.g., heavy drinkers) may have more of an effect on treatment outcome than positive peer influences (e.g., abstainers) [@alvarezSocialNetworkHeavy2021]. This relationship between social support and lapses is robust and extends to substances other than alcohol [@havassySocialSupportRelapse1991]. 

Since many social interactions occur or are planned over the phone, cellular communication logs offer insight into patterns of social interaction. We know that social relationships are dynamic [@hidalgoDynamicsMobilePhone2008; @sekaraFundamentalStructuresDynamic2016; @saramakiSecondsMonthsOverview2015; @kossinetsEmpiricalAnalysisEvolving2006]. So, with time-stamped logs there is potential to build a sensing system that tracks how these interactions fluctuate over time. For example, changes in their top contacts (i.e., who they are interacting with the most) or changes in patterns of activities (e.g., is an individual is consistently ignoring phone calls from a contact they normally interact often with?). 

However, these communications may become much more powerful when they are contextualized (e.g., pleasantness of interactions with the contact, whether the contact is supportive of their recovery, drinking history with contact).  For example, context in concert with communication logs can tell us that someone is ignoring phone calls from a former drinking buddy or that their top contacts have recently shifted to include only people supportive of their recovery. So, we can imagine that providing this social context to cellular communication logs could greatly increase the predictive signal. Take one more example - an outgoing phone call late at night might be related to lapse risk, but the direction will be very different if they are calling their sponsor vs. a former drinking buddy.

## Present Study
- Build a personal sensing system to predict lapse risk from contextualized cellular communication logs (extend our current understanding of distal risk factors by identifying additional proximal risk factors).
- Evaluate the incremental contribution to the sensitivity of this sensing system provided by measures of contextual information regarding the people with whom the participant is communicating (e.g., pleasantness of interactions with the contact, whether the contact is supportive of their recovery, drinking history with contact).
- Evaluate the importance of feature sets within the top performing model to inform potential in situ treatments. 


# Method
This project performs the initial analyses on a subset of data collected from 2017 – 2019 as part of a larger grant funded through the National Institute of Alcohol Abuse and Alcoholism (R01 AA024391). A full list of measures used in the parent project can be found at <https://osf.io/brs68/>.

## Research Transparency
We value the principles of research transparency that are essential to the robustness and reproducibility of science [@schonbrodtVoluntaryCommitmentResearch2015]. Consequently, we maximized transparency by reporting all data exclusions, manipulations, and available measures in the study [@simmons21WordSolution2012]. We also made the data, analysis scripts and annotated results, self-report surveys, and other study materials associated with this study publicly available [<https://osf.io/brs68/>].

## Participants
We recruited a community sample of people in initial stages of recovery for Alcohol Use Disorder from the Madison area. Avenues of recruitment included referrals from clinics, self-help groups, Facebook, radio, and television. Those who were interested in participating in our three-month study were given a brief description (i.e., told that our research focused on learning how mobile health technology can be used to provide individual support to anyone recovering from alcohol addiction) a short phone screen to determine initial eligibility (i.e., At least 18 years old, ability to read and write in English, and an eligible smartphone with existing cellphone plan).

Two hundred sixteen participants passed the initial phone screen and came in for a more in-depth screening session. Of the 216 interested participants, 199 enrolled in the study (i.e., they consented and were eligible to participate). We excluded potential participants if they did not meet the criteria for moderate or severe Alcohol Use Disorder (as defined by the DSM-5), did not have a goal of long-term abstinence, had not abstained from alcohol for at least one week, already had over two months of abstinence, or had severe symptoms of psychosis or paranoia. Of the 199 participants enrolled in the study, 154 provided at least one month of communications logs and EMA surveys. This was an additional requirement for the current study because cellphone communications were collected at each one month follow-up. We dropped data from three participants due to concerns quality of their data. Our final analyses were on a sample of 151 participants. 

<!-- KW: Discuss with JC if we want to use this figure. If so I will add a Figure label and caption -->

![](C:/Users/kpaquette2/analysis_risk1/meta/ana_scripts/figures/fig_disposition.png)




## Procedure
Our study involved five in-person visits (screening, enrollment, and three follow-up visits). It also required completion of daily EMA surveys to document alcohol lapses, and access to non-deleted text message and call logs (i.e., cellular communication logs). All procedures were approved by the University of Wisconsin-Madison Institutional Review Board.

During the screening session we obtained informed consent, determined eligibility, and documented demographic information, history of lifetime drug and alcohol use, and mental health traits. Participants that consented and were deemed eligible came back for a second enrollment visit. During enrollment, participants were briefed on how to delete log entries they did not want to share with us and completed a practice EMA survey. Participants also reported contacts they frequently communicated with and answered a series of questions documenting context information about their interactions with each contact (type of relationship with contact, whether they drank with contact in past, drinking status of contact, whether contact would drink in their presence, whether the contact is in recovery, the level of supportiveness the contact provides, and the pleasantness of their interactions with the contact). Participants returned for three follow-up visits, each one month apart. 

At each follow-up visit, we downloaded participants' cellular communication logs. These communication logs included the phone number of the other party, whether the call or message was incoming or outgoing, the duration of the call, and the date and time of the call or message. Participants also provided context information for newly identified frequent contacts (i.e., at least two communications in the past month). At the third follow-up visit, participants were debriefed and thanked for their participation. 

## Feature Engineering and Model Training
<!--have a section that describes how you did feature engineering.  This is separate from the data analysis plan or at least a sub section of that plan.  It can be short but talk about how you calculated raw and  percent change. How you used different windows of data preceding the lapse, and how you combined this with context.  You might also describe some of the pre-processing that you did to the phone numbers if you want to.  Not needed but will give them a window into how much data processing is needed for a project like this-->

<!-- Still working on this section -->
We used various feature engineering methods to build groups of feature sets to maximize model performance. A key distinction between features was to discriminate between features derived from passive only measures (i.e., communication logs) and those derived from more active measures (i.e., context information).    
- resampling - considered 3 methods to address unbalanced labels - down, up, and Synthetic Minority Over-sampling Technique (SMOTE) which produces new synthetic positive cases. Resampling was not done to held-out validation sets.   
- perc vs raw features

## Data Analysis Plan

We conducted all analyses in R version 4.0.3 [@rcoreteamLanguageEnvironmentStatistical2021] using RStudio [@rstudioteamRStudioIntegratedDevelopment2020a] and the tidyverse and tidymodels ecosystem of packages [@wickhamWelcomeTidyverse2019; @kuhnTidymodelsCollectionPackages2020]. 

We will characterize our sample of participants across standard demographics (age, sex, race, ethnicity, income, education level, employment status, and marital status). We will also characterize our participants according to life history of drug and alcohol use. This includes alcohol use disorder milestones (age of first drink, age of regular drinking, age of problematic drinking, age of first quit attempt), number of quit attempts, average number of days spent drinking prior to quitting, treatment history for alcohol use disorder (long-term residential, short-term residential, outpatient, individual counseling, group counseling, self-help groups), whether they have received medication for alcohol use disorder, the number of DSM-5 criteria for alcohol use disorder reported, number and types of drugs used over their lifetime, and whether they have ever injected drugs. Finally we will characterize various mental health traits of our participants using validated measures such as the Symptom Checklist-90 [@derogatisSCL90OutpatientPsychiatric1973], Intolerance of Uncertainty Scale [@freestonWhyPeopleWorry1994], Anxiety Sensitivity Index-3 [@taylorRobustDimensionsAnxiety2007], Distress Tolerance Scale [@simonsDistressToleranceScale2005], McMaster Family Assessment Device [@millerMcMasterFamilyAssessment1985], and the Multidimensional Personality Questionnaire Short Form [@patrickDevelopmentValidationBrief2002. 

<!--JJC: I dont think you need the secondary measures beyond demographics and alcohol use disorder measuures.  If you made those tables, fine to keep them but if not, dont do DTS, McMaser, MPQ etc.  not really that relevant-->

Our first study aim was to train and evaluate the best performing machine learning model to predict alcohol lapse onset from contextualized cellular communication data. We built, trained, and evaluated models with several statistical learning algorithms including penalized parametric linear classification algorithms (LASSO, ridge regression, glmnet), non-parametric classification algorithms (k nearest neighbor), and ensemble methods (random forest). Candidate statistical learning algorithms were trained on a subset of the data (i.e.., training sets) using combinations of features derived from participants cellular communications and context information.

Balanced accuracy was our performance metric for both model selection and evaluation.  However, during model evaluation we also report other performance metrics (sensitivity, specificity, positive predictive value, negative predictive value) to fully characterize the performance of our best model configuration. We also visually inspected lapse probability predictions by participant to further probe model performance.

During model selection, we used grouped 10-fold cross-validation (grouped 10X cv) without repeats (i.e, 1 set of 10 grouped folds). We selected the top performing model configuration (statistical algorithm and combination of features) according to highest balanced accuracy. All cross-validation folds were grouped by participant ID so that a single participant's data were not being used to predict future data on the same participant. In other words, all data from a participant was either included in the training or held-out validation set, but not both.  

We evaluated our top performing model configuration using grouped 10-fold cross validation with 10 repeats (grouped 10x10-fold cv). We opted to use resampling for model evaluation instead of an independent held-out test set because, with our limited sample size, averaging balanced accuracy over 100 held-out validation sets gives us a more stable (i.e., low variance) and less biased estimate of model performance than other available options using a single test set. 

Finally, we used a Bayesian correlated t-test <!--JJC: include citation for this method--> to compare our top model configuration's balanced accuracy across the 100 validation sets to the expected performance of a null model with no predictive signal(i.e., balanced accuracy = .50). In this analysis, we defined a meaningful difference to be more than a difference of 1% in either direction (i.e., Region of Practical Equivalence [ROPE] set to .49 - .51).

Our study's second aim was to compare the best model configuration using all available features from both passive signals from communications logs and actively measured context (i.e., active) with the best model configuration restricted to only passive signals (i.e., passive). To do this we employed a model comparison approach. Our top passive and active model configurations were selected using grouped 10-fold cv and then evaluated using grouped 10x10-fold cv. We then used a Bayesian correlated t-test to compare balanced accuracy from each of the 100 validation sets of our top active model configuration with our top passive model configuration. We defined a meaningful difference between model configurations to be more than a 1% difference in either direction (i.e., ROPE set to -.01 - .01). Through this relative comparison, we quantified any performance benefit from adding features based on the the active component of context. 

Our third aim of the present study was to evaluate the importance of features within the top performing model configuration. The most predictive features were identified based on an algorithm agnostic feature importance index. This approach involves permuting each individual feature to determine how much predictive signal was lost when removed from the model. 



# Results

<!--Notes on table placement
https://stackoverflow.com/questions/67685449/hold-apa-table-position-in-rmarkdown-papaja
http://frederikaust.com/papaja_man/reporting.html#tables
-->

```{r}
# individual results
results_all <- read_rds(here(path_models, "results_all.rds"))


# aggregate results
results_aggregate <- vroom(here(path_models, "results_aggregate.csv"), 
                                  col_types = vroom::cols()) 

# best model
best_model <- results_aggregate %>% 
  slice_max(bal_accuracy)
```

## Participant Characteristics

Participants were on study for an average of 85 days out of the possible 90 days. All participants provided at least one month of data. Table 1 shows the demographic breakdown for the 151 participants used in our analyses. The majority of participants identified as white (86.8%). Just over half of participants identified as male (51%) and 49% identified as female. Table 2 shows the relevant drug and alcohol history for these participants and table 3 characterizes our participants mental health. Participants had endorsed using on average 4 other types of drugs (not including alcohol) over their lifetime. Additionally, participants on average scored a 9 on a self-report version of the DSM-5 criteria for alcohol use disorder. Generally, scores of 2+ symptoms are considered mild, 4+ symptoms moderate, and 6+ symptoms severe alcohol use disorder.  

On average participants had about 32 contacts (SD = 22) they frequently communicated with. Figures 1 - 6 show the distribution of participant responses about their frequent contacts to each of our six context questions. Seventy-two percent of our participants (*N* = 109) have at least one person they frequently communicate with who they used to drink with regularly (always/almost always). Additionally, 99% of our participants (*N* = 150) regularly communicate with at least one person they know to be a drinker. In fact, each participant communicate with on average 18 people (*M* = 17.7, *SD* = 15.0) who are known drinkers and 95% of participants (*N* = 143) said that at least one of these contacts are likely to drink in front of them in the future. On the recovery-positive side of these communications, 99% of participants (*N* = 149) have a supportive contact they frequently communicate with and 80% (*N* = 120) have regular communications with someone else in recovery. Finally, on average across participants, 75% of communications (*SD* = .17) were reported to be pleasant.   


```{r}
# Demographics Table
study_dates <- vroom::vroom(here(path_meta, "study_dates.csv"), col_types = vroom::cols()) %>% 
  mutate(across(study_start:ema_end, ~with_tz(., tzone = "America/Chicago"))) 
data_id <- vroom::vroom(here(path_meta, "static_features.csv"), col_types = vroom::cols()) %>%
  mutate(id_quit_date = with_tz(id_quit_date, tzone = "America/Chicago")) 

data_id %>% 
  summarise(mean = as.character(round(mean(id_age, na.rm = TRUE), 1)),
            SD = as.character(round(sd(id_age, na.rm = TRUE), 1))) %>% 
  mutate(var = "Age",
         n = as.numeric(""),
         perc = as.numeric("")) %>% 
  select(var, n, perc, everything()) %>% 
  full_join(data_id %>% 
  select(var = id_gender) %>% 
  group_by(var) %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / sum(n)) * 100), by = c("var", "n", "perc")) %>% 
  full_join(data_id %>% 
  select(var = id_race) %>% 
  mutate(var = fct_relevel(factor(var, 
                         c("American Indian/Alaska Native", "Asian", "Black/African American",
                           "White/Caucasian", "Other/Multiracial")))) %>%
  group_by(var) %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / sum(n)) * 100), by = c("var", "n", "perc")) %>% 
  full_join(data_id %>% 
  select(var = id_hispanic) %>% 
  mutate(var = case_when(var == "no" ~ "No",
                         TRUE ~ "Yes"),
         var = fct_relevel(factor(var, c("Yes", "No")))) %>% 
  group_by(var) %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / sum(n)) * 100), by = c("var", "n", "perc")) %>% 
  full_join(data_id %>% 
  select(var = id_education) %>% 
  mutate(var = fct_relevel(factor(var, 
                         c("Less than high school or GED degree", "High school or GED", 
                           "Some college", "2-Year degree", "College degree", "Advanced degree")))) %>%
  group_by(var) %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / sum(n)) * 100), by = c("var", "n", "perc")) %>% 
  full_join(data_id %>% 
  select(var = id_employment) %>% 
  mutate(var = fct_relevel(factor(var, 
                         c("Full-time", "Part-time", "Full-time student",
                           "Homemaker", "Disabled", "Retired", "Unemployed", 
                           "Temporarily laid off, sick leave, or maternity leave",
                           "Other, not otherwise specified")))) %>%
  group_by(var) %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / sum(n)) * 100), by = c("var", "n", "perc")) %>% 
  full_join(data_id %>% 
  summarise(mean = as.character(round(mean(id_income, na.rm = TRUE), 0)),
            SD = as.character(round(sd(id_income, na.rm = TRUE), 0))) %>% 
  mutate(var = "Income",
        n = as.numeric(""),
        perc = as.numeric("")) %>% 
  select(var, n, perc, everything()), by = c("var", "n", "perc", "mean", "SD")) %>% 
  full_join(data_id %>% 
  select(var = id_marrital_status) %>% 
  mutate(var = fct_relevel(factor(var, 
                         c("Never Married", "Married", "Divorced", "Separated",
                           "Widowed")))) %>%
  group_by(var) %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / sum(n)) * 100), by = c("var", "n", "perc")) %>% 
  kbl(booktabs = TRUE,
      caption = "Demographics",
      col.names = c("", "n", "%", "M", "SD"),
      align = c("l", "c", "c", "c", "c"),
      digits = 1,
      longtable = TRUE) %>% 
  kable_styling() %>% 
  row_spec(row = 0, align = "c", italic = TRUE) %>% 
  pack_rows("Sex", 2, 3, bold = FALSE) %>% 
  pack_rows("Race", 4, 8, bold = FALSE) %>%
  pack_rows("Hispanic, Latino, or Spanish Origin", 9, 10, bold = FALSE) %>%
  pack_rows("Education", 11, 16, bold = FALSE) %>%
  pack_rows("Employment", 17, 25, bold = FALSE) %>%
  pack_rows("Marital Status", 27, 31, bold = FALSE) %>% 
  footnote("N = 151")
```

```{r}
# drug and alcohol characteristics
 data_id %>%
  summarise(mean = mean(id_age_first_drank, na.rm = TRUE),
            SD = sd(id_age_first_drank, na.rm = TRUE)) %>%
  mutate(var = "Age of first drink",
        n = as.numeric(""),
        perc = as.numeric("")) %>%
  select(var, n, perc, everything()) %>%
  full_join(data_id %>%
  summarise(mean = mean(id_age_drank_regularly, na.rm = TRUE),
            SD = sd(id_age_drank_regularly, na.rm = TRUE)) %>%
  mutate(var = "Age of regular drinking",
        n = as.numeric(""),
        perc = as.numeric("")) %>%
  select(var, n, perc, everything()), by = c("var", "n", "perc", "mean", "SD")) %>%
  full_join(data_id %>%
  summarise(mean = mean(id_age_believed_drinking_was_problem, na.rm = TRUE),
            SD = sd(id_age_believed_drinking_was_problem, na.rm = TRUE)) %>%
  mutate(var = "Age at which drinking became problematic",
        n = as.numeric(""),
        perc = as.numeric("")) %>%
  select(var, n, perc, everything()), by = c("var", "n", "perc", "mean", "SD")) %>%
  full_join(data_id %>%
  summarise(mean = mean(id_age_first_quit_drinking, na.rm = TRUE),
            SD = sd(id_age_first_quit_drinking, na.rm = TRUE)) %>%
  mutate(var = "Age of first quit attempt",
        n = as.numeric(""),
        perc = as.numeric("")) %>%
  select(var, n, perc, everything()), by = c("var", "n", "perc", "mean", "SD")) %>%
  full_join(data_id %>%
  summarise(mean = mean(id_number_quit_attempts, na.rm = TRUE),
            SD = sd(id_number_quit_attempts, na.rm = TRUE)) %>%
  mutate(var = "Number of Quit Attempts",
        n = as.numeric(""),
        perc = as.numeric("")) %>%
  select(var, n, perc, everything()), by = c("var", "n", "perc", "mean", "SD")) %>%
  full_join(data_id %>%
  summarise(mean = mean(id_days_per_week_drank_6_mos_before_quit, na.rm = TRUE),
            SD = sd(id_days_per_week_drank_6_mos_before_quit, na.rm = TRUE)) %>%
  mutate(var = "Days (per week) Drinking 6 Mos Before Quit Date",
        n = as.numeric(""),
        perc = as.numeric("")) %>%
  select(var, n, perc, everything()), by = c("var", "n", "perc", "mean", "SD")) %>%
  full_join(data_id %>%
  select(var = id_tx_long_term_residential) %>%
  mutate(var = case_when(var == "yes" ~ "Long-term residential (6+ mos.)",
                         TRUE ~ as.character(NA))) %>%
  group_by(var) %>%
  drop_na() %>%
  summarise(n = n()) %>%
  mutate(perc = (n / 151) * 100), by = c("var", "n", "perc")) %>%
  full_join(data_id %>%
  select(var = id_tx_short_term_residential) %>%
  mutate(var = case_when(var == "yes" ~ "Short-term residential (< 6 mos.)",
                         TRUE ~ as.character(NA))) %>%
  group_by(var) %>%
  drop_na() %>%
  summarise(n = n()) %>%
  mutate(perc = (n / 151) * 100), by = c("var", "n", "perc")) %>%
  full_join(data_id %>%
  select(var = id_tx_outpatient) %>%
  mutate(var = case_when(var == "yes" ~ "Outpatient",
                         TRUE ~ as.character(NA))) %>%
  group_by(var) %>%
  drop_na() %>%
  summarise(n = n()) %>%
  mutate(perc = (n / 151) * 100), by = c("var", "n", "perc")) %>%
  full_join(data_id %>%
  select(var = id_tx_indiv_counseling) %>%
  mutate(var = case_when(var == "yes" ~ "Individual counseling",
                         TRUE ~ as.character(NA))) %>%
  group_by(var) %>%
  drop_na() %>%
  summarise(n = n()) %>%
  mutate(perc = (n / 151) * 100), by = c("var", "n", "perc")) %>%
  full_join(data_id %>%
  select(var = id_tx_group_counseling) %>%
  mutate(var = case_when(var == "yes" ~ "Group counseling",
                         TRUE ~ as.character(NA))) %>%
  group_by(var) %>%
  drop_na() %>%
  summarise(n = n()) %>%
  mutate(perc = (n / 151) * 100), by = c("var", "n", "perc")) %>%
  full_join(data_id %>%
  select(var = id_tx_aa_or_na) %>%
  mutate(var = case_when(var == "yes" ~ "Alcoholics Anonymous/Narcotics Anonymous",
                         TRUE ~ as.character(NA))) %>%
  group_by(var) %>%
  drop_na() %>%
  summarise(n = n()) %>%
  mutate(perc = (n / 151) * 100), by = c("var", "n", "perc")) %>%
  full_join(data_id %>%
  select(var = id_tx_other) %>%
  mutate(var = case_when(var == "yes" ~ "Other",
                         TRUE ~ as.character(NA))) %>%
  group_by(var) %>%
  drop_na() %>%
  summarise(n = n()) %>%
  mutate(perc = (n / 151) * 100), by = c("var", "n", "perc")) %>%
  full_join(data_id %>%
  select(var = id_aud_medication) %>%
  mutate(var = fct_relevel(factor(var, c("Yes", "No")))) %>%
  group_by(var) %>%
  summarise(n = n()) %>%
  mutate(perc = (n / sum(n)) * 100), by = c("var", "n", "perc")) %>%
  full_join(data_id %>%
  select(id_dsm5_total) %>% 
  summarise(mean = mean(id_dsm5_total),
            SD = sd(id_dsm5_total)) %>%
  mutate(var = "AUD DSM-5 Symptom Count",
        n = as.numeric(""),
        perc = as.numeric("")) %>%
  select(var, n, perc, everything()), by = c("var", "n", "perc", "mean", "SD")) %>%
  full_join(data_id %>%
  select(var = id_lifetime_use_tobacco) %>%
  mutate(var = case_when(var == 1 ~ "Tobacco products (cigarettes, chewing tobacco, cigars, etc.)",
                         TRUE ~ as.character(NA))) %>%
  group_by(var) %>%
  drop_na() %>%
  summarise(n = n()) %>%
  mutate(perc = (n / 151) * 100), by = c("var", "n", "perc")) %>%
  full_join(data_id %>%
  select(var = id_lifetime_use_cannabis) %>%
  mutate(var = case_when(var == 1 ~ "Cannabis (marijuana, pot, grass, hash, etc.)",
                         TRUE ~ as.character(NA))) %>%
  group_by(var) %>%
  drop_na() %>%
  summarise(n = n()) %>%
  mutate(perc = (n / 151) * 100), by = c("var", "n", "perc")) %>%
  full_join(data_id %>%
  select(var = id_lifetime_use_cocaine) %>%
  mutate(var = case_when(var == 1 ~ "Cocaine (coke, crack, etc.)",
                         TRUE ~ as.character(NA))) %>%
  group_by(var) %>%
  drop_na() %>%
  summarise(n = n()) %>%
  mutate(perc = (n / 151) * 100), by = c("var", "n", "perc")) %>%
  full_join(data_id %>%
  select(var = id_lifetime_use_amphetamine) %>%
  mutate(var = case_when(var == 1 ~ "Amphetamine type stimulants (speed, diet pills, ecstasy, etc.)",
                         TRUE ~ as.character(NA))) %>%
  group_by(var) %>%
  drop_na() %>%
  summarise(n = n()) %>%
  mutate(perc = (n / 151) * 100), by = c("var", "n", "perc")) %>%
  full_join(data_id %>%
  select(var = id_lifetime_use_inhalant) %>%
  mutate(var = case_when(var == 1 ~ "Inhalants (nitrous, glue, petrol, paint thinner, etc.)",
                         TRUE ~ as.character(NA))) %>%
  group_by(var) %>%
  drop_na() %>%
  summarise(n = n()) %>%
  mutate(perc = (n / 151) * 100), by = c("var", "n", "perc")) %>%
  full_join(data_id %>%
  select(var = id_lifetime_use_sedative) %>%
  mutate(var = case_when(var == 1 ~ "Sedatives or sleeping pills (Valium, Serepax, Rohypnol, etc.)",
                         TRUE ~ as.character(NA))) %>%
  group_by(var) %>%
  drop_na() %>%
  summarise(n = n()) %>%
  mutate(perc = (n / 151) * 100), by = c("var", "n", "perc")) %>%
  full_join(data_id %>%
  select(var = id_lifetime_use_hallucinogen) %>%
  mutate(var = case_when(var == 1 ~ "Hallucinogens (LSD, acid, mushrooms, PCP, Special K, etc.)",
                         TRUE ~ as.character(NA))) %>%
  group_by(var) %>%
  drop_na() %>%
  summarise(n = n()) %>%
  mutate(perc = (n / 151) * 100), by = c("var", "n", "perc")) %>%
  full_join(data_id %>%
  select(var = id_lifetime_use_opioid) %>%
  mutate(var = case_when(var == 1 ~ "Opioids (heroin, morphine, methadone, codeine, etc.)",
                         TRUE ~ as.character(NA))) %>%
  group_by(var) %>%
  drop_na() %>%
  summarise(n = n()) %>%
  mutate(perc = (n / 151) * 100), by = c("var", "n", "perc")) %>% 
  full_join(data_id %>% 
  select(id_lifetime_n_drugs_endorsed) %>% 
  summarise(mean = mean(id_lifetime_n_drugs_endorsed),
            SD = sd(id_lifetime_n_drugs_endorsed)) %>%
  mutate(var = "Lifetime Drugs Endorsed",
        n = as.numeric(""),
        perc = as.numeric("")) %>%
  select(var, n, perc, everything()), by = c("var", "n", "perc", "mean", "SD")) %>% 
  full_join(data_id %>%
  select(var = id_lifetime_drug_injection) %>%
  mutate(var = if_else(var == "No, never", "No", "Yes")) %>% 
  mutate(var = fct_relevel(factor(var, c("Yes", "No")))) %>%
  group_by(var) %>%
  summarise(n = n()) %>%
  mutate(perc = (n / sum(n)) * 100), by = c("var", "n", "perc")) %>% 
  kbl(booktabs = TRUE,
      caption = "History of Lifetime Drug and Alcohol Use",
      col.names = c("", "n", "%", "M", "SD"),
      align = c("l", "c", "c", "c", "c"),
      digits = 1,
      longtable = TRUE) %>% 
  kable_styling() %>% 
  row_spec(row = 0, align = "c", italic = TRUE) %>% 
  pack_rows("AUD Milestones", 1, 4, bold = FALSE) %>%
  pack_rows("Types of Treatment (Can choose more than 1)", 7, 13, bold = FALSE) %>%
  pack_rows("Received Medication for AUD", 14, 15, bold = FALSE) %>%
  pack_rows("Lifetime Drug Use", 17, 24, bold = FALSE) %>%
  pack_rows("Lifetime Drug Injection", 26, 27, bold = FALSE) %>% 
  footnote("N = 151")
```

```{r}
# mental health characteristics
data_id %>% 
  select(id_scl90_total) %>% 
  summarise(mean = mean(id_scl90_total),
            SD = sd(id_scl90_total)) %>%
  mutate(var = "Total Score") %>%
  select(var, everything()) %>% 
  full_join(data_id %>% 
  select(id_scl90_somatization) %>% 
  summarise(mean = mean(id_scl90_somatization),
            SD = sd(id_scl90_somatization)) %>%
  mutate(var = "Somatization Subscale") %>%
  select(var, everything()), by = c("var", "mean", "SD")) %>% 
  full_join(data_id %>% 
  select(id_scl90_obsess_compuls) %>% 
  summarise(mean = mean(id_scl90_obsess_compuls),
            SD = sd(id_scl90_obsess_compuls)) %>%
  mutate(var = "Obsessive-compulsive Subscale") %>%
  select(var, everything()), by = c("var",  "mean", "SD")) %>% 
  full_join(data_id %>% 
  select(id_scl90_interpers_sensibility) %>% 
  summarise(mean = mean(id_scl90_interpers_sensibility),
            SD = sd(id_scl90_interpers_sensibility)) %>%
  mutate(var = "Interpersonal Sensibility Subscale") %>%
  select(var, everything()), by = c("var", "mean", "SD")) %>% 
  full_join(data_id %>% 
  select(id_scl90_depression) %>% 
  summarise(mean = mean(id_scl90_depression),
            SD = sd(id_scl90_depression)) %>%
  mutate(var = "Depression Subscale") %>%
  select(var, everything()), by = c("var", "mean", "SD")) %>% 
  full_join(data_id %>% 
  select(id_scl90_anxiety) %>% 
  summarise(mean = mean(id_scl90_anxiety),
            SD = sd(id_scl90_anxiety)) %>%
  mutate(var = "Anxiety Subscale") %>%
  select(var, everything()), by = c("var", "mean", "SD")) %>% 
  full_join(data_id %>% 
  select(id_scl90_anger_hostility) %>% 
  summarise(mean = mean(id_scl90_anger_hostility),
            SD = sd(id_scl90_anger_hostility)) %>%
  mutate(var = "Anger-hostility Subscale") %>%
  select(var, everything()), by = c("var", "mean", "SD")) %>% 
  full_join(data_id %>% 
  select(id_scl90_phobic_anxiety) %>% 
  summarise(mean = mean(id_scl90_phobic_anxiety),
            SD = sd(id_scl90_phobic_anxiety)) %>%
  mutate(var = "Phobic-anxiety Subscale") %>%
  select(var, everything()), by = c("var",  "mean", "SD")) %>% 
  full_join(data_id %>% 
  select(id_scl90_somatization) %>% 
  summarise(mean = mean(id_scl90_somatization),
            SD = sd(id_scl90_somatization)) %>%
  mutate(var = "Somatization Subscale") %>%
  select(var, everything()), by = c("var", "mean", "SD")) %>% 
  full_join(data_id %>% 
  select(id_scl90_paranoid) %>% 
  summarise(mean = mean(id_scl90_paranoid),
            SD = sd(id_scl90_paranoid)) %>%
  mutate(var = "Paranoid Ideation Subscale") %>%
  select(var,everything()), by = c("var", "mean", "SD")) %>% 
  full_join(data_id %>% 
  select(id_scl90_psychoticism) %>% 
  summarise(mean = mean(id_scl90_psychoticism),
            SD = sd(id_scl90_psychoticism)) %>%
  mutate(var = "Psychoticism Subscale") %>%
  select(var, everything()), by = c("var", "mean", "SD")) %>% 
  full_join(data_id %>% 
  select(id_ius_total) %>% 
  summarise(mean = mean(id_ius_total),
            SD = sd(id_ius_total)) %>%
  mutate(var = "Intolerance of Uncertainty") %>%
  select(var, everything()), by = c("var", "mean", "SD")) %>% 
  full_join(data_id %>% 
  select(id_asi3_total) %>% 
  summarise(mean = mean(id_asi3_total),
            SD = sd(id_asi3_total)) %>%
  mutate(var = "Total Score") %>%
  select(var, everything()), by = c("var", "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_asi3_phys_concerns) %>% 
  summarise(mean = mean(id_asi3_phys_concerns),
            SD = sd(id_asi3_phys_concerns)) %>%
  mutate(var = "Physical Concerns Subscale") %>%
  select(var, everything()), by = c("var",  "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_asi3_cog_concerns) %>% 
  summarise(mean = mean(id_asi3_cog_concerns),
            SD = sd(id_asi3_cog_concerns)) %>%
  mutate(var = "Cognitive Concerns Subscale") %>%
  select(var, everything()), by = c("var", "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_asi3_soc_concerns) %>% 
  summarise(mean = mean(id_asi3_soc_concerns),
            SD = sd(id_asi3_soc_concerns)) %>%
  mutate(var = "Social Concerns Subscale") %>%
  select(var, everything()), by = c("var",  "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_dts_total) %>% 
  summarise(mean = mean(id_dts_total),
            SD = sd(id_dts_total)) %>%
  mutate(var = "Distress Tolerance Scale") %>%
  select(var, everything()), by = c("var",  "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_fad_prob_solving ) %>% 
  summarise(mean = mean(id_fad_prob_solving ),
            SD = sd(id_fad_prob_solving )) %>%
  mutate(var = "Problem Solving Subscale") %>%
  select(var, everything()), by = c("var",  "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_fad_communication) %>% 
  summarise(mean = mean(id_fad_communication),
            SD = sd(id_fad_communication)) %>%
  mutate(var = "Communications Subscale") %>%
  select(var, everything()), by = c("var", "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_fad_roles) %>% 
  summarise(mean = mean(id_fad_roles),
            SD = sd(id_fad_roles)) %>%
  mutate(var = "Roles Subscale") %>%
  select(var, everything()), by = c("var",  "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_fad_affective_resp) %>% 
  summarise(mean = mean(id_fad_affective_resp),
            SD = sd(id_fad_affective_resp)) %>%
  mutate(var = "Affective Responsiveness Subscale") %>%
  select(var, everything()), by = c("var", "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_fad_affective_involv) %>% 
  summarise(mean = mean(id_fad_affective_involv),
            SD = sd(id_fad_affective_involv)) %>%
  mutate(var = "Affective Involvement Subscale") %>%
  select(var, everything()), by = c("var",  "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_fad_behavior_control) %>% 
  summarise(mean = mean(id_fad_behavior_control),
            SD = sd(id_fad_behavior_control)) %>%
  mutate(var = "Behavior Control Subscale") %>%
  select(var,everything()), by = c("var", "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_fad_gen_functioning) %>% 
  summarise(mean = mean(id_fad_gen_functioning),
            SD = sd(id_fad_gen_functioning)) %>%
  mutate(var = "General Functioning Subscale") %>%
  select(var, everything()), by = c("var", "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_mps_wellbeing) %>% 
  summarise(mean = mean(id_mps_wellbeing),
            SD = sd(id_mps_wellbeing)) %>%
  mutate(var = "Wellbeing Subscale") %>%
  select(var, everything()), by = c("var", "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_mps_social_potency) %>% 
  summarise(mean = mean(id_mps_social_potency),
            SD = sd(id_mps_social_potency)) %>%
  mutate(var = "Social Potency Subscale") %>%
  select(var,everything()), by = c("var", "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_mps_achievement) %>% 
  summarise(mean = mean(id_mps_achievement),
            SD = sd(id_mps_achievement)) %>%
  mutate(var = "Achievement Subscale") %>%
  select(var, everything()), by = c("var",  "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_mps_social_closeness) %>% 
  summarise(mean = mean(id_mps_social_closeness),
            SD = sd(id_mps_social_closeness)) %>%
  mutate(var = "Social Closeness Subscale") %>%
  select(var, everything()), by = c("var", "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_mps_stress_reaction) %>% 
  summarise(mean = mean(id_mps_stress_reaction),
            SD = sd(id_mps_stress_reaction)) %>%
  mutate(var = "Stress Reaction Subscale") %>%
  select(var, everything()), by = c("var", "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_mps_alienation) %>% 
  summarise(mean = mean(id_mps_alienation),
            SD = sd(id_mps_alienation)) %>%
  mutate(var = "Alienation Subscale") %>%
  select(var, everything()), by = c("var", "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_mps_aggression) %>% 
  summarise(mean = mean(id_mps_aggression),
            SD = sd(id_mps_aggression)) %>%
  mutate(var = "Aggression Subscale") %>%
  select(var, everything()), by = c("var",  "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_mps_control) %>% 
  summarise(mean = mean(id_mps_control),
            SD = sd(id_mps_control)) %>%
  mutate(var = "Control Subscale") %>%
  select(var, everything()), by = c("var", "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_mps_harm_avoidance) %>% 
  summarise(mean = mean(id_mps_harm_avoidance),
            SD = sd(id_mps_harm_avoidance)) %>%
  mutate(var = "Harm Avoidance Subscale") %>%
  select(var, everything()), by = c("var",  "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_mps_traditionalism) %>% 
  summarise(mean = mean(id_mps_traditionalism),
            SD = sd(id_mps_traditionalism)) %>%
  mutate(var = "Traditionalism Subscale") %>%
  select(var, everything()), by = c("var", "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_mps_absorption ) %>% 
  summarise(mean = mean(id_mps_absorption ),
            SD = sd(id_mps_absorption )) %>%
  mutate(var = "Absorption Subscale") %>%
  select(var, everything()), by = c("var", "mean", "SD")) %>%
  full_join(data_id %>% 
  select(id_mps_unlikely_virtues) %>% 
  summarise(mean = mean(id_mps_unlikely_virtues),
            SD = sd(id_mps_unlikely_virtues)) %>%
  mutate(var = "Unlikely Virtues Subscale") %>%
  select(var, everything()), by = c("var", "mean", "SD")) %>%
   kbl(booktabs = TRUE,
      caption = "Mental Health Characterization",
      col.names = c("", "M", "SD"),
      align = c("l", "c", "c"),
      digits = 1,
      longtable = TRUE) %>% 
  kable_styling() %>% 
  row_spec(row = 0, align = "c", italic = TRUE) %>% 
  pack_rows("Symptom Checklist-90", 1, 10, bold = FALSE) %>%
  pack_rows("Anxiety Sensitivity Index-3", 12, 15, bold = FALSE) %>%
  pack_rows("McMaster Family Assessment Device", 17, 23, bold = FALSE) %>%
  pack_rows("Multidimensional Personality Questionnaire Short Form", 24, 35, bold = FALSE) %>%
  footnote("N = 151")
```


```{r fig.height = 3}
# fig 1
data_context <- vroom::vroom(here(path_shared, "contacts.csv"), col_types = vroom::cols()) %>%
  filter(subid %in% study_dates$subid) %>% 
  # filter out spam contacts and self
  filter(contact_type != "Irrelevant/Spam" & contact_type != "Self")

data_context %>% 
  select(subid, contact_drank_past) %>% 
  group_by(subid) %>% 
  count(contact_drank_past) %>% 
  mutate(contact_drank_past = if_else(contact_drank_past == "Almost Always/Always",
                                      "Always/Almost Always", contact_drank_past)) %>% 
  mutate(contact_drank_past = factor(contact_drank_past, 
                                     levels = c("Always/Almost Always", "Occasionally",
                                                "Never/Almost Never"))) %>% 
  drop_na(contact_drank_past) %>% 
  ggplot(aes(x = n, group = contact_drank_past)) +
  facet_wrap(~ contact_drank_past) +
  geom_histogram(bins = 25, color = "black", fill = "light grey") +
  geom_vline(aes(xintercept = mean_count), data_context %>% 
  select(subid, contact_drank_past) %>% 
  group_by(subid) %>% 
  count(contact_drank_past) %>%
  mutate(contact_drank_past = if_else(contact_drank_past == "Almost Always/Always",
                                      "Always/Almost Always", contact_drank_past)) %>% 
  mutate(contact_drank_past = factor(contact_drank_past, 
                                     levels = c("Always/Almost Always", "Occasionally",
                                                "Never/Almost Never"))) %>% 
  ungroup() %>% 
  group_by(contact_drank_past) %>% 
  drop_na(contact_drank_past) %>% 
  summarise(mean_count = mean(n, na.rm = TRUE)), color = "red3") +
  labs(title = "Have you drank alcohol with this person?") +
  xlab("number of contacts per participant")
```

Figure 1. Have you drank alcohol with this person? Distribution of number of contacts each participant has for each response option (Always/Almost Always, Occassionally, Never/Almost Never). Mean number of contacts is depicted as the solid red line.

```{r fig.height = 3}
# figure 2
data_context %>% 
  select(subid, drink_status) %>% 
  group_by(subid) %>% 
  count(drink_status) %>% 
  mutate(drink_status = case_when(drink_status == "Dont Know" ~ "Don't Know",
                                  drink_status == "NonDrinker" ~ "Non-drinker",
                                  TRUE ~ drink_status)) %>%
  mutate(drink_status = factor(drink_status,
                               levels = c("Drinker", "Non-drinker",
                                                "Don't Know"))) %>%
  drop_na(drink_status) %>% 
  ggplot(aes(x = n, group = drink_status)) +
  facet_wrap(~ drink_status) +
  geom_histogram(bins = 25, color = "black", fill = "light grey") +
  geom_vline(aes(xintercept = mean_count), data_context %>% 
  select(subid, drink_status) %>% 
  group_by(subid) %>% 
  count(drink_status) %>%
  mutate(drink_status = case_when(drink_status == "Dont Know" ~ "Don't Know",
                                  drink_status == "NonDrinker" ~ "Non-drinker",
                                  TRUE ~ drink_status)) %>%
  mutate(drink_status = factor(drink_status,
                               levels = c("Drinker", "Non-drinker",
                                                "Don't Know"))) %>%
  ungroup() %>% 
  group_by(drink_status) %>% 
  drop_na(drink_status) %>% 
  summarise(mean_count = mean(n, na.rm = TRUE)), color = "red3") +
  labs(title = "What is their drinking status?") +
  xlab("number of contacts per participant")
```

Figure 2. What is their drinking status? Distribution of number of contacts each participant has for each response option (Drinker, Non-drinker, Don't Know). Mean number of contacts is depicted as the solid red line.

```{r fig.height = 3}
# figure 3
data_context %>% 
  select(subid, contact_drink_future) %>% 
  group_by(subid) %>% 
  count(contact_drink_future) %>% 
  mutate(contact_drink_future = factor(contact_drink_future,
                               levels = c("Yes", "No", "Uncertain"))) %>%
  drop_na(contact_drink_future) %>% 
  ggplot(aes(x = n, group = contact_drink_future)) +
  facet_wrap(~ contact_drink_future) +
  geom_histogram(bins = 25, color = "black", fill = "light grey") +
  geom_vline(aes(xintercept = mean_count), data_context %>% 
  select(subid, contact_drink_future) %>% 
  group_by(subid) %>% 
  count(contact_drink_future) %>%
 mutate(contact_drink_future = factor(contact_drink_future,
                               levels = c("Yes", "No", "Uncertain"))) %>%
  ungroup() %>% 
  group_by(contact_drink_future) %>% 
  drop_na(contact_drink_future) %>% 
  summarise(mean_count = mean(n, na.rm = TRUE)), color = "red3") +
  labs(title = "Would you expect them to drink in your presence?") +
  xlab("number of contacts per participant")
```

Figure 3. Would you expect them to drink in your presence? Distribution of number of contacts each participant has for each response option (Yes, No, Uncertain). Mean number of contacts is depicted as the solid red line.

```{r fig.height = 3}
# figure 4
data_context %>% 
  select(subid, recovery) %>% 
  group_by(subid) %>% 
  count(recovery) %>%
  mutate(recovery = if_else(recovery == "Dont Know", "Uncertain", recovery)) %>% 
  mutate(recovery = factor(recovery,
                               levels = c("Yes", "No", "Uncertain"))) %>%
  drop_na(recovery) %>% 
  ggplot(aes(x = n, group = recovery)) +
  facet_wrap(~ recovery) +
  geom_histogram(bins = 25, color = "black", fill = "light grey") +
  geom_vline(aes(xintercept = mean_count), data_context %>% 
  select(subid, recovery) %>% 
  group_by(subid) %>% 
  count(recovery) %>%
  mutate(recovery = if_else(recovery == "Dont Know", "Uncertain", recovery)) %>% 
  mutate(recovery = factor(recovery,
                               levels = c("Yes", "No", "Uncertain"))) %>%
  ungroup() %>% 
  group_by(recovery) %>% 
  drop_na(recovery) %>% 
  summarise(mean_count = mean(n, na.rm = TRUE)), color = "red3") +
  labs(title = "Are they currently in recovery from alcohol or other substances?") +
  xlab("number of contacts per participant")
```

Figure 4. Are they currently in recovery from alcohol or other substances? Distribution of number of contacts each participant has for each response option (Yes, No, Uncertain). Mean number of contacts is depicted as the solid red line.

```{r fig.height = 3}
# figure 5
data_context %>% 
  select(subid, support_status) %>% 
  group_by(subid) %>% 
  count(support_status) %>%
  mutate(support_status = if_else(support_status == "Dont Know", 
                                  "Don't Know", support_status)) %>% 
  mutate(support_status = factor(support_status,
                               levels = c("Supportive", "Neutral", "Mixed", "Unsupportive", 
                                          "Don't Know"))) %>%
  drop_na(support_status) %>% 
  ggplot(aes(x = n, group = support_status)) +
  facet_wrap(~ support_status) +
  geom_histogram(bins = 25, color = "black", fill = "light grey") +
  geom_vline(aes(xintercept = mean_count), data_context %>% 
  select(subid, support_status) %>% 
  group_by(subid) %>% 
  count(support_status) %>%
  mutate(support_status = if_else(support_status == "Dont Know", 
                                  "Don't Know", support_status)) %>% 
  mutate(support_status = factor(support_status,
                               levels = c("Supportive", "Neutral", "Mixed", "Unsupportive", 
                                          "Don't Know"))) %>%
  ungroup() %>% 
  group_by(support_status) %>% 
  drop_na(support_status) %>% 
  summarise(mean_count = mean(n, na.rm = TRUE)), color = "red3") +
  labs(title = "Do they know about your recovery goals and if so are they supportive?") +
  xlab("number of contacts per participant")
```

Figure 5. Do they know about your recovery and if so are they supportive? Distribution of number of contacts each participant has for each response option (Supportive, Neutral, Mixed, Unsupportive, Don't Know). Mean number of contacts is depicted as the solid red line.



```{r fig.height = 3}
# figure 6
data_context %>% 
  select(subid, contact_experience) %>% 
  group_by(subid) %>% 
  count(contact_experience) %>%
  mutate(contact_experience = factor(contact_experience,
                               levels = c("Pleasant", "Neutral", "Mixed", "Unpleasant"))) %>%
  drop_na(contact_experience) %>% 
  ggplot(aes(x = n, group = contact_experience)) +
  facet_wrap(~ contact_experience, nrow = 1) +
  geom_histogram(bins = 25, color = "black", fill = "light grey") +
  geom_vline(aes(xintercept = mean_count), data_context %>% 
  select(subid, contact_experience) %>% 
  group_by(subid) %>% 
  count(contact_experience) %>%
  mutate(contact_experience = factor(contact_experience,
                               levels = c("Pleasant", "Neutral", "Mixed", "Unpleasant"))) %>%
  ungroup() %>% 
  group_by(contact_experience) %>% 
  drop_na(contact_experience) %>% 
  summarise(mean_count = mean(n, na.rm = TRUE)), color = "red3") +
  labs(title = "How would you describe your typical experience with this person?") +
  xlab("number of contacts per participant")
```

Figure 6. How would you describe your typical experience with this person? Distribution of number of contacts each participant has for each response option (Pleasant, Neutral, Mixed, Unpleasant). Mean number of contacts is depicted as the solid red line.
  
<!--JJC: If you had time, it might be worth talking about the total number of lapses in the full sample and characteristics of those lapses.   Time, day of week, also number of participant who had lapses and histogram for how lapses cluster within people.  Not imperative but would be nice to have this by the symposium.  -->

## Best Model Performance 

Model configurations differed by statistical algorithm (glmnet, knn, random forest), hyperparameters, feature sets (e.g., active/passive, duration, and formula <!--use the terms here that you use in your feature engineering section of the method-->), and resampling of the outcome classes (downsample, upsample, and SMOTE).  We selected the best model configuration using a grouped 10-fold cross-validation (grouped 10-fold cv) resampling method. We selected our top candidate configurations on balanced accuracy. Table 4 shows the best performing model configuration (i.e., highest balanced accuracy) for each statistical algorithm (glmnet, random forest, Knn). We selected the statistical algorithm with highest balanced accuracy to be our top performing model configuration. 

Our top performing model configuration was a random forest statistical algorithm using passive features and down-sampling. To reduce the effects of optimization bias on our evaluation of our top model configuration's predictive performance, we re-estimated the performance of this top performing configuration using grouped 10-fold cross validation with 10 repeats (grouped 10x10 cv). This means we trained our model configuration on 100 different subsets of training data and predicted on the 100 held out validation sets. We then averaged across the 100 performance estimates to get a single estimate with low variance. This method gave us a balanced accuracy estimate of .60. Table 5 shows a confusion matrix where we can see how well the model configuration predicts on new data for negative cases (i.e., no lapse) compared to positive cases (i.e., lapses). Table 6 characterizes our best model configuration over several metrics appropriate for classification.   

We performed a model comparison to assess our model configuration's performance compared to a null model configuration (i.e., intercept only) with a balanced accuracy of .50. A Bayesian correlated t-test revealed a posterior probability that the balanced accuracy of our top model configuration was above the Region of Practical Equivalence (ROPE) is .999 (Figure 7). This suggests there is a meaningful difference between our selected model configuration and a null model configuration with no signal. 

In the appendix we show that our best performing model configuration has variation in predictions for each individual participant. Figure A1 contains predictions that are predicted probabilities of a lapse. Each observation was held out 10 times (grouped 10x10 cv) and the figure shows the averaged probability across these 10 predictions. Actual lapses, are depicted in red.    


```{r}
# Table 4
results_aggregate %>% 
  group_by(algorithm) %>% 
  arrange(desc(bal_accuracy)) %>% 
  slice(1) %>% 
  mutate(feature_set = if_else(feature_set == "feat_all", "active", "passive"),
         algorithm = str_replace(algorithm, "_", " "),
         feature_fun_type = str_replace(feature_fun_type, "_", ", "),
         feature_fun_type = str_replace(feature_fun_type, "perc", "relative"),
         resample = str_remove(resample, "_1")) %>% 
  select(algorithm, `feature set` = feature_set, `feature type(s)` = feature_fun_type, 
         `class resample` = resample, `balanced accuracy` = bal_accuracy) %>% 
  arrange(desc(`balanced accuracy`)) %>% 
  apa_table(placement = "pt",
            caption = "Balanced Accuracy for Best Configurations by Statistical Algorithm",
            note = "Table reports the best model configuration for each statistical algorithm 
            in separate rows.  Details about the model configuration are provided in subsequent 
            columns.  Balanced accuracy was estimated by grouped 10-fold cross validation 
            during model selection.",
            digits = 2)
  # kbl(booktabs = TRUE,
  #     digits = 2,
  #     caption = "Best Balanced Accuracy for Each Statistical Algorithm across 10 Folds during Model Selection") %>% 
  # kable_styling()
```


```{r}
# Table 5
results_best_model <- vroom(here(path_models, "results_best_model.csv"),
                                   col_types = vroom::cols())

preds_best_model <- vroom(here(path_models, "preds_best_model.csv"),
                                 col_types = vroom::cols())

cm <- preds_best_model %>% 
  mutate(pred_class = if_else(pred_yes >= .5, "yes", "no"),
         pred_class = factor(pred_class, levels = c("no", "yes")),
         y = factor(y, levels = c("no", "yes"))) %>% 
  conf_mat(y, pred_class)
# 
tibble(Prediction = c("no", "yes"),
       no = c(unlist(tidy(cm)[1, 2]), unlist(tidy(cm)[2, 2])),
       yes = c(unlist(tidy(cm)[3, 2]), unlist(tidy(cm)[4, 2]))) %>%
    apa_table(placement = "pt",
              caption = "Confusion Matrix for Best Model Configuration",
              note = "The best model configuration was a random forest algirthm using passive features and down-sampling. Results based on grouped 10x10-fold cross validation.")
# KENDRA add full description of this configuration to this note

# tibble(Prediction = c("no", "yes"),
#        no = c(unlist(tidy(cm)[1, 2]), unlist(tidy(cm)[2, 2])),
#        yes = c(unlist(tidy(cm)[3, 2]), unlist(tidy(cm)[4, 2]))) %>% 
#   kbl(booktabs = TRUE,
#       caption = "Confusion Matrix for Best Model (passive random forest)") %>%
#   kable_styling() %>%
#   add_header_above(c(" " = 1, "Truth" = 2)) %>%
#   row_spec(0, align = "c") 
```


```{r}
# Table 6
results_best_model %>%
  summarise(`balanced accuracy` = mean(bal_accuracy),
            accuracy = mean(accuracy),
            sensitivity = mean(sens),
            specificity = mean(spec)) %>%
  pivot_longer(everything(), names_to = "metric", values_to = "estimate") %>%
  bind_rows(cm %>%
  summary(event_level = "second") %>%
  select(metric = .metric, estimate = .estimate) %>%
  filter(metric %in% c("ppv", "npv"))) %>%
  bind_rows(results_best_model %>%
              summarise(`Area under the ROC Curve` = mean(roc_auc)) %>%
              pivot_longer(everything(), names_to = "metric", values_to = "estimate")) %>%
  apa_table(placement = "pt", digits = 2,
            caption = "Performance Metrics for Best Model Configuration",
            note = "The best model configuration was a random forest algirthm using passive features and down-sampling. Performance estimated by grouped 10x10-fold cross validation.")
# KENDRA add full description of this configuration to this note

# results_best_model %>% 
#   summarise(`balanced accuracy` = mean(bal_accuracy),
#             accuracy = mean(accuracy),
#             sensitivity = mean(sens),
#             specificity = mean(spec)) %>%
#   pivot_longer(everything(), names_to = "metric", values_to = "estimate") %>%
#   bind_rows(cm %>%
#   summary(event_level = "second") %>%
#   select(metric = .metric, estimate = .estimate) %>%
#   filter(metric %in% c("ppv", "npv"))) %>%
#   bind_rows(results_best_model %>% 
#               summarise(`Area under the ROC Curve` = mean(roc_auc)) %>% 
#               pivot_longer(everything(), names_to = "metric", values_to = "estimate")) %>% 
#   kbl(booktabs = TRUE,
#       digits = 2,
#       caption = "Classification Performance Metrics for Best Model (random forest passive) across 100 Folds") %>%
#   kable_styling() %>%
#   pack_rows(start_row = 3, end_row = 6, indent = FALSE) %>%
#   pack_rows(start_row = 7, end_row = 7, indent = FALSE) 
```



```{r fig.height = 3}
best_fits <- results_best_model$bal_accuracy
null_fits <- vroom(here(path_models, "null_model_fits.csv"), col_types = vroom::cols())$bal_accuracy

rope_min <- -.01
rope_max <- .01
plot_min = -.1
plot_max = .3 

results_ttest <- bayesian_correlated_t_test(best_fits, null_fits,
                           rope_min = rope_min, 
                           rope_max = rope_max, 
                           k = 10, 
                           plot_min = plot_min, plot_max = plot_max)

ggplot(mapping = aes(x = results_ttest$plot_diffs, y = results_ttest$pdf)) +
  geom_line() +
  geom_vline(mapping = aes(xintercept  = rope_min), linetype = "dashed") +
  geom_vline(mapping = aes(xintercept  = rope_max), linetype = "dashed") +
  scale_x_continuous(breaks=seq(plot_min, plot_max, .02)) +
  labs(x = "Accuracy Difference (Best - Null Model)",
       y = "Posterior Probability")
```


Figure 7. Model comparison of best model (passive random forest) and null model (intercept only) configurations. 

  


## Model Comparison between Active and Passive

Our best performing active model configuration (i.e., using all the features available) was a glmnet algorithm using up-sampling. We retrained this model configuration on 100 subsets of data and predicted on the held out validation set 100 times (grouped 10x10 cv). This gave us an averaged balanced accuracy of .60. 

Figure 8 shows the balanced accuracy estimates for passive and active model configurations over the 100 resamples. A Bayesian correlated t-test revealed there were no differences between the best active and best passive model configuration. The posterior probability that our active model performed meaningfully better (i.e., to the right of the ROPE) than the passive model was XXX <!--JJC: this is the most important posterior to report-->.  Thus, there is not strong evidence to support the collection of context to calculate active features at this point.  


```{r fig.height = 3}
best_active <- results_aggregate %>%
  filter(feature_set == "feat_all") %>%
  slice_max(bal_accuracy)

results_best_active <- vroom(here(path_models, "results_best_active.csv"),
                                   col_types = vroom::cols()) 

preds_best_active <- vroom(here(path_models, "preds_best_active.csv"),
                                 col_types = vroom::cols())

results_best_model %>%
  bind_rows(results_best_active) %>% 
  rename(feature_set = rec) %>% 
  mutate(feature_set = if_else(feature_set == "rec_best", "Passive (random forest)", "Active (glmnet)")) %>%
  group_by(feature_set) %>%
  ggplot(aes(x = bal_accuracy)) +
  geom_histogram(bins = 20, color = "black", fill = "light grey") +
  facet_wrap(~ feature_set) +
  xlab("balanced accuracy") +
  labs(title = "Model performance across 100 folds") +
  geom_vline(aes(xintercept = mean_ba), results_best_model %>%
  bind_rows(results_best_active) %>%
  rename(feature_set = rec) %>% 
  mutate(feature_set = if_else(feature_set == "rec_best", "Passive (random forest)", "Active (glmnet)")) %>%
  group_by(feature_set) %>%
  summarise(mean_ba = mean(bal_accuracy)), color = "red3")
```

Figure 8. Histogram of best active (glmnet) and passive (random forest) model configuration balanced accuracies across 100 folds. 


```{r fig.height = 3}
best_passive_fits <- results_best_model$bal_accuracy
best_active_fits <- results_best_active$bal_accuracy

rope_min <- -.01
rope_max <- .01
plot_min = -.20
plot_max = .20

results_ttest <- bayesian_correlated_t_test(best_active_fits,
                                            best_passive_fits,
                                            rope_min = rope_min,
                                            rope_max = rope_max,
                                            k = 10,
                                            plot_min = plot_min,
                                            plot_max = plot_max)

ggplot(mapping = aes(x = results_ttest$plot_diffs,
                                                 y = results_ttest$pdf)) +
  geom_line() +
  geom_vline(mapping = aes(xintercept  = rope_min), linetype = "dashed") +
  geom_vline(mapping = aes(xintercept  = rope_max), linetype = "dashed") +
  scale_x_continuous(breaks=seq(plot_min, plot_max, .02)) +
  labs(x = "Accuracy Difference (Active - Passive Model)",
       y = "Posterior Probability")
```

Figure 9. Model comparison of the best active (glmnet) and best passive (random forest) model configurations.


## Top Features

We permuted each feature within the top performing model configuration (passive random forest) to determine each feature's importance. Figure 10 shows which features, when permuted, resulted in the greatest reduction in balanced accuracy. 


```{r fig.height = 6, fig.width = 8}
vi_best <- read_rds(here(path_models, str_c("vi_", best_model$algorithm, ".rds")))
algorithm <- if_else(best_model$algorithm == "random_forest", "random forest",
                     best_model$algorithm)
feat_set <- if_else(best_model$feature_set == "feat_all", "active", "passive")
vi_best %>% 
      mutate(Variable = str_remove(Variable, ".passive"),
             Variable = str_remove(Variable, ".l0"),
             Variable = str_remove(Variable, ".org"),
             Variable = str_remove(Variable, ".dttm_obs"),
             Variable = str_replace(Variable, "pratecount", "perc_rate"),
             Variable = str_replace(Variable, "rratecount", "raw_rate"),
             Variable = str_replace(Variable, "pratesum_duration", "perc_sum.duration"),
             Variable = str_replace(Variable, "pmean_duration", "perc_mean.duration"),
             Variable = str_replace(Variable, "rmean_duration", "raw_mean.duration"),
             Variable = str_replace(Variable, "ppropdatetime", "perc_prop"),
             Variable = str_replace(Variable, "rpropdatetime", "raw_prop"),
             Variable = str_replace(Variable, "rpropcount", "raw_prop"),
             Variable = str_replace(Variable, "ppropcount", "perc_prop"),
             Variable = str_replace(Variable, "p6", "6hrs"),
             Variable = str_replace(Variable, "p12", "12hrs"),
             Variable = str_replace(Variable, "p24", "24hrs"),
             Variable = str_replace(Variable, "p48", "48hrs"),
             Variable = str_replace(Variable, "p72", "72hrs"),
             Variable = str_replace(Variable, "p168", "168hrs"),
             Variable = fct_reorder(Variable, Importance)) %>% 
      filter(Importance != 0) %>% 
      ggplot(aes(x = Importance, y = Variable)) +
      geom_col(color = "black", fill = "light grey") +
      scale_x_continuous(expand = c(0, 0)) +
      labs(y = NULL, title = str_c("Top features for best model (", feat_set, " ", algorithm, ")"))
```

Figure 10. Feature importance scores for best performing model configuration (Passive Random Forest). 



# Appendix

```{r fig.fullwidth = TRUE, fig.height = 11}
# average over predictions
predictions <- preds_best_model %>% 
  group_by(subid, dttm_label, y) %>% 
  summarise(mean = mean(pred_yes), .groups = "drop")

# read in study start dates for x-axis
study_start <- vroom(here(path_study_start, "study_dates.csv"), col_types = vroom::cols()) %>% 
  mutate(study_start = with_tz(study_start, tzone = "America/Chicago"),
         study_end = with_tz(study_end, tzone = "America/Chicago") + days(1)) %>% 
  select(subid, study_start, study_end)

for(i in 1:nrow(study_start))  {
  subid_dates <- tibble(subid = study_start$subid[i],
                        hour = seq(study_start$study_start[i], 
                                   study_start$study_end[i], "hours"))
  subid_dates <- subid_dates %>% 
    mutate(study_hour = seq(1:nrow(subid_dates)))
  
  study_dates <- if (i == 1) {
    subid_dates
  } else {
    study_dates %>% 
      bind_rows(subid_dates)
  }
}

predictions <- predictions %>% 
  left_join(study_dates, by = c("subid", "dttm_label" = "hour"))

# plot
predictions %>% 
  group_by(subid) %>% 
  ggplot(aes(x = study_hour, y = mean, color = y)) +
  geom_point(size = .9) +
  facet_wrap_paginate(~ subid, ncol = 3, nrow = 10, page = 1) + 
  scale_color_manual(values = c("gray70", "red3")) +
  theme(legend.position = "none") +
  ylim(0, 1) +
  ylab("Predicted Probability of Lapse") +
  scale_x_continuous(breaks = seq(1, 91*24, 30*24), labels = c("Start", "FU 1", "FU 2", "End")) +
  geom_hline(yintercept = .5, linetype = "dashed", color = "red3", size = .3)
cat('\r\n\r\n')

predictions %>% 
  group_by(subid) %>% 
  ggplot(aes(x = study_hour, y = mean, color = y)) +
  geom_point(size = .9) +
  facet_wrap_paginate(~ subid, ncol = 3, nrow = 10, page = 2) + 
  scale_color_manual(values = c("gray70", "red3")) +
  theme(legend.position = "none") +
  ylim(0, 1) +
  ylab("Predicted Probability of Lapse") +
  scale_x_continuous(breaks = seq(1, 91*24, 30*24), labels = c("Start", "FU 1", "FU 2", "End")) +
  geom_hline(yintercept = .5, linetype = "dashed", color = "red3", size = .3) 
cat('\r\n\r\n')

predictions %>% 
  group_by(subid) %>% 
  ggplot(aes(x = study_hour, y = mean, color = y)) +
  geom_point(size = .9) +
  facet_wrap_paginate(~ subid, ncol = 3, nrow = 10, page = 3) + 
  scale_color_manual(values = c("gray70", "red3")) +
  theme(legend.position = "none") +
  ylim(0, 1) +
  ylab("Predicted Probability of Lapse") +
  scale_x_continuous(breaks = seq(1, 91*24, 30*24), labels = c("Start", "FU 1", "FU 2", "End")) +
  geom_hline(yintercept = .5, linetype = "dashed", color = "red3", size = .3) 
cat('\r\n\r\n')

predictions %>% 
  group_by(subid) %>% 
  ggplot(aes(x = study_hour, y = mean, color = y)) +
  geom_point(size = .9) +
  facet_wrap_paginate(~ subid, ncol = 3, nrow = 10, page = 4) + 
  scale_color_manual(values = c("gray70", "red3")) +
  theme(legend.position = "none") +
  ylim(0, 1) +
  ylab("Predicted Probability of Lapse") +
  scale_x_continuous(breaks = seq(1, 91*24, 30*24), labels = c("Start", "FU 1", "FU 2", "End")) +
  geom_hline(yintercept = .5, linetype = "dashed", color = "red3", size = .3) 
cat('\r\n\r\n')

predictions %>% 
  group_by(subid) %>% 
  ggplot(aes(x = study_hour, y = mean, color = y)) +
  geom_point(size = .9) +
  facet_wrap_paginate(~ subid, ncol = 3, nrow = 11, page = 5) + 
  scale_color_manual(values = c("gray70", "red3")) +
  theme(legend.position = "none") +
  ylim(0, 1) +
  ylab("Predicted Probability of Lapse") +
  scale_x_continuous(breaks = seq(1, 91*24, 30*24), labels = c("Start", "FU 1", "FU 2", "End")) +
  geom_hline(yintercept = .5, linetype = "dashed", color = "red3", size = .3)
```


Figure A1. Predicted probabilities of lapse for each participant. A grouped 10x10 resampling method was used to obtain these probabilities. Known lapses are in red. The red dashed line represents the threshold for classifying a probability as a lapse (i.e., everything above the line was predicted to be a lapse).  


# Discussion


ideas: 
- more feature engineering. For example just based on the hour we are predicting for we can get similar accuracy (temporal features). We also have not fully used context to its potential. Also are not using the vast amounts of information from the ID variables (tables 1-3). This was in an effort to reduce the high dimensionality of the feature matrix and isolate the predictive value of meta logs.  

- Will also add other signals like text message content and geoposition.   Could add EMA but that might be too burdensome for long term implementation

- no ppv - day level predictions 

- lag (models with different lags - 0 lag for immediate interventions but other interventions will benefit from other lags)

- starting steps to not just detect lapse but when to intervene (context bandits, microinterventions)

\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup
