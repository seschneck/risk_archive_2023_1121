---
title: "Post-CHTC Processing"
date: "`r lubridate::today()`"
output: 
  html_document:
    toc: true 
    toc_depth: 4
    code_folding: show
editor_options: 
  chunk_output_type: console
---

### Setup

Chunk Defaults
```{r defaults, include=FALSE}
knitr::opts_chunk$set(attr.output='style="max-height: 500px;"')

options(tibble.width = Inf)
options(tibble.print_max = Inf)
```


Packages for lab workflow 
```{r, packages_workflow, message=FALSE, warning=FALSE}
library(conflicted) 
 conflict_prefer("filter", "dplyr")
 conflict_prefer("select", "dplyr")
 conflict_prefer("spec", "yardstick")

library(here)  
```

Packages for script
```{r, packages_script, message=FALSE, warning=FALSE}
library(tidyverse)  
library(janitor) 
library(lubridate)
library(ggplot2)
library(kableExtra)

theme_set(theme_classic()) 
```

Set additional paths
```{r}
path_job <- here("P:/studydata/risk/chtc/meta/jobs/features/features_1.1000")
path_output <- here(path_job, "output/output")
path_features <-  here(path_job, "output/features")
path_error <-  here(path_job, "output/error")
```

Source function scripts from lab support
```{r  source_script, message=FALSE, warning=FALSE}
source(here("../lab_support/print_kbl.R"))
```


### Notes
This script aggregates all CHTC features and runs checks for missing jobs.
  

Inputs:  

Returned CHTC files   

- output.zip  
- features.zip    
- output.zip   

Jobs input file   

- jobs.csv   

Output:   

- features_aggregate.csv   

### Unzip and check jobs

unzip chtc folders
```{r}
unzip(zipfile = file.path(path_job, "output/output.zip"), exdir = file.path(path_job, "output"))
unzip(zipfile = file.path(path_job, "output/features.zip"), exdir = file.path(path_job, "output"))
unzip(zipfile = file.path(path_job, "output/error.zip"), exdir = file.path(path_job, "output"))
```

Read in jobs
```{r}
jobs <- read_lines(here(path_job, "input/jobs.csv")) %>% 
    as.numeric() %>%
    enframe(., value = "label_num", name = NULL) %>% 
  glimpse()
```



check all error files are blank (0 kb)    
Note: error files also contain warnings
```{r}
err_files <- map_df(list.files(path_error, full.names = TRUE), file.info)
tabyl(err_files$size)
```

Pull error messages and jobs if error files are not all blank
```{r}
if (nrow(subset(err_files, size > 0)) > 0) {
  err_paths <- err_files %>% 
    filter(size > 0) %>% 
    rownames_to_column("path") %>% 
    pull(path) 
  for (i in err_paths) {
    err_i <- read_file(i) %>% 
      enframe(value = "message", name = NULL) %>% 
      mutate(label_num = as.numeric(str_remove(str_split(str_split(i, "/")[[1]][11], "_")[[1]][2], ".err")),
             message = str_remove_all(message, "\\n")) %>% 
      relocate(label_num)
    errs <- if (i == err_paths[1]) {
      err_i
    } else rbind(errs, err_i)
  }
  
  
  # print error messages
  print_kbl(errs, align = "l")
} else print("no errors or warnings")
```


check all output files are blank (0 kb)
```{r}
out_files <- map_df(list.files(path_output, full.names = TRUE), file.info)
tabyl(out_files$size)
```

### Aggregate all result CSVs

read in all result CSVs
```{r}
feat_files <- list.files(path_features, full.names = TRUE)
features <- map_dfr(feat_files, ~read_rds(.x)) %>% 
  glimpse()
```


check for missing jobs    

`r nrow(features)` rows from `r nrow(jobs)` jobs.      

```{r}
missing_job_nums <- enframe(seq(1:nrow(jobs)), name = NULL, value = "label_num") %>% 
  filter(!label_num %in% features$label_num)

if (nrow(missing_job_nums) > 0) {
  print(str_c("missing jobs: ", str_c(as.character(missing_job_nums$label_num), collapse=", ")))
  } else print("No missing jobs")
```

Add in missing jobs    
*need to rerun locally or on chtc first*
```{r}
# if (nrow(missing_job_nums > 0)) {
#   feat_files_add <- list.files(here(path_job, "output/missing_jobs"), full.names = TRUE)
#   features_add <- map_dfr(feat_files_add, ~read_rds(.x)) %>% 
#     glimpse()
# 
#   features <- features %>% 
#     rbind(features_add)
# 
#   # recheck for missing jobs
#   missing_job_nums <- enframe(seq(1:nrow(jobs)), name = NULL, value = "label_num") %>% 
#     filter(!label_num %in% features$label_num)
#   
#   if (nrow(missing_job_nums) > 0) {
#     print(str_c("missing jobs: ", str_c(as.character(missing_job_nums$label_num), collapse=", ")))
#     } else print("No missing jobs")
# }
```


Check no duplicate labels
```{r}
features %>% 
  count(subid, dttm_label) %>% 
  filter(n > 1)
```

### Check for any unexpected values

Missing values    
All missing values should be proportions   
```{r}
naniar::miss_var_summary(features) %>% 
  print(n = 200)
```

Check for NaN
```{r}
features %>% 
  summarise(across(everything(), ~ sum(is.nan(.x)))) %>% 
  glimpse()
```


proportions should be NA or between 0-1
```{r}
features %>% 
  summarise(across(contains("rpropcount"), list(min = min, max = max), na.rm = TRUE)) %>% 
  glimpse()
```

### Print features

```{r}
# print_kbl(features)
```



### Write out aggregated features


```{r}
write_csv(features, here(path_job, "output/features_aggregate.csv")) %>% 
  glimpse()


write_rds(features, here(path_job, "output/features_aggregate.rds"))
```

