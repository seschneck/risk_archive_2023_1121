---
title: "Create lapse labels"
author: "John Curtin and Kendra Wyant"
date: "`r lubridate::today()`"
output: 
  html_document:
    toc: true 
    toc_depth: 4
knit: (function(input, ...) {
    rmarkdown::render(
      input,
      output_dir = dplyr::if_else(Sys.info()[["sysname"]] == "Windows",
      "P:/studydata/risk/knits/meta", 
      "/Volumes/private/studydata/risk/knits/meta")
    )
  })
---

### Code Status

These labels are now complete to be used for the meta project. This script makes labels based on the cleaned lapses. See conclusions for important decisions and notes related to the pre-processing of these labels done in mak_lapses.   



### Conclusions   

- More complete EDA on all EMA data and lapses is in cln_ema.Rmd and mak_lapses.Rmd.  


- We decided to retain lapses with no end time if their onset was valid. We will use a
24 hour rule when sampling non-lapses. That is we will not sample non-lapses in the 
24 hours following the onset of the lapse + 3 hours as with all lapses.    


- Our exclusion criteria can be summarized as:

  - lapses that were reported in an interview   
  - lapses that have no start time and date     
  - lapses that have a negative duration   
  - lapses that have a duration longer than 24 hours     
  - future lapses (lapse start > ema end time)   

- John and Kendra decided to change Subid 74's start date to 2018-07-06 - the day after 
their first cellular communication (2018-07-05).    
  - Participant broke their phone before followup 1 so we were not able to download 
  cellular communications at followup 1 (only 2 SMS/voice log files in Raw data). 
  Unclear how this impacted other data sources yet. 
  - As a result their cellular communications don't start until day 33 on study.           
  - Subid 74 had no lapses while on study.  
  

- John and Kendra have decided to drop subid 104's data for the following reasons:   
  - They had lapses every day on study except one day.    
  - Only had 75 surveys where a lapse was not reported.   
  - Viewing their lapse times it appears they were drinking constantly (morning and 
  night).   
  - They consistently report being uncertain that their goal is to be abstinent 
  (uncertain on 125 of 137 lapses. They also report they are uncertain in this goal 
  at followup 1 and 2.    
  - They are ultimately discontinued since they were struggling to gain sobriety.   
  - Unfortunately this drops 109 valid lapses.    


- John and Kendra have decided to drop subid 269's data for the following reasons:       
  - They completed 10-15 surveys on many days on study (avg number of surveys per 
  day is 6.76).  
  - Their responses indicate careless responding - they were filling 2-4 surveys out 
  within an hour of each other and the responses to the questions were completely different.     
  - They have questionable no lapse labels - they reported no lapses while on study but 
  according to notes left two messages for study staff where they admitted to drinking 
  over the weekend.   
  

- John and Kendra have decided to drop subid 204's data for the following reasons:    
  - Subid 204 had extremely poor compliance. 33 out of 89 study days had an EMA completed. 
  They only did a total of 5 surveys between followup 2 and 3.    
  - We don't trust their lapse labels - They report several lapses during their interviews 
  but times appear questionable (same time every night). They only report 1 lapse with EMA.
  - From notes - "Participant did not do many surveys during their second month of participation. 
  At their Follow-up 2 visit they reported several lapses that were not documented in their 
  EMAs - estimated lapse days/times in subid's raw data log."  
  - JC note: "There are issues with 204. They are missing lapses reported by interview. But they  
  also stopped doing any ema by 5/17 even though their study end date was 6/13. Probably need to 
  drop them for lapse analyses for anything after 5/17.  Probably also need to add in their 
  reported lapses at follow-up 2. OR we drop them at the end of follow-up 1 or wherever their 
  ema gets sketchy"    


- John and Kendra have decided to decided to retain 128's data even though they have over 100 lapses for 
the following reasons:   
  - Compliance is good (averaged over 3 surveys per day, no days without an EMA).       
  - completed the study for the full 90 days.    
  - appeared to still want abstinence as they reported they were uncertain to ema_1_5 
  on only 3 surveys. They reported they were uncertain that their goal was to remain 
  abstinent at followup 1 and confirmed their goal was to remain abstinent at followup 2.    
  - Has more non-lapse surveys than lapse surveys.   
  

- Subid 118 has an invalid end time (None12pm) left in cleaned EMA as study-level decision. 
After Kendra and John reviewed this situation, it was concluded that it was likely they were 
still drinking at time of EMA (i.e., no end time). Changing end time to NA in this script.    
  
  
- Subid 238 has 419 total EMAs for 89 days on study. Some days they have as many as 10 
surveys a day. Not clear why. They report no lapses while on study. They also have no other notes or 
evidence to suggest their data is unreliable.    

- Interview lapses are used to exclude days from non-lapse sampling but should not be 
used as valid lapses. Times are approximations made retrospectively.     

- There were no EMA surveys sent to any participants on 3/2/19.   

- 23 EMAs with lapses took more than 10 minutes to complete (ranges from 11 - 582 minutes 
for finished surveys).     

- All unfinished surveys (finished = 0) have at least ema_1 answered which reports if 
there have been any lapses since the last survey.  
  - Note that there are several "self-correcting surveys" where a participant answers 
  "Yes" for ema_1 then restarts another survey within minutes of the incomplete survey 
  and puts "no" for ema_1.  
  

- All final timezones are in America/Chicago timezone.    


### Set Up Environment

Chunk Defaults
```{r defaults, include=FALSE}
knitr::opts_chunk$set(attr.output='style="max-height: 500px;"')

options(tibble.width = Inf)
options(tibble.print_max = Inf)
```

Absolute paths
```{r, absolute paths}
switch (Sys.info()[['sysname']],
        # PC paths
        Windows = {
          path_raw <- "P:/studydata/risk/data_raw"
          path_processed <- "P:/studydata/risk/data_processed/shared"
          path_meta <- "P:/studydata/risk/data_processed/meta"},

        # IOS paths
        Darwin = {
          path_raw <- "/Volumes/private/studydata/risk/data_raw"
          path_processed <- "/Volumes/private/studydata/risk/data_processed/shared"
          path_meta <- "/Volumes/private/studydata/risk/data_processed/meta"}
        )
```

Packages for lab workflow 
```{r, packages_workflow, message=FALSE, warning=FALSE}
library(conflicted) # detect and warn about function conflicts
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")

library(here)  # establish project directory consistently as working directory
```


Packages for script
```{r, packages_script, message=FALSE, warning=FALSE}
# for data wrangling
library(tidyverse)
library(vroom)
library(janitor)
library(lubridate)
```


Source for script
```{r, source_script, message=FALSE, warning=FALSE}
source(here("../lab_support/print_kbl.R"))
source(here("shared/fun_risk.R"))
```

### Read in lapses
```{r}
lapses <- vroom::vroom(here(path_processed, "lapses.csv"), col_types = vroom::cols()) %>% 
  mutate(across(c(lapse_start, lapse_end, ema_end)), with_tz(., "America/Chicago")) %>% 
  glimpse()
```


### Study Dates/Times

We will not predict lapses outside of study participation dates. Need info on:

* Start and end dates for participation
* Who completed followup_1 so that they have context
* Time of the last EMA so we can know the definite window for no_lapse sampling.
We can assume no_lapse sampling starts with study_start but it end with the earlier
of study_end or ema_end (time of the last ema that we trust has valid data)     

Read in dates from study level folder
```{r}
dates <- vroom::vroom(here(path_meta, "study_dates.csv"), col_types = vroom::cols()) %>%
  mutate(across(study_start:ema_end), with_tz(., tz = "America/Chicago")) %>% 
  glimpse()
```



### Get valid observations of lapse and no_lapse

Get valid lapse and no_lapse observations by hour

* tibble includes all hours for each subject starting on midnight on day 2 through
the end of study (or last ema, whichever is earlier)
* lapse column is true or false.  True for accurate lapse reports
* no_lapse column is true or NA.  True for accurate no_lapse, NA for excluded periods
These periods are excluded if there are with +-24 hours of a valid lapse period, or similar
periods around invalid lapse reports.  see function for more detail

```{r}   
labels_all <- get_lapse_labels(lapses, dates) %>% 
  glimpse()
```



#### EDA

Check `labels_all`       

* A total of `r nrow(labels_all)` labels made.    
* `r nrow(subset(labels_all, lapse))` labels are lapses.   
* `r nrow(subset(labels_all, no_lapse))` labels are labeled as no lapse.    
* `r sum(labels_all$lapse & labels_all$no_lapse)` are labeled lapse and no lapse (should be zero).   
* `r sum(!labels_all$lapse & !labels_all$no_lapse)` are not labeled lapse or no lapse (should be non-zero. Hard to know correct value).  
* `r nrow(subset(labels_all, lapse))` + `r nrow(subset(labels_all, no_lapse))` + `r sum(!labels_all$lapse & !labels_all$no_lapse)` = `r nrow(subset(labels_all, lapse)) + nrow(subset(labels_all, no_lapse)) +  sum(!labels_all$lapse & !labels_all$no_lapse)` 

Proportion of lapses (at the level of the hour)
```{r}
labels_all %>% 
  mutate(label = case_when(lapse ~ "lapse",
                           no_lapse ~ "no_lapse",
                           TRUE ~ NA_character_)) %>% 
  tabyl(label)
```


#### Get Final Labels 

Will use all lapses and a proportion of no_lapses    

Sample no lapses so that lapses make up 5% of all labels
```{r}
labels_05 <- sample_labels(labels_all, .05, 19690127) %>% 
  glimpse()
```


### EDA on Final Labels 

`r length(unique(labels_05$subid))` of `r length(unique(labels_all$subid))` subids have labels.  

Check lapses make up 5% of retained labels   
```{r}
labels_05 %>% 
  tabyl(label)
```

`r nrow(subset(labels_05, label == "lapse"))` of `r nrow(subset(lapses, exclude == FALSE))` valid lapses retained in labels.  
  
`r nrow(subset(left_join(lapses, dates, by = "subid"), !exclude & date(study_start) == date(lapse_start)))` valid lapses occurred on a participants' first day on study (i.e., day after intake).     
```{r}
lapses %>% 
  left_join(dates, by = "subid") %>% 
  filter(!exclude & date(study_start) == date(lapse_start)) %>% 
  print_kbl()
```

  
`r length(unique(subset(labels_05, label == "no_lapse")$subid))` subids have no_lapses present in final labels.
```{r}
labels_05 %>% 
  filter(label == "no_lapse") %>% 
  tabyl(subid)
```

`lapses` and `no_lapses` are negatively correlated
```{r}
labels_05 %>% 
  count(subid, label) %>% 
  pivot_wider(names_from = label, values_from = n) %>% 
  select(-subid) %>% 
  cor(use = "pairwise.complete.obs") %>% 
  round(2)
```

Check no excluded lapses were sampled
```{r}
labels_05 %>% 
  filter(label == "lapse") %>% 
  left_join(lapses %>% select(subid, lapse_start, exclude), 
            by = c("subid", "dttm_label" = "lapse_start")) %>% 
  tabyl(exclude)
```

`r nrow(subset(left_join(labels_05, lapses, by = c("subid", "dttm_label" = "lapse_start")), exclude & label == "lapse"))` excluded lapse is showing as included
```{r}
labels_05 %>% 
  left_join(lapses, by = c("subid", "dttm_label" = "lapse_start")) %>% 
  filter(exclude & label == "lapse") %>% 
  glimpse()
```


Excluded lapse included in labels was excluded for being a future lapse
```{r}
ema <- vroom(here(path_processed, "ema_later.csv"), col_types = vroom::cols())%>% 
  rename_with(~ str_replace(.x, "emal_", "ema_")) %>% 
  mutate(start_date = with_tz(start_date, "America/Chicago"),
         end_date = with_tz(end_date, "America/Chicago")) %>% 
  select(subid, response_id, start_date, end_date, ema_1_1:ema_1_4)

ema %>% 
  filter(response_id == "R_eWLl6bIFFddp6cV") %>%
  left_join(lapses %>% select(response_id, lapse_start, exclude, lapse_cnt), 
            by = "response_id") %>% 
  mutate(diff = difftime(end_date, lapse_start, units = "hours")) %>% 
  glimpse()
```

The same lapse is later reported and included (no longer a future lapse) - 2 different response_ids    
Since this is a valid lapse it is okay that it is retained in our final labels
```{r}
lapses %>% 
  filter(lapse_start == subset(left_join(ema, lapses, by = "response_id"), 
                               response_id == "R_eWLl6bIFFddp6cV")$lapse_start)
```

EMA for valid lapse
```{r}
ema %>% 
  filter(response_id == "R_UGFcl9goLnpGrwl") %>% 
  left_join(lapses %>% select(response_id, lapse_start, exclude, lapse_cnt), 
            by = "response_id") %>% 
   mutate(diff = difftime(end_date, lapse_start, units = "hours")) %>% 
  glimpse()
```



Final labels per subid
```{r}
labels_05 %>% 
  tabyl(subid, label) %>% 
  adorn_totals("col")
```



### Save

save valid_observations and labels
```{r}
labels_05 %>% 
  write_csv(here(path_meta, "labels_05.csv"))

labels_all %>% 
  write_csv(here(path_meta, "labels_all.csv"))
```

