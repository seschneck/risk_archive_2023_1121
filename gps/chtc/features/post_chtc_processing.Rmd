---
title: "Aggregates jobs for features from CHTC"
author: "John Curtin"
date: "`r lubridate::today()`"
output: 
  html_document:
    toc: true 
    toc_depth: 4
knit: (function(input, ...) {
    rmarkdown::render(
      input,
      output_dir = dplyr::if_else(Sys.info()[["sysname"]] == "Windows",
      "P:/studydata/risk/knits/gps", 
      "/Volumes/private/studydata/risk/knits/gps")
    )
  })
---

### Code Status

In development

### Notes   

This script aggregates all CHTC features and runs checks for missing jobs.
  

Inputs:  

Returned CHTC files   

- output.zip  
- features.zip    
- output.zip   

Jobs input file   

- jobs.csv   

Output:   

- features.csv 



### Set Up Environment

Absolute paths
```{r, absolute paths}
switch (Sys.info()[['sysname']],
        # PC paths
        Windows = {
          path_jobs <- "P:/studydata/risk/chtc/gps/features_1day"
          path_output <- "P:/studydata/risk/data_processed/gps"},

        # IOS paths
        Darwin = {path_jobs <- "/Volumes/private/studydata/risk/chtc/gps/features_1day"
        path_output <- "/Volumes/private/studydata/risk/data_processed/gps"}
        )
```

Packages for lab workflow 
```{r, packages_workflow, message=FALSE, warning=FALSE}
library(conflicted) # detect and warn about function conflicts
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
conflict_prefer("spec", "yardstick")

library(here)  # establish project directory consistently as working directory
```


Packages for script
```{r, packages_script, message=FALSE, warning=FALSE}

library(tidyverse)  
library(janitor) 
library(vroom)
library(furrr)
library(tictoc)
#library(lubridate)
#library(ggplot2)
#library(kableExtra)

#theme_set(theme_classic()) 
```


Source for script
```{r, source_script, message=FALSE, warning=FALSE}
# source(here("../lab_support/print_kbl.R"))
```

Chunk Defaults
```{r defaults, include=FALSE}
knitr::opts_chunk$set(attr.output='style="max-height: 500px;"')

options(tibble.width = Inf)
options(tibble.print_max = Inf)
```


### Begin Main Code


### Check jobs

Read in jobs
```{r}
jobs <- vroom(here(path_jobs, "input", "jobs.csv"), 
              delim = "\t", 
              show_col_types = FALSE, 
              col_names = FALSE) %>% 
  rename(job_start = X1, job_end = X2)
```



check all error files are blank (0 kb)    
Note: error files also contain warnings
```{r}
err_files <- map_df(list.files(here(path_jobs, "output", "error"), 
                               full.names = TRUE), 
                    file.info)
tabyl(err_files$size)
```

Pull error messages and jobs if error files are not all blank
```{r}
# if (nrow(subset(err_files, size > 0)) > 0) {
#   err_paths <- err_files %>% 
#     filter(size > 0) %>% 
#     rownames_to_column("path") %>% 
#     pull(path) 
#   
#   for (i in err_paths) {
#     err_i <- read_file(i) %>% 
#       enframe(value = "message", name = NULL) %>% 
#       mutate(label_num = as.numeric(str_remove(str_split(str_split(i, "/")[[1]][11], "_")[[1]][2], ".err")),
#              message = str_remove_all(message, "\\n")) %>% 
#       relocate(label_num)
#     errs <- if (i == err_paths[1]) {
#       err_i
#     } else rbind(errs, err_i)
#   }
#   
#   
#   # print error messages
#   print_kbl(errs, align = "l")
# } else print("no errors or warnings")
```


check all output files are blank (0 kb)
```{r}
out_files <- map_df(list.files(here(path_jobs, "output", "out"), 
                               full.names = TRUE), 
                    file.info)
tabyl(out_files$size)
```

### Aggregate all result CSVs

read in all feature CSVs
```{r}
 
#future_map over subids
(n_core <- parallel::detectCores(logical = FALSE))
plan(multisession, workers = n_core)

tic()
features <- list.files(here(path_jobs, "output", "features"), full.names = TRUE) %>% 
  future_map_dfr(read_csv) %>% 
  arrange(subid, dttm_label) %>% 
  glimpse()
toc()
```


### Check for missing jobs
check for missing jobs    

```{r}
#message("Missing jobs: ", subset(jobs$label_num, !jobs$label_num %in% features$label_num))
```


# EDA
Check correct number of rows
```{r}
# if (! nrow(jobs) == nrow(features)) stop("Number of feature rowsn(", nrow(features), 
#                                           ") does not match number of jobs (", nrow(jobs),
#                                           ")")
```

Check no duplicate labels
```{r}
features %>% 
  count(subid, dttm_label) %>% 
  filter(n > 1)
```

Missing values    
All missing values should be proportions   
```{r}
t <- naniar::miss_var_summary(features) %>% 
  filter(n_miss > 0) %>% 
  print(n = Inf)
```

Check for NaN.  Select only columns with NaN
```{r}
features %>% 
  summarise(across(everything(), ~ sum(is.nan(.x)))) %>% 
  select(where(function(x) x < 0)) %>% 
  glimpse()
```

### Write out aggregated features


```{r}
features %>% 
  vroom_write(here(path_output, "features.csv"))
```

