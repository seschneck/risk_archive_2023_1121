---
title: "Aggregates jobs for features from CHTC"
author: "John Curtin"
date: "`r lubridate::today()`"
output: 
  html_document:
    toc: true 
    toc_depth: 4
knit: (function(input, ...) {
    rmarkdown::render(
      input,
      output_dir = dplyr::if_else(Sys.info()[["sysname"]] == "Windows",
      "P:/studydata/risk/knits/gps", 
      "/Volumes/private/studydata/risk/knits/gps")
    )
  })
---

### Code Status

In development

NEED TO UPDATE TO be flexible on feature job name.  Currently hard coded to 1day

### Notes   

This script aggregates all CHTC features and runs checks for missing jobs.
  

Inputs:  

Returned CHTC files: 

* features
* error
* out   

Jobs input file   

*-* jobs.csv   

Output:   

* features.csv 



### Set Up Environment

Absolute paths
```{r, absolute paths}
switch (Sys.info()[['sysname']],
        # PC paths
        Windows = {
          path_jobs <- "P:/studydata/risk/chtc/gps/features_1day"
          path_output <- "P:/studydata/risk/data_processed/gps"},

        # IOS paths
        Darwin = {path_jobs <- "/Volumes/private/studydata/risk/chtc/gps/features_1day"
        path_output <- "/Volumes/private/studydata/risk/data_processed/gps"}
        )
```

Packages for lab workflow 
```{r, packages_workflow, message=FALSE, warning=FALSE}
library(conflicted) # detect and warn about function conflicts
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
conflict_prefer("cols", "readr")

# conflict_prefer("spec", "yardstick")

library(here)  # establish project directory consistently as working directory
```


Packages for script
```{r, packages_script, message=FALSE, warning=FALSE}

library(tidyverse)  
library(janitor) 
library(vroom)
library(furrr)
```


Source for script
```{r, source_script, message=FALSE, warning=FALSE}
source(here("../lab_support/print_kbl.R"))
```

Chunk Defaults
```{r defaults, include=FALSE}
knitr::opts_chunk$set(attr.output='style="max-height: 500px;"')

options(tibble.width = Inf)
options(tibble.print_max = Inf)
```


### Check raw files

Read job file
```{r}
jobs <- vroom(here(path_jobs, "input", "jobs.csv"), 
              delim = "\t", 
              show_col_types = FALSE, 
              col_names = FALSE) %>% 
  rename(job_start = X1, job_end = X2) %>% 
  glimpse()
```

Get counts of jobs and labels
```{r}
n_jobs <- nrow(jobs)

n_labels <- jobs %>% 
  mutate(n_bundle = job_end - job_start + 1) %>% 
  summarise(n_labels = sum(n_bundle)) %>% 
  pull(n_labels)
```

Read error, out, and feature files
```{r}
err_files <- map_df(list.files(here(path_jobs, "output", "error"), 
                               full.names = TRUE), 
                    file.info)

out_files <- map_df(list.files(here(path_jobs, "output", "out"), 
                               full.names = TRUE), 
                    file.info)

feature_files <- map_df(list.files(here(path_jobs, "output", "features"), 
                               full.names = TRUE), 
                    file.info)
```

Check counts of error, out, and features
```{r}
if (!(n_jobs == nrow(err_files))) {
  stop(n_jobs, " jobs != ", nrow(err_files), " error files!") 
} else {
  message(nrow(err_files), " error files detected.  Correct!")
}

if (!(n_jobs == nrow(out_files))) {
  stop(n_jobs, " jobs != ", nrow(out_files), " out files!")
} else {
  message(nrow(out_files), " out files detected.  Correct!")
}

if (!(n_jobs == nrow(feature_files))) {
  stop(n_jobs, " jobs != ", nrow(feature_files), " feature files!")
} else {
  message(nrow(feature_files), " feature files detected.  Correct!")
}
```

Display path/filename of non-zero error files
```{r}
err_files %>%
    filter(size > 0) %>%
    rownames_to_column("path") %>%
    pull(path)
```

Display path/filename of non-zero out files
```{r}
out_files %>%
    filter(size > 0) %>%
    rownames_to_column("path") %>%
    pull(path)
```


### Aggregate feature files 

```{r}
 
#future_map over subids
(n_core <- parallel::detectCores(logical = FALSE))
plan(multisession, workers = n_core)

features <- list.files(here(path_jobs, "output", "features"), full.names = TRUE) %>% 
  future_map_dfr(~read_csv(file = .x, col_types = cols())) %>% 
  arrange(subid, dttm_label) %>% 
  glimpse()
```


### Brief EDA on Features

Check for correct number of features (matches number of labels)  

```{r}
if (nrow(features) == n_labels) {
  message("Features detected for ", n_labels, " labels.  Correct!")
} else {
  stop("Missing features for label_num: \n", 
       subset(1:n_labels, !1:n_labels %in% features$label_num))
}
```


Check for duplicate labels
```{r}
features %>% 
  count(subid, dttm_label) %>% 
  filter(n > 1)
```

Missing values    
All missing values should be proportions   
```{r}
t <- naniar::miss_var_summary(features) %>% 
  filter(n_miss > 0) %>% 
  print(n = Inf)
```

Check for NaN.  Select only columns with NaN
```{r}
features %>% 
  summarise(across(everything(), ~ sum(is.nan(.x)))) %>% 
  select(where(function(x) x < 0)) %>% 
  glimpse() 
```

### Write feature file

```{r}
features %>% 
  vroom_write(here(path_output, "features.csv")) %>% 
  vroom_write(here(path_output, "features.csv.xz"))
```

