---
title: "make enriched gps/location"
author: "John Curtin"
date: "`r lubridate::today()`"
output: 
  html_document:
    toc: true 
    toc_depth: 4
knit: (function(input, ...) {
    rmarkdown::render(
      input,
      output_dir = dplyr::if_else(Sys.info()[["sysname"]] == "Windows",
      "P:/studydata/risk/knits/gps", 
      "/Volumes/private/studydata/risk/knits/gps")
    )
  })
---

### Code Status

Complete

### Notes   

This script aggregates gps files for all subjects and then matches each 
geolocation to its nearest context.

The sample starts with the N = 151 participants who completed through at 
least follow-up 1 and who had valid lapse data.   More details on these decisions
are available in the cleaning of EMA and lapses and in the mak_study_dates.Rmd
scripts

We then do EDA to confirm that GPS data are valid for these N=151.  
This results in further removals 

**GPS problems that require removal**

* 190 had gps problems through-out study.  Missing GPS on most (85) days.  Drop participant
* 56 is missing most of their data until the last few days of the study. Drop participant
* 2 had tech (samsung) issues and is missing most of their data until the last few days of the study. Drop participant
* 51 tech (samsung) issues with big (month long) gaps in their data.  Drop participant
* 21 had tech (samsung) issues.  Large gaps.  Drop participant
* 84 had many phone issues (lost phone, missing data, out of country wiht GPS off).  Drop participant
* 65 had tech (samsung) issues with many gaps in gps.  Drop participant
* 117 turned off location services repeatedly b/c of data plan issues. Many gaps. Drop participant
* 19 had tech issues (samsung) with many gaps in gps.  Drop participant
* 42 had many big gaps throughout their data.  Drop participant


**GPS problems that require adjustment**

* 80 has good data for about first month (through 7/31).  No data after that.  Retain lapses through 7/31
* 74 had problems with Moves.  Gaps in data using Moves.  Switched to FollowMee on 7/19 and seemed
to resolve issue.   Filter data (and lapses before 7/19) 
* 167 had gps problems in first month.  Resolved at FU1.  Recode study start to 2/6 (data of FU1 when GPS starts working)
* 207 had issues with broken phone, missing days, and out of country travel. Despite this, data were ok (some gaps but not really big ones) through 5/19.   End study on 5/19 
*28 missing data for most of the first month.   Data are present afterward.  Adjust study start to 12/18

**Data OK despite missing**

* 3 has missing days but these appear to result from not leaving home for long periods do to a fractured leg.  Retain all data

** Not sure**

* 63 has some big gaps but mostly good data.  Also stays home a lot.  If we can
find a way to handle the gaps, maybe can retain?



### Set Up Environment

Absolute paths
```{r, absolute paths}
switch (Sys.info()[['sysname']],
        # PC paths
        Windows = {
          path_shared <- "P:/studydata/risk/data_processed/shared"
          path_gps <- "P:/studydata/risk/data_processed/gps"},

        # IOS paths
        Darwin = {
          path_shared <- "/Volumes/private/studydata/risk/data_processed/shared"
          path_gps <- "/Volumes/private/studydata/risk/data_processed/gps"}
        )
```

Packages for lab workflow 
```{r, packages_workflow, message=FALSE, warning=FALSE}
library(conflicted) # detect and warn about function conflicts
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")

library(here)  # establish project directory consistently as working directory
```


Packages for script
```{r, packages_script, message=FALSE, warning=FALSE}
# for data wrangling
library(tidyverse)
library(lubridate)
library(vroom)
library(purrr)
library(furrr)
library(janitor)
```


Source for script
```{r, source_script, message=FALSE, warning=FALSE}
source(here("../lab_support/fun_gps.R"))
```


### Study Dates

Open study dates b/c it contains all the subids with context and valid lapses
```{r}
study_dates <- vroom(here(path_gps, "study_dates.csv"), col_types = "dTTT",
                     show_col_types = FALSE) %>% 
  mutate(study_start = as_date(study_start),
         study_end = as_date(study_end)) %>% 
  mutate(study_ndays = as.numeric(difftime(study_end, study_start, units = "days"))) %>% 
  glimpse()

subids_dates <- study_dates %>% 
  pull(subid) %>% 
  unique()
```

### Locations

Confirm that locations exists and has some places
```{r}
locs <- vroom(here(path_shared, "locations.csv"), col_types = "cddcccccccccccdd",
              show_col_types = FALSE) %>% 
  mutate(subid = as.numeric(subid)) %>% 
  glimpse()

subids_locs <- locs %>% 
  pull(subid) %>% 
  unique

if(any(!(subids_dates %in% subids_locs))) stop("Missing location for some subids")
```



### GPS
```{r}
gps <-  vroom(here(path_shared, "gps.csv"), col_types = "ddTdccccdddd",
              show_col_types = FALSE) %>% 
  filter(subid %in% subids_dates) %>%   # limit to sample in study_dates
  glimpse()

#get all subids
subids_gps <- gps %>% 
  pull(subid) %>% 
  unique() %>% 
  print()

if(any(!(subids_dates %in% subids_gps))) stop("Missing gps for some subids")
```

Merge context into gps
```{r}
#enrich gps with context for one subid
enrich_subid <- function(a_subid, gps, locs) {
  gps <- gps %>% 
    filter(subid == a_subid)
  
  locs <- locs %>% 
    filter(subid == a_subid)
  
  enriched <- gps %>% 
    bind_cols(map2_dfr(gps$lon, gps$lat, find_nearest_context, context = locs)) 
  
  return(enriched)
}

#future_map over subids
(n_core <- parallel::detectCores(logical = FALSE))
plan(multisession, workers = n_core)

enriched <- subids_gps %>% 
  future_map_dfr(enrich_subid, gps = gps, locs = locs) %>% 
  left_join(locs, by = c("subid", "context_id")) %>% 
  select(-lat.y, -lon.y, -accuracy, -speed_kmh, -altitude_meters, -direction,
         -data_type) %>% 
  rename(lat = lat.x, lon = lon.x) %>% 
  relocate(subid)
```


###  Brief EDA

```{r}
enriched %>%  
  glimpse

enriched %>% 
  pull(subid) %>% 
  unique %>% 
  length
```

```{r}
enriched %>% 
  tabyl(subid) %>% 
  arrange(n)

enriched %>% 
  tabyl(subid) %>%
  summarize(min(n), max(n))

enriched %>% 
  tabyl(subid) %>%
  pull(n) %>% 
  hist

enriched %>% 
  tabyl(subid) %>%
  filter(n < 5000) %>% 
  pull(n) %>% 
  hist
```

```{r}
enriched %>% 
  summarize(across(.fns = ~sum(is.na(.)))) %>% 
  glimpse()
```

```{r}
enriched %>% tabyl(type)
enriched %>% tabyl(drank)
enriched %>% tabyl(alcohol)
enriched %>% tabyl(emotion)
enriched %>% tabyl(risk)
enriched %>% tabyl(avoid)
enriched %>% tabyl(vacation)
```

### EDA for participant removal based on missing days

```{r}
enriched <- enriched %>% 
  mutate(time = with_tz(time, tzone = "America/Chicago")) %>% 
  mutate(gps_date = as_date(time)) %>%
  left_join(select(study_dates, subid, study_start, study_end, study_ndays), by = "subid") %>% 
  filter(gps_date >= study_start,
         gps_date <= study_end) %>% 
  glimpse()

enriched %>% 
  tabyl(subid) %>% 
  arrange(n)

# number of days with gps points
gps %>% 
  group_by(subid, gps_date) %>% 
  summarize(n()) %>% 
  group_by(subid) %>% 
  summarize(gps_ndays = n()) %>% 
  left_join(select(study_dates, subid, study_ndays), by = "subid") %>% 
  mutate(days_diff = gps_ndays - study_ndays) %>% 
  arrange(days_diff) %>% 
  print %>% 
  pull(days_diff) %>% 
  hist(main = "Days of Missing GPS")
```




### Save enriched GPS
Saving xz compressed for use on CHTC for feature engineering

```{r}
enriched %>% 
  vroom_write(here(path_gps, "gps_enriched.csv.xz"), delim = ",")
```