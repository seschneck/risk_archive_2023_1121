---
title: "Untitled"
format: pdf
csl: https://raw.githubusercontent.com/jjcurtin/lab_support/main/rmd_templates/csl/elsevier-vancouver.csl
geometry: margin=.5in
fontsize: 11pt
bibliography: paper_insight.bib
editor_options: 
  chunk_output_type: console
---



<!--General notes
Additional YAML formatting will need to be added once it's decided where this will be submitted. Tag Susan to handle that.

-->

```{r knitr_settings, include = FALSE}
# settings
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, cache = FALSE, 
                      message = FALSE)
options(knitr.kable.NA = '')
knitr::opts_chunk$set(fig.pos = "ht", out.extra = "")
```

```{r setup, include = FALSE}
library(knitr)
# library(yardstick) # for roc_curve
library(kableExtra)
library(janitor)
# library(corx)
library(patchwork)
library(ggtext)
library(consort)
library(tidyverse)
library(tidymodels)
library(tidyposterior)
library(cowplot)

theme_set(theme_classic()) 
```


```{r paths}
switch (Sys.info()[['sysname']],
        # PC paths
        Windows = {
          path_input <- "P:/studydata/risk/chtc/insight"
          path_processed <- "P:/studydata/risk/data_processed/insight"
          path_models <- "P:/studydata/risk/models/insight"
          path_shared <- "P:/studydata/risk/data_processed/shared"},

        # IOS paths
        Darwin = {
          path_input <- "/Volumes/private/studydata/risk/chtc/insight"
          path_processed <- "/Volumes/private/studydata/risk/data_processed/insight"
          path_models <- "/Volumes/private/studydata/risk/models/insight"
          path_shared <- "/Volumes/private/studydata/risk/data_processed/shared"},
        
        # Linux paths
        Linux = {
          path_input <- "~/mnt/private/studydata/risk/chtc/insight"
          path_processed <- "~/mnt/private/studydata/risk/data_processed/insight"
          path_models <- "~/mnt/private/studydata/risk/models/insight"
          path_shared <- "~/mnt/private/studydata/risk/data_processed/shared"}
        )
```

```{r load_data}
```

# Abstract

<!-- background -->

<!-- 
In the United States, alcohol use disorder (AUD) affects nearly 30 million adults annually and 30% of adults over the course of their lifetime. Of those who receive treatment, 2/3 relapse within 6 months. Static measures of self-efficacy have proven to be predictive of next lapse risk, but are less understood in the context of continuous self-monitoring. 

GEF: I love the key concepts you are portraying here! What I'm taking away is: 1) AUD is prevalent and costly, 2) individuals rarely receive (effective) treatment, 3) self-efficacy/self-monitoring is/can be predictive of future lapse, and 4) this construct hasn't been assessed dynamically. I think all of these should be in the abstract, so great job! My edits focused on simplifying those messages (e.g., removing numbers/statistics) and helping to link ideas 1/2 to ideas 3/4 (i.e., why are self-efficacy and continuous monitoring relevant and important?).
-->

Alcohol use disorder (AUD) remains a highly prevalent and costly disorder. One component of clinician-delivered treatment for AUD is self-monitoring, whereby individuals monitor their risk of returning to alcohol use between sessions and post-treatment. Self-monitoring requires reflecting on self-efficacy: How likely am I to drink alcohol in the future? Self-efficacy has typically been assessed statically and infrequently; however, insight into self-efficacy likely changes dynamically as risk changes throughout recovery.

<!-- purpose -->

<!-- 
The current study measured individuals' insight into their own lapse risk via daily EMAs situated within a digital therapeutic. 

GEF: This sounds great. I made some small tweaks to bring in the self-efficacy language & to highlight our key questions
-->

The current study investigated 1) whether dynamically measured self-efficacy can predict dynamic lapse risk; 2) if a single, static self-efficacy measurement can predict dynamic lapse risk; and 3) if the prediction model can be improved by including additional features based on relevant risk factors.

<!-- methods -->

<!--
We developed three separate models that provide week-level probabilities of a future lapse back to alcohol use using a baseline alcohol abstinence self-efficacy (AASE)-only score, a once-daily measure of self-efficacy, and a 'full-feature' model including 4 times daily EMA responses. Model features were based on scores collected through ecological momentary assessment (EMA). 

GEF: I like how you adapted the EMA paper methods to fit our project. Some small edits below.
-->

Participants (*N*=151; 51% male; mean age = 41; 87% White, 97% Non-Hispanic) in early recovery (1–8 weeks of abstinence) from AUD provided 4x daily ecological momentary assessments (EMAs) for up to three months. We developed three models to predict the probability of lapse back to alcohol use in the next week. Models differed by included features: 1) raw self-efficacy ("How likely are you to drink alcohol in the next week?"), measured via 1X daily EMAs; 2) total Alcohol Abstinence Self-Efficacy (AASE) score measured at study intake; or 3) features derived from 10 items assessing relapse-relevant constructs (e.g., self-efficacy, craving, stress), measured via 4X daily EMAs. We used grouped, nested cross-validation to select best models and evaluate the performance of those best models. 

<!-- results -->

<!-- 
Participants (*N*=151; 51% male; mean age = 41; 87% White, 97% Non-Hispanic) in early recovery (1–8 weeks of abstinence) from alcohol use disorder provided 4x daily EMA for up to three months. [Include results here that show the all feature model predicted the best, with with an ___, the once-daily measure of self-efficacy performed well at____, and finally, the baseline AASE-only had some predictive value for dichotomous outcomes but was insufficient for prediction and clinical utility]. 

GEF: You included all the right information here. I changed the structure/presentation slightly to match up with our questions. I also moved the participant sentence earlier to provide that context earlier on. You're right that in the paper, reporting on demographics of the sample would be in the Results, but I think providing who our sample is and the general procedure of the study fits best earlier here where we have less space
-->

Dynamically measured self-efficacy predicted next-week lapse risk quite accurately (area under the receiver operating curve [auROC]=0.80). Static self-efficacy did not predict next-week lapse risk well (auROC=0.59) and predicted worse than dynamic self-efficacy (posterior probability >99.99%). Including additional EMA items improved performance compared to dynamic self-efficacy alone (all-EMA model auROC=0.88, posterior probability )

<!-- discussion/conclusion/impact -->
This suggests dynamic measures of self-efficacy are accurate in predicting future lapse risk over time and may be further improved via inclusion of other data collected via EMA when available.

# Introduction

## Background

AUD/SUDs are problematic and prevalent and require lifelong care/monitoring.

Self-monitoring is thought to be a valuable and necessary tool during recovery from AUD and other SUDs.It promises a cost-effective, accessible, and easy-to-use tool when integrated in digital therapeutics
-   Anecdotally - encouraged by clinicians, prompted by many self-help tools/apps, etc. Considered to be a productive component of CBT in the treatment of SUDs
-   Empirically? Findings are mixed and data is limited. In one review of 41 studies investigating self-monitoring on substance use outcomes, only 29% found a helpful effect (like reducing substance use) (Gass et al., 2021). 63% had no effect and 8% found it to be detrimental. This ambiguity may be at least partially explained by a lack of research. For instance, in another review of 191 web-based interventions designed to decrease alcohol consumption, only ten met quality criteria for inclusion and only 1 was an RCT (Bewick et al., 2008).No empirical evidence was provided that apps could serve as an intervention. 
-   Consider ARCP framing - there is a strongly held belief about monitoring perhaps without **sufficient evidence** and/or without **sufficient nuance** to how monitoring should be implemented

Self-monitoring, insight, and/or confidence in remaining abstinent/pursuing treatment goals has traditionally been measured statically.
-   Measures like the AASE are often used to assess an individual's "long-term" likelihood of remaining abstinent. 
-   Efficacy can be hard to capture consistently because it is context-specific. Since its development in 1994, the AASE, built on Bandura's construct of self-efficacy, has been used with frequency. The 20-item scale demonstrates high-internal consistency as well as strong indices of reliability and validity (DiClemente et al., 1994). The shortened 12-item scale shares in these attributes (McKiernan et al., 2011)
-   Scores from measures like the AASe may be used at the end of treatment/end of study/etc. to estimate an individual's future likelihood of staying abstinent
-   It is **unclear if or how clinicians use or might use static measures like the AASE** (e.g., in determining treatment conclusion or retention, in determining level of care, etc.)
-   negative affect, social positive, physical and other concerns, and withdrawal and urges

It is **unclear how well static measures like the AASE predict future lapse/relapse outcomes**.
-    A baseline measure of self-efficacy is predictive of first lapse similar to how daily-measurements of self-efficacy are predictive of subsequent lapses, demonstrating the relative stability of efficacy (with daily fluctuation in AASE also predictive of following relapses)

Risk of lapse/relapse is best understood **dynamically**.
-   Relapse prevention model
-   Fluctuating risk over time due to fluctuating proximal and distal risk factors that interact fluidly with one another
-   Thus, **monitoring dynamic risk of lapse likely requires dense, dynamic monitoring to be effective**.

**EMA** offers a method to assess individuals' insight into risk of lapse densely and longitudinally.
-   This has/has not? (look at review) been done before (check Y/N, duration of monitoring, question being asked, etc. - Ariela to add from review)
-   When done, it has/has not? (look at review - Ariela to add from review) been done with **true prediction**.

Continuous monitoring with EMA can be embedded within a digital therapeutic context that can allow for monitoring of other risk factors and offer access to supports and tools to be used throughout recovery.

## Current study

We measured individuals' insight into their own lapse risk via daily EMA surveys situated within a digital therapeutic.
-   Thus, insight was assessed in a way that was: **cued** (i.e., prompted to reflect), **contextualized** (i.e., asked at the end of the survey assessing 9 other relevant risk factors, with three additional daily surveys asking similar question - a LOT of reflection!), and **continuous** (i.e., daily assessments).
-   Question was asked about individuals' risk of lapsing in the next week, so we used corresponding 1-week outcome windows that began at the time of the daily survey completion.

The purpose of this project is to determine:

1. The accuracy of individuals' insight into their lapse risk (in the next week)

*Relevant model configurations*
1 week windows ~ insight only (raw)

2. Whether dynamic assessment of insight and lapse risk has more predictive value than static assessment of insight and/or lapse risk

*Relevant model configurations*
1 week windows ~ insight only (raw)
1 week windows ~ AASE total score only --> comparable to how an individual might currently use their own post-treatment insight to assess ongoing lapse risk
Dichotomous lapse (whether an individual lapsed or not during study period) ~ AASE total score only --> comparable to how a clinician might use post-treatment insight to determine whether an individual should leave or continue treatment

3. Whether models that take advantage of full EMA data & feature engineering can predict lapse risk more accurately than insight alone

*Relevant model configurations*
1 week windows ~ insight only (raw)
1 week windows ~ all EMA items (4x daily surveys, engineered features)

# Method
<!-- copy HEAVILY from EMA paper -->

## Research Transparency
<!-- 
make sure 21-word solution is accurate
make sure to update OSF links
-->

## Participants
<!-- identify if any participants excluded because of data exclusions (though maybe not here, still report on 151 sample?) -->

## Procedure

## Measures

### EMA

### AASE

### Individual Differences
<!-- just to characterize data, not included in analyses -->

## Data Analytic Strategy

### Lapse Labels

### Feature Engineering

### Model Training and Evaluation

# Results

## Demographic and Clinical Characteristics

<!-- Demographics table-->

## Model Performance

### auROC

### Model Comparisons

### Feature Importance

# Discussion

<!-- all just notes -->

Cued, contextualized, continuous insight can accurately predict dynamic risk of alcohol lapse.

Why is this good?

-   Shows the value of insight/self-monitoring that we have long suspected/believed, now with empirical evidence and with theoretical nuance regarding the need for dynamic assessment of predictor and outcome

-   Within a dtx environment, accurate insight may lead to increased: trust in the algorithm (risk feedback aligns with insight), engagement with the app (d/t trust, but also perhaps reengagement following a period of lower use), self-efficacy, etc.

-   There may be opportunities for decreased burden (following additional research) if insight can be used in place of a full survey (still with cued daily assessment & ask to reflect on contextual factors), but we don't know how that will do on its own

AASE has some predictive value for dichotomous (and even rolling week window) outcomes (supports value of self-monitoring) but is insufficient for prediction and clinical utility.

Dynamic insight measurement can predict better than static AASE measurement.

Prediction algorithms grow more accurate when we add in other EMA features from 4X daily surveys - we can do our best prediction when we use more information. 

Cued insight only permits an individual to know:
* with relatively high accuracy if they are going to lapse
Full ema context permits an individual to know:
* with even higher accuracy if they are going to lapse
* whether that lapse risk represents a change from previous risk levels
* whether their self-efficacy/insight is changing from previous levels
* the key contributing factors that are driving that changing risk
* the key factors that may be targeted to most effectively reduce high and/or increasing lapse risk

\clearpage

# References
