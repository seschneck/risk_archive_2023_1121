---
title: "Evaluates ROC over time for the Insight study (version `r version`)"
author: "Gaylen Fronk"
date: "`r lubridate::today()`"
output: 
  html_document:
    toc: true 
    toc_depth: 4
format:
  html:
    embed-resources: true
editor_options: 
  chunk_output_type: console
---

### Set Up Environment

```{r set_values}
study <- "insight"
version <- "v2"
cv <- "nested"
```

Function conflicts
```{r, packages_workflow}
#| message: false
#| warning: false

# source
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_ml.R?raw=true")

# handle conflicts
options(conflicts.policy = "depends.ok")
tidymodels_conflictRules()
```

Packages for script
```{r, packages_script}
#| message: false
#| warning: false

library(tidyverse)
library(tidymodels)
library(lubridate)
```

Source support functions
```{r source_functions}
# EDA
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true")

# CHTC support functions
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/chtc/static_files/fun_chtc.R?raw=true")
```

Absolute paths
```{r, absolute_paths}
switch (Sys.info()[['sysname']],
        # PC paths
        Windows = {
          path_input <- str_c("P:/studydata/risk/chtc/", study)
          path_processed <- str_c("P:/studydata/risk/data_processed/", study)
          path_models <- str_c("P:/studydata/risk/models/", study)
          path_knits <- str_c("P:/studydata/risk/knits/", study)},
        
        # IOS paths
        Darwin = {
          path_input <- str_c("/Volumes/private/studydata/risk/chtc/", study)
          path_processed <- str_c("/Volumes/private/studydata/risk/data_processed/",
                                  study)
          path_models <- str_c("/Volumes/private/studydata/risk/models/", study)
          path_knits <- str_c("/Volumes/private/studydata/risk/knits/", study)},
        
        # Linux paths
        Linux = {
          path_input <- str_c("~/mnt/private/studydata/risk/chtc/", study)
          path_processed <- str_c("~/mnt/private/studydata/risk/data_processed/",
                                  study)
          path_models <- str_c("~/mnt/private/studydata/risk/models/", study)
          path_knits <- str_c("~/mnt/private/studydata/risk/knits/", study)}
)
```

Chunk Defaults
```{r defaults}
#| include: false

knitr::opts_chunk$set(attr.output='style="max-height: 500px;"')

options(tibble.width = Inf)
options(tibble.print_max = Inf)
```

Knit to specific directory
```{r, eval = FALSE, include=FALSE}
# Render knit file manually to different location

rmarkdown::render(input = file.path("insight/ana/ana_roc_over_time.qmd"),
                  output_dir = file.path(path_knits),
                  output_file = str_c("ana_roc_over_time.html"),
                  env = new.env())
```

## Read in data

Features file
```{r}
d <- read_csv(file.path(path_processed, "features_v1.csv"), 
              show_col_types = FALSE) |> 
  mutate(dttm_label = with_tz(dttm_label, tz = "America/Chicago"))

```

Dates
```{r}
dates <- read_csv(file.path(path_processed, "study_dates.csv"),
                  show_col_types = FALSE) |> 
  mutate(across(c(study_start, data_start, study_end, ema_end),
                ~ with_tz(., tz = "America/Chicago")))
```

Combine
```{r}
d <- d |> 
  left_join(dates, by = "subid")

glimpse(d)
```

## Make study_week variable

```{r}
d <- d |> 
  mutate(study_duration = difftime(dttm_label, data_start, units = "secs")) |> 
  mutate(study_week = case_when(
    study_duration > (13 * 604800) ~ "week_14",
    study_duration > (12 * 604800) ~ "week_13",
    study_duration > (11 * 604800) ~ "week_12",
    study_duration > (10 * 604800) ~ "week_11",
    study_duration > (9 * 604800) ~ "week_10",
    study_duration > (8 * 604800) ~ "week_9",
    study_duration > (7 * 604800) ~ "week_8",
    study_duration > (6 * 604800) ~ "week_7",
    study_duration > (5 * 604800) ~ "week_6",
    study_duration > (4 * 604800) ~ "week_5",
    study_duration > (3 * 604800) ~ "week_4",
    study_duration > (2 * 604800) ~ "week_3",
    study_duration > 604800 ~ "week_2",
    study_duration > 1 ~ "week_1",
  ))
```

Remove unnecessary variables
```{r}
d <- d |> 
  select(-study_start, -data_start, -study_end, -ema_end, -study_duration)
```

## Function

```{r}
fit_predict_eval <- function(row_num, splits, configs_best){
  
  config_best <- configs_best |> 
    slice(row_num) |> 
    rename(n_jobs_in = n_jobs, accuracy_in = accuracy, 
           bal_accuracy_in = bal_accuracy,
           roc_auc_in = roc_auc, sens_in =  sens, spec_in = spec, 
           ppv_in = ppv, npv_in = npv)
  
  split_num <- config_best$outer_split_num
  feature_set <- config_best$feature_set
  
  d_in <- training(splits$splits[[split_num]]) |> 
    select(-study_week)  # not used for training
  d_out <- testing(splits$splits[[split_num]])
  
  rec <- build_recipe(d = d_in, config = config_best)
  
  rec_prepped <- rec |> 
    prep(training = d_in, strings_as_factors = FALSE)
  
  feat_in <- rec_prepped |> 
    bake(new_data = NULL)
  
  model_best <- fit_best_model(config_best, feat_in, "classification")
  
  feat_out <- rec_prepped %>% 
    bake(new_data = d_out)
  
  # metrics from raw (uncalibrated) predictions for held out fold
  preds_prob <- predict(model_best, feat_out,
                        type = "prob")
  preds_class <- predict(model_best, feat_out, type = "class")$.pred_class
  
  # combine raw and calibrated probs
  probs_out <- tibble(outer_split_num = rep(split_num, nrow(preds_prob)),
                      feature_set = rep(feature_set, nrow(preds_prob)),
                      study_week = d_out$study_week,
                      prob_raw = preds_prob[[str_c(".pred_", y_level_pos)]],
                      label = d_out$y) |> 
    mutate(label = fct_recode(label, "No lapse" = "no",
                              "Lapse" = "yes"))
  
  return(probs_out)
}
```

## Get best configurations

Read in aggregate CHTC metrics for inner folds
```{r read_inner_metrics}
metrics_raw <- 
  read_csv(file.path(path_models, 
                     str_c("inner_metrics_", version, "_", cv, ".csv")), 
           col_types = "iiiiccdddcdddddddc") |> 
  filter(outcome == "1week") |> 
  glimpse()
```

Average metrics for each configuration across inner folds for each outer fold/outcome/feature set
```{r best_model_1}
metrics_avg <- metrics_raw |> 
  group_by(outcome, algorithm, feature_set, 
           hp1, hp2, hp3, resample, outer_split_num) |> 
  summarize(across(c(accuracy, bal_accuracy, roc_auc, sens, spec, ppv, npv),
                   median),
            n_jobs = n(), .groups = "drop") |> 
  relocate(outer_split_num, n_jobs) |> 
  arrange(outer_split_num, desc(roc_auc))

```

Best configuration for each outer fold/outcome/feature set
```{r best_model_2}
configs_best <- metrics_avg |> 
  group_by(outcome, feature_set, outer_split_num) |> 
  arrange(desc(roc_auc)) |> 
  slice(1) |> 
  ungroup() |> 
  relocate(roc_auc, .before = accuracy) 

configs_best <- configs_best |> 
  mutate(row_id = 1:nrow(configs_best)) 

configs_best |> print_kbl()

```

## Get all probabilities from held-out folds & tag with study_week

```{r}
if (file.exists(file.path(path_models, 
                          str_c("probs_by_week_", version, ".csv")))) {
  
  message("Probabilities by week already exist for this version. Reading in file. If you need to re-calculate the probabilities, delete the file.")
  
  all_probs <- read_csv(file.path(path_models, str_c("probs_by_week_", version, ".csv")),
                        show_col_types = FALSE) |> 
    mutate(label = factor(label, levels = c("Lapse", "No lapse")))
  
} else {
  
  batch_names <- list.dirs(path_input, full.names = FALSE, recursive = FALSE)
  
  batch_names <- batch_names[str_detect(batch_names, "train") & 
                               str_detect(batch_names, cv) &
                               str_detect(batch_names, version) &
                               str_detect(batch_names, "1week")] 
  batch_name <- batch_names[1] 
  # all TC files are the same except feature_set, which we set manually within map loop
  
  source(file.path(path_input, batch_name, "input", "training_controls.R"))
  
  d <- format_data(d)
  
  splits <- d %>% 
    make_splits(cv_resample_type, cv_resample, cv_outer_resample, 
                cv_inner_resample, cv_group, seed_splits)
  
  all_probs <- configs_best$row_id |> 
    map(\(row_num) fit_predict_eval(row_num, splits, configs_best)) |> 
    list_rbind()
  
  rm(splits)
  
  all_probs |> 
    write_csv(file.path(path_models, str_c("probs_by_week_", version, ".csv")))
}

```

## Get ROC over time by model

```{r}
all_roc <- all_probs |> 
  group_by(outer_split_num, feature_set, study_week) |> 
  mutate(roc = roc_auc_vec(prob_raw, truth = label, event_level = "first"))
```

## Visualize

Single median value for plotting
```{r}
med_roc <- all_roc |> 
  select(feature_set, study_week, outer_split_num, roc) |> 
  group_by(feature_set, study_week) |> 
  summarize(median_roc = median(roc)) |> 
  ungroup()
```

Plots
```{r}
med_roc |> 
  mutate(study_week = factor(study_week,
                             levels = str_c("week_", 1:12))) |> 
  ggplot(mapping = aes(x = study_week, y = median_roc, 
                       group = feature_set, color = feature_set)) +
  geom_line() +
  theme(legend.position = "bottom")

med_roc |> 
  mutate(study_week = factor(study_week,
                             levels = str_c("week_", 1:12))) |> 
  ggplot(mapping = aes(x = study_week, y = median_roc, 
                       group = feature_set, color = feature_set)) +
  geom_point() +
  geom_smooth(method = "loess") +
  geom_smooth(method = "lm", se = FALSE, linetype = "dashed", linewidth = .75) +
  theme(legend.position = "bottom")
  
```

Tables by model/week
```{r}
med_roc |> 
  pivot_wider(names_from = feature_set, values_from = median_roc,
              names_prefix = "roc_") |> 
  relocate(roc_insight_only, .before = "roc_all") |> 
    mutate(study_week = factor(study_week,
                             levels = str_c("week_", 1:12))) |> 
  arrange(study_week)
```








