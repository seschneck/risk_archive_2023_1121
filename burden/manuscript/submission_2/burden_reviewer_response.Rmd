---
output:
  pdf_document:
    includes:
      in_header: !expr here::here("..", "lab_support", "rmd_templates", "latex", "header.tex")
    template: !expr here::here("..", "lab_support", "rmd_templates", "latex", "nih_latex_template.tex")
    keep_tex: no
    number_sections: no
    latex_engine: xelatex
    citation_package: default
header-includes:
  - \usepackage{helvet}
  - \usepackage[T1]{fontenc}
  - \renewcommand\familydefault{\sfdefault}
geometry: margin=.5in
fontsize: 11pt
---

Dear Dr. Ruis,

We are pleased to submit a revised version of our manuscript "Acceptability of personal sensing among people with alcohol use disorder: Observational study" (Manuscript No. JMU 41833) for your review at JMIR mHealth and uHealth. We thank the reviewers and you for the thoughtful commentary. We believe that these suggestions have greately improved our manuscript. We have included detailed repsonses to each of the reviewers' concerns beginning on the following page.

If we can provide any additional information that can be of assistance, please do not hesitate to ask. Thank you in advance for your consideration.

Sincerely,

Kendra Wyant, Hannah Moshontz, Stephanie Ward, Gaylen Fronk, & John Curtin

---


Below, we delineate the reviewers’ and action editor’s questions, concerns, and requests regarding our original submission, and we detail the ways in which we have addressed each item. All comments have been copied verbatim to avoid misinterpretation. For brevity, we have removed comments regarding the strengths of the manuscript, but we appreciated these complimentary remarks.

# Action Editor's Comments

## AE.1: Please address the formatting issues identified in the checklist above.

## AE.1.1: Please add subheadings under Introduction/Methods/Results/Discussion (if you use WinWord, apply the style "Heading 2" to IMRD headings, and the styles "Heading 3" to subsequent subheadings). Do not use italics or bold keywords or sentences in paragraphs in lieu of subheadings/sub-subheadings.
The Heading Introduction has been added to encompass subheadings in the introduction section of the manuscript.

## AE.1.2: Shorten the paper. Some of the material/tables/formulas can be moved to a Multimedia Appendix.
<!--dont worry about this one yet but do consider generating a list of what can be moved to an appendix-->

## AE.1.3: For all results for which you provide a relative result (percentage), you should also provide the absolute number, e.g. "132 out of 264 participants (50%) said that...". If n is less than 100, do not use decimal points in your percentages. Otherwise, do not use more than one decimal place.
The authors have revised the manuscript so that they now report absolute numbers with all relative percentages and round percentages to one decimal place.

## AE.2: Please include relevant IRB approval numbers.
The IRB approval number (Study #2015-0780) has been added to the methods section (see paragraph 2).

## AE.3: Consider reformatting Fig 1. in to a more traditional CONSORT diagram: https://www.consort-statement.org/consort-statement/flow-diagram
We have reformatted Figure 1 to fit a traditional CONSORT diagram. 

## AE.4: The qualitative data presented in the Discussion really belongs in the Results section.
We have moved the qualitative data from the Discussion to Table 7 in the Results section.

## AE.5: The paper is quite lengthy and I'm not convinced all material, especially the lengthy content in the introduction, is required.
<!--hold off but will have same response as AE1.1=2-->


# Reviewer B Comments:

## RB.1: A systematic methodology and rationale for selecting the specific personal sensing types explored was not presented.
<!--assigned to JC-->

## RB.2: Prior work applying personal sensing to intoxication in general and AUD specifically with clear motivation for each of the sensing methods selected could be improved.
<!--assigned to JC-->

## RB.3: In Table 3, the number of subjects who discontinued prior to completing enrolment whose reasons are unknown seems quite large. Feels like a lot of information is lost there
<!-- will mention as limitation -->

## RB.4: It would have been great to rank user acceptance to various personal sensing streams
<!--assigned to JC-->

## RB.5: It would have been great to compare or propose comparing in future, the response of subjects with AUD with those without AUD. User willingness for subjects under treatment may differ from those not under treatment.
<!-- add as future direction-->

## RB.6: Paper has several typos that should be checked and fixed including: - One a day would be great -> Once a day would be great
We originally left grammatical errors and typos in the participant quotations to preserve authenticity. We have since edited these quotations to make them more readable (see Table 7). 

## RB.7: The paper uncovered some interesting findings. However, the reasons behind some user responses and preferences were not clear. A strong qualitative study or follow-on focus group might have provided more answers. The paper does contain some qualitative research in the form of free form user responses but that falls short.
<!-- acknowledge as limitation and future direction-->

## RB.8: The lack of racial or ethnic information of participants substantially influences the significance of study's findings as racial and ethnic differences are likely to be great and provide additional insights.
Racial and ethnic information of participants was previously reported in Table 1 (see page 18). We now make our sample demographics more salient by providing a summary in the first paragraph of the results section.



# Reviewer E Comments:

## RE.1: The biggest flaw regarding acceptability is the inability for formal measures of compliance on the more sensitive data collection measures (location, logs, text message content). Considering all participants opted-in to provide data...this is how one would know if they were quietly opting out (by turning the sensor collection off).
<!--need to acknowledge as limitation but also consider if analyses can highlight that everyone provided some data and maybe some is a pretty reasonable size suggesting reasonable comfort-->

## RE.2: The 50/50 split on sex is concerning. A 50/50 fit would imply the recruitment mechanism made this split. Thus how did you exactly assess choice at consent and enrollment when you probably had screeners built in to ensure the sex split was 50/50?
<!--assigned to JC-->

## RE.3: The inclusion of data in the discussion is a problem to me and the discussion section reads more like a qualitative review than a discussion. Also, there is no limitation section. I think the discussion should greatly be reduced to be comment solely on the data presented in the paper.
We have removed the qualitative data from the discussion. Additionally, we had previously presented limitations throughout the discussion. We have updated this to now have a limitations section and have increased our consideration of limitations based on reviewer critiques. 

## RE.4: How much were participants paid for opting in--exactly. How much for each opt-in and where they only asked once to opt-in to tracking or could they add a feature on at any time?
This information was previously reported in the methods (see Behavioral Measures of Acceptability) and the discussion (see Section 5). We now make it more salient in the methods section (see Behavioral Measures of Acceptability) by listing a breakdown of bonuses participants could earn by choosing to opt in to each sensing method each month.


# Reviewer K Comments:

## RK.1: Would authors explain more about why certain sensing methods were compensated while others were not? In particular, the passive sensing methods require little effort were the ones more likely to be compensated. If anything, this provides greater support for their conclusions, still the question is why reimbursement there and not for other data?
All sensing methods were compensated. We now explicitly state the breakdown of payments in the methods section (see Behavioral Measures of Acceptability section in Measures).

## RK.2: The questions about the willingness to wear devices ends with the phrase, "check-in for one year if it helped with my recovery." Would the authors comment on the possible effect of that on participant responses? Alcohol use disorder is a relapsing disorder with few guarantees in treatment. How would people respond if the question were phrased, "i would be willing to check in for one year to TEST it helped with my recovery."? My point is, the way the question is phrased may be affecting the answer, particularly in this early stage of testing.
<!-- will address in limitations section-->

## RK.3: There is a relevant paper that might be worth including on the longevity of tracker use: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6952057/#:~:text=Based%20on%20these%20results%20from,have%20accounted%20for%20the%20NE. How would the authors respond to this letter?
<!-- Will address in limitations section:
Article assesses novelty effect of activity tracker apps and websites. They find that the novelty period for fitbit users is about 3 months. Will mention as limitation to a 3 month study and future direction to look over longer periods of time.-->

## RK.4: Can the authors comment on their use of "undecided" versus neutral as an anchor on the scale? They define it as 'neutral' but it is not necessarily clear that is so. For some questions, such terms could have different response sets.
<!--assigned to JC-->

## RK.5: How were the alcohol use disorder questions and diagnosis collected? was there a standard survey? There appear to be footnotes perhaps explaining this? but I did not find them.
Alcohol diagnoses were based on a self-report questionnaire of DSM-5 symptoms (See footnote 1 on page 71). Alcohol use disorder questions were collected through a lab-made self-report survey. All surveys are made available on our OSF page (direct link to surveys is https://osf.io/du2an). 

## RK.6: Is there a count of how many disabled locations or deleted texts/phone calls occurred? This is important bc as someone might near a bar, a warning text could be sent. however, if people can disable their location, then the method is nugatory
<!-- will address in limitations section-->

## RK.7: The compensation for participants should be in the methods section esp as it has bearing here.
We added the financial compensation to the Methods section (see paragraph 5 in the Participants section).

## RK.8: Reference for this: This is notable given that individuals with alcohol use disorder may have been expected to present with more barriers to smartphone ownership than that of the general population.
<!-- Discuss removing this with JC as literature seems to suggest there would not be more barriers to smartphone ownership. Barriers that might exist: pay-as-you-go cellphone plans, frequent number changes, data plan restrictions.-->

## RK.9: Providing cellphones for those who did not have one should also go in the methods
We added that cellphones were provided to participants who did not have one in the Methods section (see paragraph 5 in the Participants section).

## RK.10: Suggest that authors switch to word 'adhere' instead of 'comply' as that is the more accepted term for many reasons.
We thank the reviewer for bringing this to our attention and have switched to the word adhere instead of comply throughout the manuscript. 

# Reviewer O Comments:

General comments (**JOHN**: I am leaving these general comments in because there are some criticisms here - not sure if we need to address these broader points or just the specific ones below)
=============
This paper reports on an interesting experiment using several different methods of mobile sensing. The. Participants were recruited as a part of a bigger project and reimbursed for using mobile sensing. One main finding of the study is that individuals interested in personal sensing can sustain their commitment to providing personally sensed data over time with limited drop-off, in a research setting.

Other conclusion presented is less clearly supported by the methods and results presented. Some of the methods of the study should be better explained. The sample reached and framing of the offer to use sensing is important to be able to interpret the results. The results are also limited by technical and data problems in several of the sensing methods, and by the questions used to asses acceptability. The qualitative statements from users are interesting, but are not covered in methods or results.

## RO.1: The abstract should include more information about method relevant to the current aim.
<!-- need to do some edits to abstract and state that here-->

## RO.2: The title of the larger project suggests that sensors would be used to prevent relapse. Is there a risk that participants have been motivated by clinical benefit even if that was not the intention?
 <!-- we expand on our discussion about costs and beneifits in this research study vs. clinical implmentation and implications for these differences in the discussion-->
 
## RO.3: The different methods are presented as opt-in, but it is important to know in detail how this was presented. Were the participants free to choose want they wanted and interested in or were they more or less expected to agree and more had to opt-out of certain methods?
<!-- we clarify this in the  methods; cite page-->

## RO.4: Background provide a good overview of the use of mobile sensors in psychiatry. But it is sometimes unclear when the statements refer to alcohol or substance use and what is more general in mental health.

<!-- we now clarify this-->

## RO.5: The authors write regarding EMA that “compliance concerns may be limited to applications with patients with substance use disorders rather than all psychiatric disorders more generally”. This is confusing when the study is about substance use.

<!-- maybe limit intro more to aud/sud as possible and then be clear when it is broader mental health.  Maybe also make clear that these methods are releavant to all psychiatric disoerders-->



## RO.6: What previous research have been made on the different sensing methods for alcohol use disorder? (Bae 2018, Stevenson 2020, Scott 2020…)

<!-- now reference these papers and expand a bit more on this review-->

## RO.7: The data as it is presented should not be presented as “transparent window into the feasibility”.
We have removed this language from the manuscript.

## RO.8: Thank you for making documentation available via OSF. Could be improved by adding participant information about the project and recruitment messages.

<!--IRB text about recruiting strategies:
1. Potential participants will informed of the opportunity to participate in a research study by their treatment providers. They will be instructed to contact study staff once they have established alcohol abstinence.
2. Participants can sign a release of information with their provider. This would allow the provider to provide study staff with the potential participant's name and contact number, so that we may initiate contact with them. Participants will sign a release of information form giving permission for their provider to release only this minimal information. A copy of the flyer has been uploaded below. They can also decline to sign the release, but still take a flyer and initiate contact with us as in step 1.
3. There may also be community recruitment using flyers posted at locations such as AA meetings or in Metro buses, or on Facebook/Craigslist; and digital flyers posted on the UW Health AppSpace screens in UW Hospitals and Clinics. Business cards will be available to participants who request our information to spread by word-of-mouth.
4. There will be email blasts to unique, non-overlapping 2000 person subsets of the UW faculty and staff, graduate and professional students, using the UW Mass Email system. No person will be emailed more than once.
5. There will be ads in local Madison area newspapers such as the Cap City Times, Isthmus, Coop News, etc.-->

## RO.9: What was the aim of the parent project. Will/are the results from the parent study available?

<!-- JJC; will provide a bit more context regarding parent study.   Papers in prep-->

## RO.10: What was the reason for the sobriety requirement? Many people with AUD prefer a moderation goal. Would not the sensors work just as well with moderate consumption?

<!-- JJC; requirement was for parent project aims which focused on lapses, which don't occur for people who are pursuing moderation-->

## RO.11: It is hard to understand the reason for using geolocation and cellular communication logs without reading the OSF material, and even after that it is somewhat unclear. It probably connects to the aim or the parent study, but should be made clear in methods here.

<!-- JJC; again reference expanded context-->

## RO.12: Did the participants receive any additional information on the purpose of each method connected to their alcohol use?

<!-- NO.  Add sentence to method-->

## RO.13: There are no references to the acceptability questions having been previously used or tested in research. The fact that the answers were significantly higher than neutral is interpreted as the method being acceptable. But without any other comparison it is impossible to know what explains this result. It is common in evaluations that participants give over average grade for many different reasons like social desirability or lack of willingness to give feedback.

<!-- limitation-->

## RO.14: All of the questions are framed in a lack of negative way rather than from a negative to a positive experience of the different methods.


## RO.15: How was the content of text messages analyzed?

<!-- not relevant for this study-->

## RO.16: Most of the result section show detailed information about the results on the acceptability questions. On most of the questions and sensing methods the users mean ratings are similar. Could this be an indication on problems with the questions and/or sampling rather than that the methods really are acceptable for people with AUD?

<!-- substantial variation across participants.  Correlations between methods are moderate but not high-->  

## RO.17: In table 2, does Types of Treatment refer to recent treatment or lifetime?

## RO.18: In table 3 Not wanting to stay sober, cancelling no/show and unknown are clearly the main reasons for discontinuing. This is interpreted as not being about acceptability. Can you really know and say that?

<!-- latter two categories are identified as possibility related to acceptability--> 

## RO.19: Have this high sampling density been used in substance use before? Would it be used clinically and if so for what reasons?

<!-- JJC context of parent project--> 

## RO.20: It is not clinically reasonable to remind people with 2-3 months abstinence about their alcohol use problems 4 times a day. This could have side effects on emotional state or drinking. Have you considered this?

<!-- not part of this study.   That said, clinicians to encourage ongoing (daily) self-monitoring as very important, particularly early in recovery.   -->


## RO.21: There is a lack of data on cravings, alcohol use and on qualitative data from users in the result section.

<!-- JJC not relevant-->

## RO.22: How was lapses/relapses among the participants handled?

<!-- instructed that no consequences for participation;  Offered brief motivational session to return to abstinence if desired.  Add to method-->

## RO.23: There are several indications that the individuals in this sample are different from other individuals with alcohol use disorder in regard to their perception of mobile sensing. The large proportion of people agreeing to participate in research probably depend a lot on where and with what message the participants were recruited and what information they got about the project. This should be described in much more detail for others to be able to get the same results and to be able to judge what, if anything, the high proportion of people agreeing say about personal sensing.

<!--more detail on recruiting added-->

## RO.24: The authors write: “Participants concerned about sharing passively sensed private information such as their moment-by-moment location or cellular communications would likely have had these concerns from the beginning such that they would not have consented, enrolled, and then opted-in to provide these sensitive data.” This is probably true, not only for passively sensed private information, but for participation in the study as a whole. Those less likely to accept mobile sensing would not have consented, enrolled, and then opted-in.
<!--  agreed.  acknowledged.  Yet most consented-->

## RO.25: The qualitative data in the form of statements from paticipants on their experience is interesting. How where they collected and analyzed? Why are they not presented as results?
We have updated the manuscript per feedback from an earlier reviewer and now present the qualitative data as results (Table 7) and describe the methods for data collection in the Methods section.

## RO.26: The study demonstrate that active sensing methods are feasible for this type of research setting but not for clinical applications.

<!-- discussion; future direction-->

## RO.27: The overall aim of the use of these kind of sensors in treatment should be made more clear. Why should this information be gathered about people with alcohol use disorder? Is it for feedback, self-control and self-knowledge, for external control/pressure to stay abstinent and/or for other purposes?

<!-- JJC context of parent project-->

## RO.28: Who made repeated attempts to reschedule before discontinuing, researchers or participants?
We now clarify in Table 3 that participants made attempts to reschedule before ultimately discontinuing. 

## RO.29: The authors argue that reimbursing participant is common in many studies and even in clinical settings. Even if this is true it is a big limitation than should be clear from the abstract. The way the sample was recruited and informed about the project should be more clearly discussed under benefits.

<!-- JJC clarify compensation for research participants.  Clarify that compensation for specific outcomes (e.g., abstinence, compliance with other requirements) is used as clinical intervention--> 

## RO.30: The section on how trust is important is interesting. How might participants trust in researchers affect the results?
We discuss how trust may be different in research vs clinical setting in the discussion (section 6, paragraphs 2-3). We also state that "Trust is also likely to affect the overall acceptability of personal sensing data" and "Acceptability may depend on who employs personal sensing and who has access to the raw and processed data" (discussion section 6 paragraph 1). 


## RO.31: How were the themes presented in the discussion chosen?

<!-- JJC  organization of results determined by us--> 

## RO.32: Its contradictory to state that the sensing was acceptable “without explicit clinical benefits to the participants” and at the same time that they can be “used for clinical applications”. The study does not appear to be designed to test clinical application, but recruited a population that seem clinical, with ongoing substance use among many participants.

<!-- JJC clarify no clinical benefits in this study because sensing was not used to help participants here.  Sensing COULD be used to help participants in subsequent applications;   Refernce parent project-->