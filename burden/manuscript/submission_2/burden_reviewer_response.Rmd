---
output:
  pdf_document:
    includes:
      in_header: !expr here::here("..", "lab_support", "rmd_templates", "latex", "header.tex")
    template: !expr here::here("..", "lab_support", "rmd_templates", "latex", "nih_latex_template.tex")
    keep_tex: no
    number_sections: no
    latex_engine: xelatex
    citation_package: default
header-includes:
  - \usepackage{helvet}
  - \usepackage[T1]{fontenc}
  - \renewcommand\familydefault{\sfdefault}
geometry: margin=.5in
fontsize: 11pt
---

Dear Dr. Ruis,

We are pleased to submit a revised version of our manuscript "Acceptability of personal sensing among people with alcohol use disorder: Observational study" (Manuscript No. JMU 41833) for your review at JMIR mHealth and uHealth. We thank the reviewers and you for the thoughtful commentary. We believe that these suggestions have greately improved our manuscript. We have included detailed repsonses to each of the reviewers' concerns beginning on the following page.

If we can provide any additional information that can be of assistance, please do not hesitate to ask. Thank you in advance for your consideration.

Sincerely,

Kendra Wyant, Hannah Moshontz, Stephanie Ward, Gaylen Fronk, & John Curtin

---


Below, we delineate the reviewers’ and action editor’s questions, concerns, and requests regarding our original submission, and we detail the ways in which we have addressed each item. All comments have been copied verbatim to avoid misinterpretation. For brevity, we have removed comments regarding the strengths of the manuscript, but we appreciated these complimentary remarks.

# Action Editor's Comments

## AE.1: Please address the formatting issues identified in the checklist above.

## AE.1.1: Please add subheadings under Introduction/Methods/Results/Discussion (if you use WinWord, apply the style "Heading 2" to IMRD headings, and the styles "Heading 3" to subsequent subheadings). Do not use italics or bold keywords or sentences in paragraphs in lieu of subheadings/sub-subheadings.
The Heading Introduction has been added to encompass subheadings in the introduction section of the manuscript.


## AE.1.2: Shorten the paper. Some of the material/tables/formulas can be moved to a Multimedia Appendix.

<!--dont worry about this one yet but do consider generating a list of what can be moved to an appendix-->


## AE.1.3: For all results for which you provide a relative result (percentage), you should also provide the absolute number, e.g. "132 out of 264 participants (50%) said that...". If n is less than 100, do not use decimal points in your percentages. Otherwise, do not use more than one decimal place.
The authors have revised the manuscript so that they now report absolute numbers with all relative percentages and round percentages to one decimal place.


## AE.2: Please include relevant IRB approval numbers.
The IRB approval number (Study #2015-0780) has been added to the methods section (see paragraph 2).



## AE.3: Consider reformatting Fig 1. in to a more traditional CONSORT diagram: https://www.consort-statement.org/consort-statement/flow-diagram
We have reformatted Figure 1 to fit a traditional CONSORT diagram. 


## AE.4: The qualitative data presented in the Discussion really belongs in the Results section.

<!-- lets hold off on this-->

## AE.5: The paper is quite lengthy and I'm not convinced all material, especially the lengthy content in the introduction, is required.

<!--hold off but will have same response as AE1.1=2-->


# Reviewer B Comments:

## RB.1: A systematic methodology and rationale for selecting the specific personal sensing types explored was not presented.

## RB.2: Prior work applying personal sensing to intoxication in general and AUD specifically with clear motivation for each of the sensing methods selected could be improved.


## RB.3: In Table 3, the number of subjects who discontinued prior to completing enrolment whose reasons are unknown seems quite large. Feels like a lot of information is lost there

## RB.4: It would have been great to rank user acceptance to various personal sensing streams

## RB.5: It would have been great to compare or propose comparing in future, the response of subjects with AUD with those without AUD. User willingness for subjects under treatment may differ from those not under treatment.

<!-- add as future direction-->

## RB.6: Paper has several typos that should be checked and fixed including: - One a day would be great -> Once a day would be great
<!-- hold off to determine how we handle comments but do acknowledge that the spelling errors were in the original comments, not our errors-->

## RB.7: The paper uncovered some interesting findings. However, the reasons behind some user responses and preferences were not clear. A strong qualitative study or follow-on focus group might have provided more answers. The paper does contain some qualitative research in the form of free form user responses but that falls short.

<!-- acknowledge as limitation and future direction-->


## RB.8: The lack of racial or ethnic information of participants substantially influences the significance of study's findings as racial and ethnic differences are likely to be great and provide additional insights.
Racial and ethnic information of participants was previously reported in Table 1 (see page 18). We now make our sample demographics more salient by providing a summary in the first paragraph of the results section.



# Reviewer E Comments:

## RE.1: The biggest flaw regarding acceptability is the inability for formal measures of compliance on the more sensitive data collection measures (location, logs, text message content). Considering all participants opted-in to provide data...this is how one would know if they were quietly opting out (by turning the sensor collection off).

<!--need to acknowledge as limitation but also consider if analyses can highlight that everyone provided some data and maybe some is a pretty reasonable size suggesting reasonable comfort-->

## RE.2: The 50/50 split on sex is concerning. A 50/50 fit would imply the recruitment mechanism made this split. Thus how did you exactly assess choice at consent and enrollment when you probably had screeners built in to ensure the sex split was 50/50?

## RE.3: The inclusion of data in the discussion is a problem to me and the discussion section reads more like a qualitative review than a discussion. Also, there is no limitation section. I think the discussion should greatly be reduced to be comment solely on the data presented in the paper.

<!--remove qualitative data from discussion.   Acknowledge the limitations were presented throughout previously but that we now put them in a a limitations section and have increased our consideration of limitations based on reviewer critiques-->

## RE.4: How much were participants paid for opting in--exactly. How much for each opt-in and where they only asked once to opt-in to tracking or could they add a feature on at any time?
This information was previously reported in the methods (see Behavioral Measures of Acceptability) and the discussion (see Section 5). We now make it more salient in the methods section (see Behavioral Measures of Acceptability) by listing a breakdown of bonuses participants could earn by choosing to opt in to each sensing method each month.


# Reviewer K Comments:

## RK.1: Would authors explain more about why certain sensing methods were compensated while others were not? In particular, the passive sensing methods require little effort were the ones more likely to be compensated. If anything, this provides greater support for their conclusions, still the question is why reimbursement there and not for other data?
All sensing methods were compensated. We now explicitly state the breakdown of payments in the methods section (see Behavioral Measures of Acceptability section in Measures).

## RK.2: The questions about the willingness to wear devices ends with the phrase, "check-in for one year if it helped with my recovery." Would the authors comment on the possible effect of that on participant responses? Alcohol use disorder is a relapsing disorder with few guarantees in treatment. How would people respond if the question were phrased, "i would be willing to check in for one year to TEST it helped with my recovery."? My point is, the way the question is phrased may be affecting the answer, particularly in this early stage of testing.

## RK.3: There is a relevant paper that might be worth including on the longevity of tracker use: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6952057/#:~:text=Based%20on%20these%20results%20from,have%20accounted%20for%20the%20NE. How would the authors respond to this letter?

<!-- 
Article assesses novelty effect of activity tracker apps and websites. They find that the novelty period for fitbit users is about 3 months. Will mention as limitation to a 3 month study and future direction to look over longer periods of time.
-->

## RK.4: Can the authors comment on their use of "undecided" versus neutral as an anchor on the scale? They define it as 'neutral' but it is not necessarily clear that is so. For some questions, such terms could have different response sets.

## RK.5: How were the alcohol use disorder questions and diagnosis collected? was there a standard survey? There appear to be footnotes perhaps explaining this? but I did not find them.
Alcohol diagnoses were based on a self-report questionnaire of DSM-5 symptoms (See footnote 1 on page 71). Alcohol use disorder questions were collected through a lab-made self-report survey. All surveys are made available on our OSF page (direct link to surveys is https://osf.io/du2an). 

## RK.6: Is there a count of how many disabled locations or deleted texts/phone calls occurred? This is important bc as someone might near a bar, a warning text could be sent. however, if people can disable their location, then the method is nugatory

## RK.7: The compensation for participants should be in the methods section esp as it has bearing here.

<!--compensation from consent:

You will be paid $20/hour for all time spent in the laboratory (estimated at 11.5 hours across screening, intake and 3 follow-up visits = $230). You will be paid $40 for completing a take home assignment about the locations you frequent, and the people with who you communicate with monthly. All participants will be compensated for using their own smartphone at the rate of $66 per month ($198 over the course of the study) to offset the cost of your cell phone service. All participants who complete the study will be given a $99 study completion bonus. You will receive compensation for each visit, at the subsequent visit. 
Bus transportation to and from study visits will be provided to all participants as needed. 
The remainder of your compensation is contingent on achieving targets for missing data thresholds for our mobile measures. You will be paid monthly for each month you achieve < 10% missing information in each measure category. The monthly payments for each measure were set to encourage meeting or exceeding this target missing data threshold based on estimated burden to you for each category. 
Specifically:

•	You will be paid $25/month for achieving this reporting goal for the daily text surveys. A survey is coded as missing if it is not completed within 1 hour of receipt of the text message prompt.

•	You will be paid $25/month for achieving this reporting goal for the daily audio surveys. 

•	You will be paid $15/month for achieving this goal for the sleep logs collected by the Beddit sleep sensor.  
	
•	You will be paid $10/month for achieving this goal with respect to GPS location information (coded as missing only if you choose to turn off location monitoring services).
Total compensation could be valued up to approximately $800 755 ($230 for study visits; $40 for take-home assignment, $198 for use of your own smartphone, $99 study completion bonus; bus passes for all visits (valued at $8); $75 for text survey messages; $75 for audio survey messages; $45 for Beddit sleep logs; $30 for GPS location information). All monetary study compensation is provided in the form of checks. 
You will receive compensation by check at each subsequent visit. No payment is received at your first (screening) visit. You will be paid up to $60 at your second (intake) visit, up to $216 at your third visit, up to $171 at your fourth visit, and up to $240 at your fifth (final) visit. A check for remaining study bonuses (up to $10560) will be mailed to you 1 week after your final visit.
If you do withdraw prior to the end of the study, you will receive $20 per hour for your time spent in the lab, as well as whatever reporting bonuses have earned for each part of the study completed thus far. 
-->


## RK.8: Reference for this: This is notable given that individuals with alcohol use disorder may have been expected to present with more barriers to smartphone ownership than that of the general population.

## RK.9: Providing cellphones for those who did not have one should also go in the methods

## RK.10: Suggest that authors switch to word 'adhere' instead of 'comply' as that is the more accepted term for many reasons.
We thank the reviewer for bringing this to our attention and have switched to the word adhere instead of comply throughout the manuscript. 

# Reviewer O Comments:

General comments (**JOHN**: I am leaving these general comments in because there are some criticisms here - not sure if we need to address these broader points or just the specific ones below)
=============
This paper reports on an interesting experiment using several different methods of mobile sensing. The. Participants were recruited as a part of a bigger project and reimbursed for using mobile sensing. One main finding of the study is that individuals interested in personal sensing can sustain their commitment to providing personally sensed data over time with limited drop-off, in a research setting.

Other conclusion presented is less clearly supported by the methods and results presented. Some of the methods of the study should be better explained. The sample reached and framing of the offer to use sensing is important to be able to interpret the results. The results are also limited by technical and data problems in several of the sensing methods, and by the questions used to asses acceptability. The qualitative statements from users are interesting, but are not covered in methods or results.

## RO.1: The abstract should include more information about method relevant to the current aim.

## RO.2: The title of the larger project suggests that sensors would be used to prevent relapse. Is there a risk that participants have been motivated by clinical benefit even if that was not the intention?

## RO.3: The different methods are presented as opt-in, but it is important to know in detail how this was presented. Were the participants free to choose want they wanted and interested in or were they more or less expected to agree and more had to opt-out of certain methods?

## RO.4: Background provide a good overview of the use of mobile sensors in psychiatry. But it is sometimes unclear when the statements refer to alcohol or substance use and what is more general in mental health.

## RO.5: The authors write regarding EMA that “compliance concerns may be limited to applications with patients with substance use disorders rather than all psychiatric disorders more generally”. This is confusing when the study is about substance use.

## RO.6: What previous research have been made on the different sensing methods for alcohol use disorder? (Bae 2018, Stevenson 2020, Scott 2020…)

## RO.7: The data as it is presented should not be presented as “transparent window into the feasibility”.

## RO.8: Thank you for making documentation available via OSF. Could be improved by adding participant information about the project and recruitment messages.

<!--IRB text about recruiting strategies:
1. Potential participants will informed of the opportunity to participate in a research study by their treatment providers. They will be instructed to contact study staff once they have established alcohol abstinence.
2. Participants can sign a release of information with their provider. This would allow the provider to provide study staff with the potential participant's name and contact number, so that we may initiate contact with them. Participants will sign a release of information form giving permission for their provider to release only this minimal information. A copy of the flyer has been uploaded below. They can also decline to sign the release, but still take a flyer and initiate contact with us as in step 1.
3. There may also be community recruitment using flyers posted at locations such as AA meetings or in Metro buses, or on Facebook/Craigslist; and digital flyers posted on the UW Health AppSpace screens in UW Hospitals and Clinics. Business cards will be available to participants who request our information to spread by word-of-mouth.
4. There will be email blasts to unique, non-overlapping 2000 person subsets of the UW faculty and staff, graduate and professional students, using the UW Mass Email system. No person will be emailed more than once.
5. There will be ads in local Madison area newspapers such as the Cap City Times, Isthmus, Coop News, etc.-->

## RO.9: What was the aim of the parent project. Will/are the results from the parent study available?

## RO.10: What was the reason for the sobriety requirement? Many people with AUD prefer a moderation goal. Would not the sensors work just as well with moderate consumption?

## RO.11: It is hard to understand the reason for using geolocation and cellular communication logs without reading the OSF material, and even after that it is somewhat unclear. It probably connects to the aim or the parent study, but should be made clear in methods here.

## RO.12: Did the participants receive any additional information on the purpose of each method connected to their alcohol use?

## RO.13: There are no references to the acceptability questions having been previously used or tested in research. The fact that the answers were significantly higher than neutral is interpreted as the method being acceptable. But without any other comparison it is impossible to know what explains this result. It is common in evaluations that participants give over average grade for many different reasons like social desirability or lack of willingness to give feedback.

## RO.14: All of the questions are framed in a lack of negative way rather than from a negative to a positive experience of the different methods.

## RO.15: How was the content of text messages analyzed?

## RO.16: Most of the result section show detailed information about the results on the acceptability questions. On most of the questions and sensing methods the users mean ratings are similar. Could this be an indication on problems with the questions and/or sampling rather than that the methods really are acceptable for people with AUD?

## RO.17: In table 2, does Types of Treatment refer to recent treatment or lifetime?

## RO.18: In table 3 Not wanting to stay sober, cancelling no/show and unknown are clearly the main reasons for discontinuing. This is interpreted as not being about acceptability. Can you really know and say that?

## RO.19: Have this high sampling density been used in substance use before? Would it be used clinically and if so for what reasons?

## RO.20: It is not clinically reasonable to remind people with 2-3 months abstinence about their alcohol use problems 4 times a day. This could have side effects on emotional state or drinking. Have you considered this?

## RO.21: There is a lack of data on cravings, alcohol use and on qualitative data from users in the result section.

## RO.22: How was lapses/relapses among the participants handled?

## RO.23: There are several indications that the individuals in this sample are different from other individuals with alcohol use disorder in regard to their perception of mobile sensing. The large proportion of people agreeing to participate in research probably depend a lot on where and with what message the participants were recruited and what information they got about the project. This should be described in much more detail for others to be able to get the same results and to be able to judge what, if anything, the high proportion of people agreeing say about personal sensing.

## RO.24: The authors write: “Participants concerned about sharing passively sensed private information such as their moment-by-moment location or cellular communications would likely have had these concerns from the beginning such that they would not have consented, enrolled, and then opted-in to provide these sensitive data.” This is probably true, not only for passively sensed private information, but for participation in the study as a whole. Those less likely to accept mobile sensing would not have consented, enrolled, and then opted-in.

## RO.25: The qualitative data in the form of statements from paticipants on their experience is interesting. How where they collected and analyzed? Why are they not presented as results?

## RO.26: The study demonstrate that active sensing methods are feasible for this type of research setting but not for clinical applications.

## RO.27: The overall aim of the use of these kind of sensors in treatment should be made more clear. Why should this information be gathered about people with alcohol use disorder? Is it for feedback, self-control and self-knowledge, for external control/pressure to stay abstinent and/or for other purposes?

## RO.28: Who made repeated attempts to reschedule before discontinuing, researchers or participants?

## RO.29: The authors argue that reimbursing participant is common in many studies and even in clinical settings. Even if this is true it is a big limitation than should be clear from the abstract. The way the sample was recruited and informed about the project should be more clearly discussed under benefits.

## RO.30: The section on how trust is important is interesting. How might participants trust in researchers affect the results?

## RO.31: How were the themes presented in the discussion chosen?

## RO.32: Its contradictory to state that the sensing was acceptable “without explicit clinical benefits to the participants” and at the same time that they can be “used for clinical applications”. The study does not appear to be designed to test clinical application, but recruited a population that seem clinical, with ongoing substance use among many participants.