---
output:
  pdf_document:
    includes:
      in_header: !expr here::here("..", "lab_support", "rmd_templates", "latex", "header.tex")
    template: !expr here::here("..", "lab_support", "rmd_templates", "latex", "nih_latex_template.tex")
    keep_tex: no
    number_sections: no
    latex_engine: xelatex
    citation_package: default
header-includes:
  - \usepackage{helvet}
  - \usepackage[T1]{fontenc}
  - \renewcommand\familydefault{\sfdefault}
csl: "national-library-of-medicine-grant-proposals.csl"
geometry: margin=.5in
fontsize: 11pt
bibliography: paper_ema.bib
---

```{r knitr_settings, include = FALSE}
# settings
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, cache = FALSE, 
                      message = FALSE)
options(knitr.kable.NA = '')
knitr::opts_chunk$set(fig.pos = "ht", out.extra = "")
```

```{r setup, include = FALSE}
library(knitr)
library(yardstick) # for roc_curve
library(kableExtra)
library(janitor)
library(corx)
library(patchwork)
library(ggtext)
library(consort)
library(tidyverse)
library(tidymodels)
library(tidyposterior)

theme_set(theme_classic()) 
```


```{r paths}
switch (Sys.info()[['sysname']],
        # PC paths
        Windows = {
          path_models <- "P:/studydata/risk/models/ema"
          path_data_shared <- "P:/studydata/risk/data_processed/shared"
          path_data_ema <- "P:/studydata/risk/data_processed/ema"},
        # IOS paths
        Darwin = {
          path_models <- "/Volumes/private/studydata/risk/models/ema"
          path_data_shared <- "/Volumes/private/studydata/risk/data_processed/shared"
          path_data_ema <- "/Volumes/private/studydata/risk/data_processed/ema"}
       )
```

```{r load_data}
# Table data
disposition <- read_csv(file.path(path_data_ema, "disposition.csv"), col_types = "ccDDcccccccccc")
screen <- read_csv(file.path(path_data_shared, "screen.csv"), col_types = vroom::cols()) %>% 
  filter(subid %in% subset(disposition, analysis == "yes")$subid)

# Predictions data
preds_week<- readRDS(file.path(path_models, "resample_preds_best_all_1week_0_v4_kfold.rds"))
preds_day<- readRDS(file.path(path_models, "resample_preds_best_all_1day_0_v4_kfold.rds"))
preds_hour<- readRDS(file.path(path_models, "resample_preds_best_all_1hour_0_v4_kfold.rds")) 

# posterior probabilites
pp <- readRDS(file.path(path_models, "posteriors_all_allwindows_0_v4_kfold.rds"))

# ROC curves
roc_week <- preds_week %>% 
  roc_curve(prob, truth = truth) %>% 
  mutate(model = "1week")

roc_day <- preds_day %>% 
  roc_curve(prob, truth = truth) %>% 
  mutate(model = "1day")

roc_hour <- preds_hour%>% 
  roc_curve(prob, truth = truth) %>% 
  mutate(model = "1hour")

roc_all <- roc_week %>% 
  bind_rows(roc_day) %>% 
  bind_rows(roc_hour)

# PR curves
pr_week <- preds_week %>% 
  pr_curve(prob, truth = truth) %>% 
  mutate(model = "1week")

pr_day <- preds_day %>% 
  pr_curve(prob, truth = truth) %>% 
  mutate(model = "1day")

pr_hour <- preds_hour%>% 
  pr_curve(prob, truth = truth) %>% 
  mutate(model = "1hour")

pr_all <- pr_week %>% 
  bind_rows(pr_day) %>% 
  bind_rows(pr_hour)

# Raw SHAPS
shap_raw_week <- readRDS(file.path(path_models, "imp_shap_raw_all_1week_0_v4.rds")) %>% 
  group_by(variable) %>% 
  slice(1) %>%   
  ungroup() %>% 
  arrange(mean_value)
shap_raw_day <- readRDS(file.path(path_models, "imp_shap_raw_all_1day_0_v4.rds")) %>% 
  group_by(variable) %>% 
  slice(1) %>%   
  ungroup() %>% 
  arrange(mean_value)
shap_raw_hour <- readRDS(file.path(path_models, "imp_shap_raw_all_1hour_0_v4.rds")) %>% 
  group_by(variable) %>% 
  slice(1) %>%   
  ungroup() %>% 
  arrange(mean_value)

# Grouped SHAPS
shap_grouped_week <- readRDS(file.path(path_models, "imp_shap_grouped_all_1week_0_v4.rds")) %>% 
  group_by(group) %>% 
  summarize(mean_value = mean(abs(shap)), .groups = "drop") %>% 
  arrange(mean_value)
shap_grouped_day <- readRDS(file.path(path_models, "imp_shap_grouped_all_1day_0_v4.rds")) %>% 
  group_by(group) %>% 
  summarize(mean_value = mean(abs(shap)), .groups = "drop") %>% 
  arrange(mean_value)
shap_grouped_hour <- readRDS(file.path(path_models, "imp_shap_grouped_all_1hour_0_v4.rds")) %>% 
  group_by(group) %>% 
  summarize(mean_value = mean(abs(shap)), .groups = "drop") %>% 
  arrange(mean_value)
```

# Introduction

Alcohol and other substance use disorders are highly prevalent and costly.  In 2019, the National Survey on Drug Use and Health estimated that more than 20 millions adults in the United States had some form of active substance use disorder (SUD) in that year [@substanceabuseandmentalhealthservicesadministrationKeySubstanceUse2020a]. Nearly 15 million (5.6%) had an active alcohol use disorder (AUD), specifically [@samhsa2019NationalSurvey; @samhsa2019NationalSurveyb]. Many more adults (25.8%) reported that they engaged in hazardous alcohol misuse in the past month [@samhsa2019NationalSurveya]. Alcohol is the third leading preventable cause of death, with approximately 140,000 deaths per year [@centersfordiseasecontrolandpreventionAlcoholPublicHealth; @esserEstimatedDeathsAttributable2022].  Overall, the US Surgeon General reported that alcohol misuse cost the United States $249 billion in 2016 alone [@administrationusFacingAddictionAmerica2016]. 

Existing interventions for AUD are effective when delivered. Clinician-delivered cognitive-behavioral therapy [@mchughCognitiveBehavioralTherapySubstance2010; @lieseCognitiveBehavioralTherapyAddictive2022] and mindfulness-based relapse prevention [@bowenMindfulnessBasedRelapsePrevention2021] interventions for AUD are consistently grouped among the interventions that have the highest level of empirical support[@yaghubiEffectivenessMindfulnessbasedRelapse2018; @ramadasEffectivenessMindfulnessBasedRelapse2021; @goldbergMindfulnessbasedInterventionsPsychiatric2018a]. Other therapeutic approaches and supports such as Motivational Interviewing [@millerMotivationalInterviewingHelping2012], Contingency Management[@bigelowTheoreticalEmpiricalFoundations1999; @carrollCognitiveBehavioralInterventions2017a;@magillMetaAnalysisCognitiveBehavioralTherapy2019; @dutraMetaanalyticReviewPsychosocial2008; @mchughCognitiveBehavioralTherapySubstance2010; @administrationusFacingAddictionAmerica2016], and participation in support groups[@bigelowTheoreticalEmpiricalFoundations1999] are also effective.

Unfortunately, the vast majority of people with AUD do not receive any treatment due to well-known barriers.
For example, in 2019, fewer than 1 in 13 adults who had an active AUD in the past year received any treatment[@samhsa2019NationalSurveyc].  More troubling still, failure to access treatment is associated with demographic factors including race, ethnicity, geographic region, and socioeconomic status that further increase mental health disparities [@wangFailureDelayInitial2005; @MentalHealthReport1999; @generalusMentalHealthCulture2001; @mauraMentalHealthDisparities2017; @novakChangesHealthInsurance2018]. This lack of treatment results from well-known barriers[@jacobsonUsingDigitalTherapeutics2023] to receiving clinician-delivered mental healthcare that includes issues related to: (1) High costs for treatment, lack of insurance, and/or inadequate coverage [@bishopAcceptanceInsurancePsychiatrists2014; @fullenImpactMedicareMental2020; @cohenThreeCrowdClients2006; @winkelmanHealthInsuranceTrends2016]; (2) Vastly inadequate numbers of providers [@satianiProjectedWorkforcePsychiatrists2018; @nationalcenterforhealthworkforceanalysisNationalProjectionsSupply2015]; (3) Limited access in rural communities [@andrillaGeographicVariationSupply2018a; @MentalHealthRural; @pollackThereShortageRural2021]; (4) Long wait lists for first appointments and inconvenient appointment times (e.g., during working hours which may require time off from work)[@harveyEvidencebasedPsychologicalTreatments2015; @kowalewskiPreliminaryInvestigationWait2011; @PsychiatryWaitList2022; @tribune-starMentalHealthCrisis]; (5) Transportation issues that pose barriers for many across geographic regions and can be severe in rural communities [@sommersGeographicLocationMental1989; @whettenDoesDistanceAffect2006]; and (6) Stigma, intersectional stigma, and discrimination against individuals with AUD/SUD from the public generally [@yangStigmaSubstanceUse2017; @turanChallengesOpportunitiesExamining2019; @jackson-bestStigmaIntersectionalitySystematic2018], but also from healthcare professionals [@vanboekelStigmaHealthProfessionals2013; @vistorteStigmatizingAttitudesPrimary2018; @thornicroftDiscriminationHealthCare2007].

Digital therapeutics can address these barriers to deliver interventions cost-effectively and at scale.  Digital therapeutics are "apps" that are used to prevent, treat, or manage a medical disorder including AUD or other mental illnesses [@digitaltherapeuticsallianceDigitalTherapeuticsDefinition2019].  They are used to deliver evidence-based interventions and supports to patients independently or concurrently with medications or clinician-delivered mental healthcare. Because digital therapeutics are typically provided to patients as apps on their smartphones, they reduce or eliminate many of the availability, accessibility, and acceptability barriers that exist for in-person, clinician-delivered mental healthcare[@jacobsonUsingDigitalTherapeutics2023].  Recent Pew Research Center survey data indicate high rates (~85% in April 2021) of smartphone ownership among adults in the US overall with little variation in these rates across race, ethnicity, socioeconomic status, and geographic setting (e.g., urban, suburban, rural)[@pewresearchcenterMobileFactSheet2021]. Furthermore, people with SUD also have generally high rates of mobile technology use [@collinsFactorsAssociatedPatterns2016].  This allows digital therapeutics to provide on-demand therapeutic support, which can reduce time constraints associated with receiving care at limited appointment times or after long waiting periods.  Digital therapeutics can remove geographic and other transportation barriers associated with traveling to treatment.  Digital therapeutic support may be less stigmatizing because it can be provided anonymously in the privacy of the patient's home.  This may be particularly important for patients with stigmatized conditions like AUD and/or other stigmatized identities [@munozUsingEvidencebasedInternet2010].  Finally, digital therapeutics can scale up access to mental healthcare because of the low marginal costs to provide care to additional patients once the app is developed [@jacobsonUsingDigitalTherapeutics2023; @aspvallCosteffectivenessInternetDeliveredVs2021; @velezEvaluationCostutilityPrescription2021; @wangEconomicModelingReSETO2021].

<!--
### A6. A-CHESS is effective.
A-CHESS has a substantial evidence base from both RCTs and field studies to establish its feasibility, acceptability, and effectiveness to support patients' recovery from AUD/SUD [@hochstatterEffectMHealthIntervention2021; @mckayEfficacyComparativeEffectiveness2022; @hochstatterPotentialInfluencesCOVID192021; @yooSmartphonebasedSupportGroup2020; @hochstatterMobileHealthIntervention2019; @johnstonUsingSmartphonesImprove2019; @muroffOutcomeStudyCASACHESS2019; @mckayEffectsAutomatedSmartphone2018; @glassTreatmentSeekingMechanism2017a; @muroffUseSmartphoneRecovery2017; @scottPilotStudyFeasibility2017; @gustafsonEffectBundlingMedicationassisted2016a; @lordImplementationSubstanceUse2016; @fordiiSuccessfulOrganizationalStrategies2015; @gustafsonSmartphoneApplicationSupport2014; @scottUsingMobilePhone2013; @mctavishHowPatientsRecovering2012; @gustafsonEHealthSolutionPeople2011; @gustafsonExplicatingEvidenceBasedTheoretically2011; @alagozTechnologyBasedInterventionsLateLife2016; @gustafsonjrUsingNIATxModel2016; @maresImplementingMHealthSystem2016; @quanbeckImplementingMobileHealth2018]. For example, a large RCT has established the effectiveness of A-CHESS for relapse prevention in patients who completed inpatient AUD treatment[@gustafsonSmartphoneApplicationSupport2014]. Patients using A-CHESS had 57% fewer risky drinking days and approximately double the odds of abstinence compared to those without A-CHESS over 12 months.  A-CHESS has also been documented to increase treatment retention, reduce re-admissions, and support engagement with medication-assisted treatments [@bottsMPOWERProjectResults2017a; @japuntichSmokingCessationInternet2006a; @pattenRandomizedClinicalTrial2006a]. Moreover, A-CHESS has been used successfully in field tests with patients from high-risk, marginalized, or under-served groups[@gustafsonCHESS10Years2002a] (e.g., veterans[@bottsMPOWERProjectResults2017a], Latinx patients[@muroffOutcomeStudyCASACHESS2019; @muroffUseSmartphoneRecovery2017], low SES Appalachian women [@johnstonUsingSmartphonesImprove2019], patients from medically under-served communities [@quanbeckImplementingMobileHealth2018], patients with Hepatitis C [@hochstatterEffectMHealthIntervention2021] or HIV[@hochstatterPotentialInfluencesCOVID192021], criminal justice-connected individuals [@johnsonPilotTestMobile2016a], and older adults [@alagozTechnologyBasedInterventionsLateLife2016; @gustafsonjrUsingNIATxModel2016]).
-->

Patients don't use digital therapeutics optimally.  Patients often don't engage with them as developers intended, and long-term engagement may not be sustained or matched to patients' needs [@hatchExpertConsensusSurvey2018; @lattieDigitalMentalHealth2019; @ngUserEngagementMental2019; @yeagerIfWeBuild2018].  The substantial benefits of digital therapeutics come from easy, 24/7 access to their many modules - their treatments, tools, and other support services.  However, this also presents patients with a challenge.  Patients may not know when they should use the app, which of the many modules in the app are best for them, and more precisely, which of the modules are best for them at that moment in time given the dynamic nature of relapse and recovery over time.  

AUD is a chronic, relapsing disorder, and recovery is a dynamic process [@brandonRelapseRelapsePrevention2007; @witkiewitzModelingComplexityPosttreatment2007; @mclellanDrugDependenceChronic2000].  Relapse probability is a complex, nonlinear function of numerous risk and protective factors that combine and interact to affect relapse timing and severity [@hendershotRelapsePreventionAddictive2011; @witkiewitzRelapsePreventionAlcohol2004; @huffordRelapseNonlinearDynamic2003a; @witkiewitzNonnormalityDivergencePosttreatment2007; @witkiewitzModelingComplexityPosttreatment2007]. Many of these factors are transient, which contributes to fluctuating relapse risk.  Urges, mood, lifestyle imbalances, self-efficacy, and motivation can all vary over time.  Social networks can evolve to be more protective or risky.  High risk situations can occur at any time.  

Clinical observations and research suggest that successful recovery requires life-long monitoring [@hendershotRelapsePreventionAddictive2011; @brandonRelapseRelapsePrevention2007; @huffordRelapseNonlinearDynamic2003a; @witkiewitzTherapistGuideEvidencebased2007; @witkiewitzModelingComplexityPosttreatment2007].  However, such monitoring is difficult given the dynamic, complex interplay of these many factors over time.  Nonetheless, ongoing monitoring of both lapse risk and the factors contributing to that risk, if possible, would allow the patient to adapt their lifestyle, behaviors, and supports to their changing needs.  In the context of digital therapeutic use, successful monitoring could guide the patient to engage with the optimal specific modules in the app to address the unique risks present at any distinct moment in time across their recovery. Such guided, adaptive engagement could potentially increase the app's effectiveness.  

<!--
### A8. Moment-by-moment personal sensing of intra- and interpersonal risk factors for AUD is now feasible[@epsteinPredictionStressDrug2020b; @suchtingUsingElasticNet2019; @hebertPredictingFirstSmoking2021a; @engelhardPredictingSmokingEvents2018; @mohrPersonalSensingUnderstanding2017a; @businelleUsingIntensiveLongitudinal2016; @soysterPooledPersonspecificMachine2022; @hebertEcologicalMomentaryIntervention2018; @moshontzProspectivePredictionLapses2021; @wyantAcceptabilityPersonalSensing2022; @chihPredictiveModelingAddiction2014; @curtinPersonalSensingTemporally2022; @baeMobilePhoneSensors2018a]. 
Curtin (PI) and other scientists at UW's Center for Health Enhancement Systems Studies (Gustafson, Co-I) and Northwestern's Center for Behavioral Intervention Technologies (Mohr, Kornfield, Co-Is) have been at the forefront of developing and implementing these sensing systems to monitor symptoms and/or lapse risk for patients with AUD, SUD, and other mental illness [@chihPredictiveModelingAddiction2014; @moshontzProspectivePredictionLapses2021; @wyantAcceptabilityPersonalSensing2022; @curtinPersonalSensingTemporally2022; @kornfieldWhatYouSay2018; @kornfieldDetectingRecoveryProblems2018; @saebRelationshipClinicalMomentary2015; @adlerMachineLearningPassive2022; @deangelDigitalHealthTools2022a; @meyerhoffEvaluationChangesDepression2021; @zhangPredictingDepressiveSymptom2021; @moshePredictingSymptomsDepression2021; @saebMobilePhoneDetection2017a; @mohrPersonalSensingUnderstanding2017a; @saebRelationshipMobilePhone2016; @henryHumanMachineTeaming2022]. In a seminal review, Mohr et al.[@mohrPersonalSensingUnderstanding2017a] describe methods and applications of personal sensing for both monitoring and future forecasting of mental health functioning.  Mohr defines personal sensing as "collecting and analyzing data from sensors embedded in the context of daily life with the aim of identifying human behaviors, thoughts, feelings, and traits".  The widespread proliferation of smartphones has made personal sensing powerful and practical today.  Smartphones can be used for ecological momentary assessments (i.e., repeated brief self-reports) and also passive, continuous sensing of geolocation, cellular communications (e.g., phone calls and text messages), activity level, sleep, and other raw signals that can be used to predict meaningful clinical outcomes. 

Mohr and his colleagues were arguably the first to employ personal sensing within a digital therapeutic for depression (i.e., Mobilize[@burnsHarnessingContextSensing2011a]). They have also been leaders in the effort to use passive sensing of geolocation to predict mental health symptoms and clinical outcomes.  In fact, they have developed key geolocation features (e.g., location variance, normalized entropy)[@saebRelationshipClinicalMomentary2015; @saebRelationshipMobilePhone2016] that are now used routinely in nearly all published research using sensed geolocation within predictive machine learning algorithms[@deangelDigitalHealthTools2022a].

In parallel lines of research, both Mohr and Curtin have developed techniques to increase the predictive power of geolocation features by contextualizing important locations visited by patients.  For example, Mohr and colleagues[@saebMobilePhoneDetection2017a] have passively identified the semantic meaning of locations (e.g., home, work, store, another person's home, medical office, place of worship) by capitalizing on distinct geo-temporal characteristics of these locations such as the days, hours, length, or frequency of visits, and related patterns of movement.  Curtin's collaborators have adopted a similar approach using geolocation data from his NIAAA project with patients with AUD[@liuGraphbasedRepresentationIdentifying2022; @curtinR01AA024391Dynamic2015]. In a separate vein, Curtin developed methods to obtain personalized context for frequently visited locations (e.g., previously drank at location, alcohol typically present, typical emotional experience, risky location)[@moshontzProspectivePredictionLapses2021; @curtinR01AA024391Dynamic2015].  Features based on this method contribute substantially to the performance of algorithms to predict future lapses back to drinking (see section A9).
 
Equally important, Curtin and colleagues have recently demonstrated the feasibility of sensing geolocation, ecological momentary assessments, and other signals for long durations (i.e., months) and that patients with AUD find sensing of these sensitive raw signals acceptable when appropriate privacy protections are provided [@wyantAcceptabilityPersonalSensing2022].  In a current NIDA protocol[@moshontzProspectivePredictionLapses2021], Curtin and colleagues are sensing these same signals in patients (current N > 250) with Opioid Use Disorder for up to one year [@moshontzProspectivePredictionLapses2021].
-->

<!--

### A9. Temporally precise prediction of future lapses back to alcohol use is now possible using these sensed features (i.e., predictors) as inputs to machine learning algorithms.  
Gustafson et al. developed one of the earliest machine learning prediction algorithms for future alcohol lapse [@chihPredictiveModelingAddiction2014]. This algorithm used features based on EMAs delivered by A-CHESS to predict patient-specific probabilities of future lapses back to drinking in the next week.  These lapse probabilities were updated weekly. The algorithm displayed good performance, with an area under receiver operating characteristic curve (AUC) of 0.83 assessed by 10-fold cross-validation.  
-->


# Method
## Research Transparency

## Participants
We recruited participants in early recovery (1-8 weeks of abstinence) from alcohol use disorder in Madison, Wisconsin, USA, to participate in a 3-month longitudinal study. Participants were recruited through print and targeted digital advertisements and partnerships with treatment centers. We required that participants:

1.  were 18 years of age or older,
2.  were able to write and read in English,
3.  had at least moderate alcohol use disorder (\>= 4 DSM-5 symptoms^[We measured DSM-5 symptoms with a self-report survey administered to participants during the in-person screening visit.]),
4.  were abstinent from alcohol for at least 1 week but no longer than 2 months,
5.  were willing to use a single smartphone (their personal phone or one provided by us) while enrolled in the study.

We also excluded participants if they exhibited severe symptoms of psychosis or paranoia^[Psychosis and paranoia were defined as scores greater than 2.2 or 2.8, respectively, on the psychosis or paranoia scales of the on the Symptom Checklist – 90 (SCL-90) [@derogatisSCL90OutpatientPsychiatric1973].]. 

One hundred ninety-two participants were eligible for enrollment. Of these participants, 191 consented to participate in the study at the screening session and 169 subsequently enrolled in the study at the enrollment visit which occurred approximately one week later. Fifteen participants discontinued prior to the first monthly follow-up visit. <!--GEF: might be a good place to refer to a consort diagram/enrollment chart (or maybe below the next paragraph?). i'm left wondering why these people didn't enroll - though not sure if we have that information-->

We excluded data from one participant who appeared to not have a goal of abstinence during their participation (i.e., they had lapses every day on study except for one day and reported they were uncertain if their goal was abstinence on the daily EMA and monthly follow-up surveys). We also excluded data from two participants who showed evidence of careless responding (e.g., completing 2-4 EMAs within an hour and providing different responses) and unusually low compliance (e.g., only 5 EMAs completed over one month), rendering their lapse labels unusable. 

Our final sample consisted of 151 participants. Participants provided study measures for one (N = 14), two (N = 6) or three (N = 131) months. Participants were mostly white (87%), roughly half were male (51%), and the mean age was 41 years (SD = 12). 

<!--KW: Discuss if we want any demographic/AUD history/mental health tables or flowchart of participant retention.-->
<!--GEF: see my comment above, i think the flowchart would be helpful! demographic/AUD history/other participant characteristic tables probably most relevant in results -->

## Procedure
Participants completed five study visits over the course of approximately three months. After an initial phone screen, participants attended an in-person screening visit where we determined eligibility, obtained informed consent, and collected self-report measures of individual differences (e.g., demographics, mental health and alcohol use history). Eligible and consented participants returned approximately one week later to enroll in the study. Three additional follow-up visits  occurred about every 30 days participants were on study. At each follow-up visit, we collected additional self-report and interview measures (e.g., Alcohol Timeline Followback). <!--GEF: rather than provide an example here of the TLFB, i think you could just refer to Measures below. or could refer above when you talk about IDs and then say nothing here.-->

For the entire duration on study, participants were expected to complete EMAs four times each day. Other personal sensing data streams (geolocation, cellular communications, sleep quality, and audio check-ins) were collected as part of the larger grant's aims (R01 AA024391). A full description of the procedure and data collected at each visit can be found at the study's OSF page [<!--Insert link here-->]. All procedures were approved by the University of Wisconsin-Madison Institutional Review Board.

## Measures
### EMA
<!--citation for validity of self-reported alcohol use: https://pubmed.ncbi.nlm.nih.gov/26160523/-->
Participants completed a brief (7-10 questions) EMA four times each day following reminders from us that were sent by text message. These text messages included a link to a Qualtrics survey, optimized for completion on their smartphone. 

All four EMAs included seven items that asked about alcohol use not yet reported, current affective state (pleasantness and arousal), greatest urge to drink alcohol since the last EMA, any pleasant or positive events, any hassles or stressful events, and any exposure to risky situations (i.e., people, places, or things) that occurred since the last EMA. The first EMA each day asked an additional three questions about how likely participants were to encounter a risky situation, encounter a stressful event, and drink alcohol in the upcoming week. 

The first and last EMAs of the day were scheduled within one hour of participants' typical wake and sleep times. The other two EMAs were each scheduled randomly within the first and second halves of the participants' typical day. All EMAs were separated from each other by at least one hour.

### Individual Differences
At the screening visit we collected self-report information about demographics, mental health, and drug and alcohol use history. These measures are used to describe our sample. Only age, sex, race, education, and marital status are used as features for our analyses. <!--Refer to OSF for full list of measures--> <!--GEF: if you're using them to describe the sample, do they need to be listed/mentioned here? -->

## Data Analytic Strategy
Data preprocessing and modeling were done in RStudio, using the tidyverse and tidymodels ecosystems. <!--KW: Will add version numbers and references-->

### Lapse Labels
We created rolling lapse windows that varied in width (i.e., 1 hour, 24 hours, and 168 hours). Each window shifted hour by hour for prediction.

We only included lapse and no lapse windows that we were confident were accurately labeled. A valid lapse window must contain a lapse observation. A valid no lapse window must have all observations labeled as no lapse (i.e., no excluded observations). <!--GEF: after reading the next two paragraphs, i'm not sure this paragraph is necessary. possibly, you could move this information into the subsequent paragraphs? but i feel like it's already there and is clearer in those paragraphs -->

We derived lapse labels from the first item of each EMA ("Have you drank any alcohol that you have not yet reported?"). If participants answered yes to this item, they were prompted to enter the hour and date of the first unreported drink (i.e., lapse onset) and the hour and date of their last drink (i.e., lapse offset). To be labeled as a lapse, the observation must have an hour associated with it, not be in the future, and the onset and offset of lapse must be ordered correctly. 

We used the EMA and other data (e.g., Alcohol Timeline Follow-back <!--GEF: cite -->) to label no lapse observations. Observations that we could not definitively label as no lapse were excluded from sampling (e.g., occurred within 24 hours of lapse onset, contained lapse reported retrospectively <!--GEF: this second example isn't clear to me-->).


### Feature Engineering
Features were calculated from different periods of data (6, 12, 24, 48, 72, and 168 hours prior to observation). Features were derived from EMA questions, demographics (i.e., age, white vs. other race, sex, education, and marital status), previous history of lapses, and date and time of observation (i.e., evening vs other hour, and day of week). 

We created features using both raw (e.g., min., max., median, most recent response, and total counts) and change (e.g., within-subject baseline comparisons) scores. 

This gave us a total of 267,283 features for 1-hour lapse windows, 274,175 features for 24-hour lapse windows, and 270,077 features for 168-hour lapse windows.


### Model Training and Evaluation

**1. algorithms**  
We considered three candidate classification statistical algorithms (elasticnet, random forest, xgboost) that differed across various characteristics expected to affect model performance (e.g., flexibility, ability to handle higher-order interactions natively, complexity, linear vs. non-linear). <!-- [also changed previous sentence to expand slightly]. Suggested addition: These algorithms are well-established with documented good "out of box" performance, and they vary with respect to the degree of feature selection performed automatically during model fitting.--> <!--cite Kunn & Johnson APM -->

**2. Model configurations**   
Each candidate algorithm was tuned for its associated hyperparameters <!--(i.e., model tuning parameters)--> and resampled using two methods (up and down sampling). <!--GEF: Resampling approaches are designed to address class imbalances by sampling additional minority class observations (upsampling) or removing majority class observations (downsampling) within held-in data.-->

**3. k-fold**  
We trained all possible model configurations (i.e., <!--combination of -->algorithm, hyperparameter values, and resampling method) using 10-fold cross validation. <!--GEF suggest adding a 1-2 sentence description here--> Cross-validation folds were grouped by participant ID (i.e., participants in the held-in data set were not also in the held-out data set). 

**4. pre-processing**  
Generic (e.g., handling of missing data and zero-variance variables) and algorithmic-specific (e.g., dummy coding and normalization) pre-processing steps were estimated using held in data and applied to held out data<!--KW: possibly reference supplemental recipe code here-->.

**5. selection** <!--GEF: if this subsection gets labeled, consider calling it performance metric?--> 
The best model configuration was selected <!--GEF: using cross-validation--> based on the primary performance metric of interest, area under the receiver operating characteristic curve (AUC ROC).

**6. evaluation**  
We evaluated performance of our best model configuration by averaging the AUC ROC across the 10 held out folds. In addition to our primary performance metric, we report the average sensitivity, specificity, balanced accuracy, and positive predictive value (PPV) from all held out folds<!--KW: will cite source for these metrics - tidymodels reference or IAML-->. We also provide the ROC and Precision-Recall (PR) curves. 

**7. interpretability**  
We calculated Shapley Additive Explanations (SHAP) scores to provide a global (i.e., across participants) index of feature importance.<!--KW: Not sure best spot for this section yet-->


\newpage

# Results
<!--Information for results: Participants were on study for an average of 85 days out of the possible 90 days. Participants had endorsed using on average 4 other types of drugs (not including alcohol) over their lifetime. Additionally, participants on average scored a 9 on a self-report version of the DSM-5 symptom criteria for alcohol use disorder. Generally, scores of 2-3 are considered mild, 4-5 are considered moderate, and 6+ considered severe alcohol use disorder.-->

<!--Move to results: Across participants there were a total of 1029 unique lapses. There was variation in the frequency of lapses, ranging from 0-75 lapses per participant (M = 6.8, SD = 12.0). Only 56% of participants (N = 84) reported a lapse. However, this was expected since our participants all had a goal of abstinence from alcohol.-->

<!--Citation for ROC cutoffs - https://journals.copmadrid.org/ejpalc/art/ejpalc2018a5 (.58 = small effect size, .69 = medium effect size, .79 = large effect size, corresponding to Cohen's d of .2, .5, .8 respectively).-->


<!-- Demographics table-->
```{r}
footnote_table_dem <- "N = 151"
```

```{r table_demo}
dem <- screen %>% 
  summarise(mean = as.character(round(mean(dem_1, na.rm = TRUE), 1)),
            SD = as.character(round(sd(dem_1, na.rm = TRUE), 1)),
            min = as.character(min(dem_1, na.rm = TRUE)),
            max = as.character(max(dem_1, na.rm = TRUE))) %>% 
  mutate(var = "Age",
         n = as.numeric(""),
         perc = as.numeric("")) %>% 
  select(var, n, perc, everything()) %>% 
  full_join(screen %>% 
  select(var = dem_2) %>% 
  group_by(var) %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / sum(n)) * 100), by = c("var", "n", "perc")) %>% 
  full_join(screen %>% 
  select(var = dem_3) %>% 
  mutate(var = fct_relevel(factor(var, 
                         c("American Indian/Alaska Native", "Asian", "Black/African American",
                           "White/Caucasian", "Other/Multiracial")))) %>%
  group_by(var) %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / sum(n)) * 100), by = c("var", "n", "perc")) %>% 
  full_join(screen %>% 
  select(var = dem_4) %>% 
  mutate(var = case_when(var == "No, I am not of Hispanic, Latino, or Spanish origin" ~ "No",
                         TRUE ~ "Yes"),
         var = fct_relevel(factor(var, c("Yes", "No")))) %>% 
  group_by(var) %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / sum(n)) * 100), by = c("var", "n", "perc")) %>% 
  full_join(screen %>% 
  select(var = dem_5) %>% 
  mutate(var = fct_relevel(factor(var, 
                         c("Less than high school or GED degree", "High school or GED", 
                           "Some college", "2-Year degree", "College degree", "Advanced degree")))) %>%
  group_by(var) %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / sum(n)) * 100), by = c("var", "n", "perc")) %>% 
  full_join(screen %>% 
  select(var = dem_6, dem_6_1) %>% 
  mutate(var = case_when(dem_6_1 == "Full-time" ~ "Employed full-time",
                         dem_6_1 == "Part-time" ~ "Employed part-time",
                         TRUE ~ var)) %>% 
  mutate(var = fct_relevel(factor(var, 
                         c("Employed full-time", "Employed part-time", "Full-time student",
                           "Homemaker", "Disabled", "Retired", "Unemployed", 
                           "Temporarily laid off, sick leave, or maternity leave",
                           "Other, not otherwise specified")))) %>%
  group_by(var) %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / sum(n)) * 100), by = c("var", "n", "perc")) %>% 
  full_join(screen %>% 
  summarise(mean = format(round(mean(dem_7, na.rm = TRUE), 0), big.mark = ","),
            SD = format(round(sd(dem_7, na.rm = TRUE), 0), big.mark = ","),
            min =format(round(min(dem_7, na.rm = TRUE), 0), big.mark = ","),
            max = format(round(max(dem_7, na.rm = TRUE), 0), scientific = FALSE, big.mark = ",")) %>% 
  mutate(var = "Personal Income",
        n = as.numeric(""),
        perc = as.numeric(""),
        mean = str_c("$", as.character(mean)),
        SD = str_c("$", as.character(SD)),
        min = str_c("$", as.character(min)),
        max = as.character(max)) %>% 
  select(var, n, perc, everything()), by = c("var", "n", "perc", "mean", "SD", "min", "max")) %>% 
  full_join(screen %>% 
  select(var = dem_8) %>% 
  mutate(var = case_when(var == "Never Married" ~ "Never married",
                         TRUE ~ var)) %>% 
  mutate(var = fct_relevel(factor(var, 
                         c("Never married", "Married", "Divorced", "Separated",
                           "Widowed")))) %>%
  group_by(var) %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / sum(n)) * 100), by = c("var", "n", "perc"))

# display and format table
dem %>% 
  mutate(range = str_c(min, "-", max)) %>%
  select(-c(min, max)) %>% 
  kbl(longtable = TRUE,
      booktabs = TRUE,
      col.names = c("", "N", "%", "M", "SD", "Range"),
      align = c("l", "c", "c", "c", "c", "c"),
      digits = 1,
      caption = "Demographics") %>%
  kable_styling() %>% 
  row_spec(row = 0, align = "c", italic = TRUE) %>% 
  pack_rows("Sex", 2, 3, bold = FALSE) %>% 
  pack_rows("Race", 4, 8, bold = FALSE) %>% 
  pack_rows("Hispanic, Latino, or Spanish Origin", 9, 10, bold = FALSE) %>% 
  pack_rows("Education", 11, 16, bold = FALSE) %>% 
  pack_rows("Employment", 17, 25, bold = FALSE) %>% 
  pack_rows("Marital Status", 27, 31, bold = FALSE) %>% 
  footnote(general=footnote_table_dem, threeparttable = TRUE)
```

\newpage

<!-- Alcohol Use History table-->
```{r}
footnote_table_auh_a <- "N = 151"
footnote_table_auh_b <- "Two participants reported 100 or more quit attempts. We removed these outliers prior to calculating the mean (M), standard deviation (SD), and range."
```

```{r table_auh}
auh <- screen %>% 
  summarise(mean = mean(auh_1, na.rm = TRUE),
            SD = sd(auh_1, na.rm = TRUE),
            min = min(auh_1, na.rm = TRUE),
            max = max(auh_1, na.rm = TRUE)) %>% 
  mutate(var = "Age of first drink",
        n = as.numeric(""),
        perc = as.numeric("")) %>% 
  select(var, n, perc, everything()) %>% 
  full_join(screen %>% 
  summarise(mean = mean(auh_2, na.rm = TRUE),
            SD = sd(auh_2, na.rm = TRUE),
            min = min(auh_2, na.rm = TRUE),
            max = max(auh_2, na.rm = TRUE)) %>% 
  mutate(var = "Age of regular drinking",
        n = as.numeric(""),
        perc = as.numeric("")) %>% 
  select(var, n, perc, everything()), by = c("var", "n", "perc", "mean", "SD", 
                                             "min", "max")) %>% 
  full_join(screen %>% 
  summarise(mean = mean(auh_3, na.rm = TRUE),
            SD = sd(auh_3, na.rm = TRUE),
            min = min(auh_3, na.rm = TRUE),
            max = max(auh_3, na.rm = TRUE)) %>% 
  mutate(var = "Age at which drinking became problematic",
        n = as.numeric(""),
        perc = as.numeric("")) %>% 
  select(var, n, perc, everything()), by = c("var", "n", "perc", "mean", "SD",
                                             "min", "max")) %>% 
  full_join(screen %>% 
  summarise(mean = mean(auh_4, na.rm = TRUE),
            SD = sd(auh_4, na.rm = TRUE),
            min = min(auh_4, na.rm = TRUE),
            max = max(auh_4, na.rm = TRUE)) %>% 
  mutate(var = "Age of first quit attempt",
        n = as.numeric(""),
        perc = as.numeric("")) %>% 
  select(var, n, perc, everything()), by = c("var", "n", "perc", "mean", "SD",
                                             "min", "max")) %>% 
  full_join(screen %>% 
  # filter out 2 people with 100 and 365 reported quit attempts - will make footnote in table
  filter(auh_5 < 100) %>% 
  summarise(mean = mean(auh_5, na.rm = TRUE),
            SD = sd(auh_5, na.rm = TRUE),
            min = min(auh_5, na.rm = TRUE),
            max = max(auh_5, na.rm = TRUE)) %>% 
  mutate(var = "Number of Quit Attempts*",
        n = as.numeric(""),
        perc = as.numeric("")) %>% 
  select(var, n, perc, everything()), by = c("var", "n", "perc", "mean", "SD",
                                             "min", "max")) %>% 
  full_join(screen %>% 
  select(var = auh_6_1) %>%
  mutate(var = case_when(var == "Long-Term Residential Treatment (more than 6 months)" ~ "Long-term residential (6+ months)",
                         TRUE ~ var)) %>% 
  group_by(var) %>% 
  drop_na() %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / 154) * 100), by = c("var", "n", "perc")) %>% 
  full_join(screen %>% 
  select(var = auh_6_2) %>%
  mutate(var = case_when(var == "Short-Term Residential Treatment (less than 6 months)" ~ "Short-term residential (< 6 months)",
                         TRUE ~ var)) %>% 
  group_by(var) %>% 
  drop_na() %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / 154) * 100), by = c("var", "n", "perc")) %>% 
  full_join(screen %>% 
  select(var = auh_6_3) %>%
  mutate(var = case_when(var == "Outpatient Treatment" ~ "Outpatient",
                         TRUE ~ var)) %>% 
  group_by(var) %>% 
  drop_na() %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / 154) * 100), by = c("var", "n", "perc")) %>% 
  full_join(screen %>% 
  select(var = auh_6_4) %>%
  mutate(var = case_when(var == "Individual Counseling" ~ "Individual counseling",
                         TRUE ~ var)) %>% 
  group_by(var) %>% 
  drop_na() %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / 154) * 100), by = c("var", "n", "perc")) %>% 
  full_join(screen %>% 
  select(var = auh_6_5) %>%
  mutate(var = case_when(var == "Group Counseling" ~ "Group counseling",
                         TRUE ~ var)) %>% 
  group_by(var) %>% 
  drop_na() %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / 154) * 100), by = c("var", "n", "perc")) %>% 
  full_join(screen %>% 
  select(var = auh_6_6) %>%
  group_by(var) %>% 
  drop_na() %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / 154) * 100), by = c("var", "n", "perc")) %>% 
  full_join(screen %>% 
  select(var = auh_6_7) %>%
  group_by(var) %>% 
  drop_na() %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / 154) * 100), by = c("var", "n", "perc")) %>% 
  full_join(screen %>% 
  select(var = auh_7) %>% 
  mutate(var = fct_relevel(factor(var, c("Yes", "No")))) %>%
  group_by(var) %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / sum(n)) * 100), by = c("var", "n", "perc")) %>% 
  full_join(screen %>% 
  mutate(across(dsm5_1:dsm5_11, ~ recode(., "No" = 0, "Yes" = 1))) %>% 
  rowwise() %>% 
  # calculate dsm5 score by adding up dsm5_1 through dsm5_11
  mutate(dsm5_total = sum(c(dsm5_1, dsm5_2, dsm5_3, dsm5_4, dsm5_5, dsm5_6, dsm5_7, 
                            dsm5_8, dsm5_9, dsm5_10, dsm5_11))) %>% 
  ungroup() %>% 
  summarise(mean = mean(dsm5_total),
            SD = sd(dsm5_total),
            min = min(dsm5_total, na.rm = TRUE),
            max = max(dsm5_total, na.rm = TRUE)) %>% 
  mutate(var = "Alcohol Use Disorder DSM-5 Symptom Count",
        n = as.numeric(""),
        perc = as.numeric("")) %>% 
  select(var, n, perc, everything()), by = c("var", "n", "perc", "mean", "SD",
                                             "min", "max")) %>% 
  full_join(screen %>% 
  select(var = assist_2_1) %>%
  filter(var != "Never" & !is.na(var)) %>% 
  mutate(var = "Tobacco products (cigarettes, chewing tobacco, cigars, etc.)") %>% 
  group_by(var) %>% 
  drop_na() %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / 154) * 100), by = c("var", "n", "perc")) %>% 
  full_join(screen %>% 
  select(var = assist_2_2) %>%
  filter(var != "Never" & !is.na(var)) %>% 
  mutate(var = "Cannabis (marijuana, pot, grass, hash, etc.)") %>% 
  group_by(var) %>% 
  drop_na() %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / 154) * 100), by = c("var", "n", "perc")) %>% 
  full_join(screen %>% 
  select(var = assist_2_3) %>%
  filter(var != "Never" & !is.na(var)) %>% 
  mutate(var = "Cocaine (coke, crack, etc.)") %>% 
  group_by(var) %>% 
  drop_na() %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / 154) * 100), by = c("var", "n", "perc")) %>% 
  full_join(screen %>% 
  select(var = assist_2_4) %>%
  filter(var != "Never" & !is.na(var)) %>% 
  mutate(var = "Amphetamine type stimulants (speed, diet pills, ecstasy, etc.)") %>% 
  group_by(var) %>% 
  drop_na() %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / 154) * 100), by = c("var", "n", "perc")) %>% 
  full_join(screen %>% 
  select(var = assist_2_5) %>%
  filter(var != "Never" & !is.na(var)) %>% 
  mutate(var = "Inhalants (nitrous, glue, petrol, paint thinner, etc.)") %>% 
  group_by(var) %>% 
  drop_na() %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / 154) * 100), by = c("var", "n", "perc")) %>% 
  full_join(screen %>% 
  select(var = assist_2_6) %>%
  filter(var != "Never" & !is.na(var)) %>% 
  mutate(var = "Sedatives or sleeping pills (Valium, Serepax, Rohypnol, etc.)") %>% 
  group_by(var) %>% 
  drop_na() %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / 154) * 100), by = c("var", "n", "perc")) %>% 
  full_join(screen %>% 
  select(var = assist_2_7) %>%
  filter(var != "Never" & !is.na(var)) %>% 
  mutate(var = "Hallucinogens (LSD, acid, mushrooms, PCP, Special K, etc.)") %>% 
  group_by(var) %>% 
  drop_na() %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / 154) * 100), by = c("var", "n", "perc")) %>% 
  full_join(screen %>% 
  select(var = assist_2_8) %>%
  filter(var != "Never" & !is.na(var)) %>% 
  mutate(var = "Opioids (heroin, morphine, methadone, codeine, etc.)") %>% 
  group_by(var) %>% 
  drop_na() %>% 
  summarise(n = n()) %>% 
  mutate(perc = (n / 154) * 100), by = c("var", "n", "perc")) 

# display and format table
auh %>%
  mutate(range = str_c(min, "-", max)) %>%
  select(-c(min, max)) %>% 
  kbl(longtable = TRUE,
      booktabs = TRUE,
      col.names = c("", "N", "%", "M", "SD", "Range"),
      align = c("l", "c", "c", "c", "c", "c"),
      digits = 1,
      caption = "Alcohol Related Information") %>% 
  row_spec(row = 0, align = "c", italic = TRUE) %>% 
  kable_classic(html_font = "Times New Roman", position = "left") %>% 
  pack_rows("Alcohol Use Disorder Milestones", 1, 4, bold = FALSE) %>% 
  pack_rows("Lifetime History of Treatment (Can choose more than 1)", 6, 12, bold = FALSE) %>% 
  pack_rows("Received Medication for Alcohol Use Disorder", 13, 14, bold = FALSE) %>% 
  pack_rows("Current (Past 3 Month) Drug Use", 16, 23, bold = FALSE) %>% 
  footnote(general=footnote_table_auh_a, symbol = c(footnote_table_auh_b), 
           threeparttable = TRUE)
```

\newpage

<!--fix borders-->
```{r table_metrics}
metrics_week <- preds_week %>%   
  conf_mat(truth, estimate) %>% 
  summary() %>% 
  mutate(.estimate = round(.estimate, 3)) %>% 
  rename(week = .estimate,
         metric = .metric) %>% 
  select(-.estimator)

metrics_day <- preds_day %>%   
  conf_mat(truth, estimate) %>% 
  summary() %>% 
  mutate(.estimate = round(.estimate, 3)) %>% 
  rename(day = .estimate,
         metric = .metric) %>% 
  select(-.estimator)

metrics_hour <- preds_hour %>%   
  conf_mat(truth, estimate) %>% 
  summary() %>% 
  mutate(.estimate = round(.estimate, 3)) %>% 
  rename(hour = .estimate,
         metric = .metric) %>% 
  select(-.estimator)

metrics <- metrics_week %>% 
  full_join(metrics_day, by = "metric") %>% 
  full_join(metrics_hour, by = "metric") %>% 
  filter(metric %in% c("accuracy", "sens", "spec", "ppv", "npv"))

auc <- tibble(metric = "auc", 
              week = preds_week %>% roc_auc(prob, truth = truth) %>%  
                pull(.estimate) %>% round(3), 
              day = preds_day %>% roc_auc(prob, truth = truth) %>%  
                pull(.estimate) %>% round(3),
              hour = preds_hour %>% roc_auc(prob, truth = truth) %>%  
                pull(.estimate) %>% round(3))

metrics <- metrics %>% 
  bind_rows(auc)

metrics <- metrics[c(6,1,2,3,4,5),]

metrics %>%
  kbl(col.names = c("metric", "week", "day", "hour"),
      digits = 3,
      align = c("l", "c", "c", "c"),
      caption = "Table 3: Performance Metrics by Model",
      table.attr = "style='width:40%;'") %>% 
  row_spec(row = 0, align = "c") %>% 
  kable_classic(html_font = "Times New Roman", position = "left") %>% 
  footnote("insert table note")
```

\newpage


<!-- Consort Diagram-->
<!--: KW: I think the powerpoint version looks a bit nicer than this.-->
<!--fix margin-->
```{r caption_consort}
fig_caption_consort <- "Figure X. Consort Diagram"
```

```{r fig_consort, fig.cap=fig_caption_consort, fig.height=6.5}
consort_plot(data = disposition,
             orders = c(eligible = "Eligible Sample",
                        consented_reason = "Not Consented",
                        consented = "Consented",
                        enrolled_reason = "Not Enrolled",
                        enrolled = "Enrolled",
                        completed_followup_reason = "Discontinued",
                        completed_followup = "Completed through Followup 1",
                        analysis_reason = "Excluded",
                        analysis = "Final Analysis"),
             side_box = c("consented_reason", 
                          "enrolled_reason", 
                          "completed_followup_reason",
                          "analysis_reason"),
             cex = .9)
```


<!-- Single AUC figure by model-->  
```{r caption_roc}
fig_caption_roc <- "Receiver Operating Characteritic Curves by Model  "
```

```{r fig_roc, fig.cap = fig_caption_roc, fig.height=7}

roc_all %>% 
  mutate(model = factor(model, levels = c("1week", "1day", "1hour"))) %>% 
  ggplot(aes(x = 1 - specificity, y = sensitivity, color = model)) +
  geom_path() +
  geom_abline(lty = 3) +
  coord_fixed(xlim = c(0, 1), ylim = c(0, 1)) +
  labs(x = "Specificity",
       y = "Sensitivity") +
  scale_x_continuous(breaks = seq(0,1,.25),
    labels = sprintf("%.2f", seq(1,0,-.25))) +
  theme(axis.text = element_text(size = rel(1.50)), 
        axis.title = element_text(size = rel(1.75)))
```


<!-- Single Posteriors for AUC by model with rope-->

```{r caption_pp}
fig_caption_pp <- "Posterior Probability Distributions for Area Under the ROC Curve by Model.  Horizontal lines represent 95 percent credible intervals for each model.  Verical line represents mean of the posteerior distribution."
```

<!--fix legend to remove horizontal line-->
```{r fig_pp, fig.cap = fig_caption_pp, fig.height=7}
pp_tidy <- pp %>% 
  tidy(seed = 123)

ci <- pp_tidy %>% 
  summary() %>% 
  mutate(model = factor(model, levels = c("week", "day", "hour")),
         y = 1000)

pp_tidy %>% 
  mutate(model = factor(model, levels = c("week", "day", "hour"))) %>%
  ggplot() + 
  geom_histogram(aes(x = posterior, fill = model), color = "black", alpha = .4, 
                 bins = 30) +
  geom_segment(mapping = aes(y = y+100, yend = y-100, x = mean, xend = mean,
                           color = model),
               data = ci) +
  geom_segment(mapping = aes(y = y, yend = y, x = lower, xend = upper, color = model),
                data = ci) +
  facet_wrap(~model, ncol = 1) +
  scale_y_continuous("Posterior Probability", breaks = c(0, 500, 1000)) +
  # ylab("Posterior Probability Density") +
  xlab("Area Under ROC Curve")
```


<!-- PR curve by model-->
```{r caption_pr}
fig_caption_pr <- "Precision-Recall Curves for models."
```

<!--fix order of models - week, day, hour-->
```{r fig_pr, fig.cap = fig_caption_pr, fig.height=7}
pr_all %>% 
  ggplot(aes(x = recall, y = precision, color = model)) +
  geom_path() +
  coord_fixed(xlim = c(0, 1), ylim = c(0, 1)) +
  labs(x = "Sensitivity (Recall)",
       y = "Positive Predictive Value (Precision)")
```

<!-- SHAP Importance figures separate by model-->
```{r caption_shap_week}
fig_caption_shapgrouped_1week <- "Variable Importance (SHAP Valuse) for 1week Model.  Raw EMA features are grouped by the original item from the EMA. Features from demographics and the day and hour for the start of the  prediction window are also included."
```

```{r fig_shap_week, fig.cap = fig_caption_shapgrouped_1week, fig.height=7}
shap_grouped_week %>% 
  mutate(group = factor(group),
         group = forcats::fct_inorder(group)) %>% 
  ggplot(mapping = aes(x = group, y = mean_value)) +
  geom_point(size = 2, color = "red") +
  geom_segment(aes(x = group, y = mean_value, xend = group), 
               yend = 0, colour = "grey50")  +
  ylab("Mean |SHAP| value") +
  xlab("") +
  coord_flip()
```

```{r caption_shap_day}
fig_caption_shapgrouped_1day <- "Variable Importance (SHAP Values) for 1day Model.  Raw EMA features are grouped by the original item from the EMA. Features from demographics and the day and hour for the start of the  prediction window are also included."
```

```{r fig_shap_day, fig.cap = fig_caption_shapgrouped_1day, fig.height=7}
shap_grouped_day %>% 
  mutate(group = factor(group),
         group = forcats::fct_inorder(group)) %>% 
  ggplot(mapping = aes(x = group, y = mean_value)) +
  geom_point(size = 2, color = "red") +
  geom_segment(aes(x = group, y = mean_value, xend = group), 
               yend = 0, colour = "grey50")  +
  ylab("Mean |SHAP| value") +
  xlab("") +
  coord_flip()
```

```{r caption_shap_hour}
fig_caption_shapgrouped_1hour <- "Variable Importance (SHAP Values) for 1hour Model.  Raw EMA features are grouped by the original item from the EMA. Features from demographics and the day and hour for the start of the  prediction window are also included."
```

```{r fig_shap_hour, fig.cap = fig_caption_shapgrouped_1hour, fig.height=7}
shap_grouped_hour %>% 
  mutate(group = factor(group),
         group = forcats::fct_inorder(group)) %>% 
  ggplot(mapping = aes(x = group, y = mean_value)) +
  geom_point(size = 2, color = "red") +
  geom_segment(aes(x = group, y = mean_value, xend = group), 
               yend = 0, colour = "grey50")  +
  ylab("Mean |SHAP| value") +
  xlab("") +
  coord_flip()
```

<!-- SHAP Importance figure combined across models-->
<!--organize by item, window and then demo-->